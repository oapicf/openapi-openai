/*
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

package org.openapitools.client.model;

import org.openapitools.client.model.ResponseFormatJsonObject;
import org.openapitools.client.model.ResponseFormatJsonSchema;
import org.openapitools.client.model.ResponseFormatJsonSchemaJsonSchema;
import org.openapitools.client.model.ResponseFormatText;
import io.swagger.annotations.*;
import com.google.gson.annotations.SerializedName;

/**
 * An object specifying the format that the model must output.  Setting to &#x60;{ \&quot;type\&quot;: \&quot;json_schema\&quot;, \&quot;json_schema\&quot;: {...} }&#x60; enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).  Setting to &#x60;{ \&quot;type\&quot;: \&quot;json_object\&quot; }&#x60; enables JSON mode, which ensures the message the model generates is valid JSON.  **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \&quot;stuck\&quot; request. Also note that the message content may be partially cut off if &#x60;finish_reason&#x3D;\&quot;length\&quot;&#x60;, which indicates the generation exceeded &#x60;max_tokens&#x60; or the conversation exceeded the max context length. 
 **/
@ApiModel(description = "An object specifying the format that the model must output.  Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).  Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.  **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length. ")
public class CreateChatCompletionRequestResponseFormat {
  
  public enum TypeEnum {
     text,  json_object,  json_schema, 
  };
  @SerializedName("type")
  private TypeEnum type = null;
  @SerializedName("json_schema")
  private ResponseFormatJsonSchemaJsonSchema jsonSchema = null;

  /**
   * The type of response format being defined: `text`
   **/
  @ApiModelProperty(required = true, value = "The type of response format being defined: `text`")
  public TypeEnum getType() {
    return type;
  }
  public void setType(TypeEnum type) {
    this.type = type;
  }

  /**
   **/
  @ApiModelProperty(required = true, value = "")
  public ResponseFormatJsonSchemaJsonSchema getJsonSchema() {
    return jsonSchema;
  }
  public void setJsonSchema(ResponseFormatJsonSchemaJsonSchema jsonSchema) {
    this.jsonSchema = jsonSchema;
  }


  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    CreateChatCompletionRequestResponseFormat createChatCompletionRequestResponseFormat = (CreateChatCompletionRequestResponseFormat) o;
    return (this.type == null ? createChatCompletionRequestResponseFormat.type == null : this.type.equals(createChatCompletionRequestResponseFormat.type)) &&
        (this.jsonSchema == null ? createChatCompletionRequestResponseFormat.jsonSchema == null : this.jsonSchema.equals(createChatCompletionRequestResponseFormat.jsonSchema));
  }

  @Override
  public int hashCode() {
    int result = 17;
    result = 31 * result + (this.type == null ? 0: this.type.hashCode());
    result = 31 * result + (this.jsonSchema == null ? 0: this.jsonSchema.hashCode());
    return result;
  }

  @Override
  public String toString()  {
    StringBuilder sb = new StringBuilder();
    sb.append("class CreateChatCompletionRequestResponseFormat {\n");
    
    sb.append("  type: ").append(type).append("\n");
    sb.append("  jsonSchema: ").append(jsonSchema).append("\n");
    sb.append("}\n");
    return sb.toString();
  }
}
