/*
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

package org.openapitools.client.model;

import io.swagger.annotations.*;
import com.google.gson.annotations.SerializedName;

/**
 * Sent by the server when in &#x60;server_vad&#x60; mode to indicate that speech has been  detected in the audio buffer. This can happen any time audio is added to the  buffer (unless speech is already detected). The client may want to use this  event to interrupt audio playback or provide visual feedback to the user.   The client should expect to receive a &#x60;input_audio_buffer.speech_stopped&#x60; event  when speech stops. The &#x60;item_id&#x60; property is the ID of the user message item  that will be created when speech stops and will also be included in the  &#x60;input_audio_buffer.speech_stopped&#x60; event (unless the client manually commits  the audio buffer during VAD activation). 
 **/
@ApiModel(description = "Sent by the server when in `server_vad` mode to indicate that speech has been  detected in the audio buffer. This can happen any time audio is added to the  buffer (unless speech is already detected). The client may want to use this  event to interrupt audio playback or provide visual feedback to the user.   The client should expect to receive a `input_audio_buffer.speech_stopped` event  when speech stops. The `item_id` property is the ID of the user message item  that will be created when speech stops and will also be included in the  `input_audio_buffer.speech_stopped` event (unless the client manually commits  the audio buffer during VAD activation). ")
public class RealtimeServerEventInputAudioBufferSpeechStarted {
  
  @SerializedName("event_id")
  private String eventId = null;
  public enum TypeEnum {
     input_audio_buffer.speech_started, 
  };
  @SerializedName("type")
  private TypeEnum type = null;
  @SerializedName("audio_start_ms")
  private Integer audioStartMs = null;
  @SerializedName("item_id")
  private String itemId = null;

  /**
   * The unique ID of the server event.
   **/
  @ApiModelProperty(required = true, value = "The unique ID of the server event.")
  public String getEventId() {
    return eventId;
  }
  public void setEventId(String eventId) {
    this.eventId = eventId;
  }

  /**
   * The event type, must be `input_audio_buffer.speech_started`.
   **/
  @ApiModelProperty(required = true, value = "The event type, must be `input_audio_buffer.speech_started`.")
  public TypeEnum getType() {
    return type;
  }
  public void setType(TypeEnum type) {
    this.type = type;
  }

  /**
   * Milliseconds from the start of all audio written to the buffer during the  session when speech was first detected. This will correspond to the  beginning of audio sent to the model, and thus includes the  `prefix_padding_ms` configured in the Session. 
   **/
  @ApiModelProperty(required = true, value = "Milliseconds from the start of all audio written to the buffer during the  session when speech was first detected. This will correspond to the  beginning of audio sent to the model, and thus includes the  `prefix_padding_ms` configured in the Session. ")
  public Integer getAudioStartMs() {
    return audioStartMs;
  }
  public void setAudioStartMs(Integer audioStartMs) {
    this.audioStartMs = audioStartMs;
  }

  /**
   * The ID of the user message item that will be created when speech stops. 
   **/
  @ApiModelProperty(required = true, value = "The ID of the user message item that will be created when speech stops. ")
  public String getItemId() {
    return itemId;
  }
  public void setItemId(String itemId) {
    this.itemId = itemId;
  }


  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    RealtimeServerEventInputAudioBufferSpeechStarted realtimeServerEventInputAudioBufferSpeechStarted = (RealtimeServerEventInputAudioBufferSpeechStarted) o;
    return (this.eventId == null ? realtimeServerEventInputAudioBufferSpeechStarted.eventId == null : this.eventId.equals(realtimeServerEventInputAudioBufferSpeechStarted.eventId)) &&
        (this.type == null ? realtimeServerEventInputAudioBufferSpeechStarted.type == null : this.type.equals(realtimeServerEventInputAudioBufferSpeechStarted.type)) &&
        (this.audioStartMs == null ? realtimeServerEventInputAudioBufferSpeechStarted.audioStartMs == null : this.audioStartMs.equals(realtimeServerEventInputAudioBufferSpeechStarted.audioStartMs)) &&
        (this.itemId == null ? realtimeServerEventInputAudioBufferSpeechStarted.itemId == null : this.itemId.equals(realtimeServerEventInputAudioBufferSpeechStarted.itemId));
  }

  @Override
  public int hashCode() {
    int result = 17;
    result = 31 * result + (this.eventId == null ? 0: this.eventId.hashCode());
    result = 31 * result + (this.type == null ? 0: this.type.hashCode());
    result = 31 * result + (this.audioStartMs == null ? 0: this.audioStartMs.hashCode());
    result = 31 * result + (this.itemId == null ? 0: this.itemId.hashCode());
    return result;
  }

  @Override
  public String toString()  {
    StringBuilder sb = new StringBuilder();
    sb.append("class RealtimeServerEventInputAudioBufferSpeechStarted {\n");
    
    sb.append("  eventId: ").append(eventId).append("\n");
    sb.append("  type: ").append(type).append("\n");
    sb.append("  audioStartMs: ").append(audioStartMs).append("\n");
    sb.append("  itemId: ").append(itemId).append("\n");
    sb.append("}\n");
    return sb.toString();
  }
}
