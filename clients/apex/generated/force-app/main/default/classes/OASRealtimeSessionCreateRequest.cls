/*
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by the OAS code generator program.
 * https://github.com/OpenAPITools/openapi-generator
 * Do not edit the class manually.
 */

/**
 * Realtime session object configuration.
 */
public class OASRealtimeSessionCreateRequest implements OAS.MappedProperties {
    /**
     * Gets or Sets modalities
     */
    public enum ModalitiesEnum {
        TEXT,
        AUDIO
    }

    /**
     * The set of modalities the model can respond with. To disable audio,\nset this to ["text"].\n
     * @return modalities
     */
    public List<ModalitiesEnum> modalities { get; set; }

    /**
     * The Realtime model used for this session.\n
     */
    public enum ModelEnum {
        GPT_4O_REALTIME_PREVIEW,
        GPT_4O_REALTIME_PREVIEW_2024_10_01,
        GPT_4O_REALTIME_PREVIEW_2024_12_17,
        GPT_4O_MINI_REALTIME_PREVIEW,
        GPT_4O_MINI_REALTIME_PREVIEW_2024_12_17
    }

    /**
     * The Realtime model used for this session.\n
     * @return model
     */
    public ModelEnum model { get; set; }

    /**
     * The default system instructions (i.e. system message) prepended to model \ncalls. This field allows the client to guide the model on desired \nresponses. The model can be instructed on response content and format, \n(e.g. "be extremely succinct", "act friendly", "here are examples of good \nresponses") and on audio behavior (e.g. "talk quickly", "inject emotion \ninto your voice", "laugh frequently"). The instructions are not guaranteed \nto be followed by the model, but they provide guidance to the model on the \ndesired behavior.\n\nNote that the server sets default instructions which will be used if this \nfield is not set and are visible in the `session.created` event at the \nstart of the session.\n
     * @return instructions
     */
    public String instructions { get; set; }

    /**
     * The voice the model uses to respond. Voice cannot be changed during the \nsession once the model has responded with audio at least once. Current \nvoice options are `alloy`, `ash`, `ballad`, `coral`, `echo` `sage`, \n`shimmer` and `verse`.\n
     */
    public enum VoiceEnum {
        ALLOY,
        ASH,
        BALLAD,
        CORAL,
        ECHO,
        SAGE,
        SHIMMER,
        VERSE
    }

    /**
     * The voice the model uses to respond. Voice cannot be changed during the \nsession once the model has responded with audio at least once. Current \nvoice options are `alloy`, `ash`, `ballad`, `coral`, `echo` `sage`, \n`shimmer` and `verse`.\n
     * @return voice
     */
    public VoiceEnum voice { get; set; }

    /**
     * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n
     */
    public enum InputAudioFormatEnum {
        PCM16,
        G711_ULAW,
        G711_ALAW
    }

    /**
     * The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n
     * @return inputAudioFormat
     */
    public InputAudioFormatEnum inputAudioFormat { get; set; }

    /**
     * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n
     */
    public enum OutputAudioFormatEnum {
        PCM16,
        G711_ULAW,
        G711_ALAW
    }

    /**
     * The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.\n
     * @return outputAudioFormat
     */
    public OutputAudioFormatEnum outputAudioFormat { get; set; }

    /**
     * Get inputAudioTranscription
     * @return inputAudioTranscription
     */
    public OASRealtimeSessionInputAudioTranscri inputAudioTranscription { get; set; }

    /**
     * Get turnDetection
     * @return turnDetection
     */
    public OASRealtimeSessionCreateRequestTurnD turnDetection { get; set; }

    /**
     * Tools (functions) available to the model.
     * @return tools
     */
    public List<OASRealtimeResponseCreateParamsTools> tools { get; set; }

    /**
     * How the model chooses tools. Options are `auto`, `none`, `required`, or \nspecify a function.\n
     * @return toolChoice
     */
    public String toolChoice { get; set; }

    /**
     * Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.\n
     * @return temperature
     */
    public Double temperature { get; set; }

    /**
     * Get maxResponseOutputTokens
     * @return maxResponseOutputTokens
     */
    public OASRealtimeResponseCreateParamsMaxRe maxResponseOutputTokens { get; set; }

    private static final Map<String, String> propertyMappings = new Map<String, String>{
        'input_audio_format' => 'inputAudioFormat',
        'output_audio_format' => 'outputAudioFormat',
        'input_audio_transcription' => 'inputAudioTranscription',
        'turn_detection' => 'turnDetection',
        'tool_choice' => 'toolChoice',
        'max_response_output_tokens' => 'maxResponseOutputTokens'
    };

    public Map<String, String> getPropertyMappings() {
        return propertyMappings;
    }

    private static final Map<String, String> propertyMappings = new Map<String, String>{
        'input_audio_format' => 'inputAudioFormat',
        'output_audio_format' => 'outputAudioFormat',
        'input_audio_transcription' => 'inputAudioTranscription',
        'turn_detection' => 'turnDetection',
        'tool_choice' => 'toolChoice',
        'max_response_output_tokens' => 'maxResponseOutputTokens'
    };

    public Map<String, String> getPropertyMappings() {
        return propertyMappings;
    }

    private static final Map<String, String> propertyMappings = new Map<String, String>{
        'input_audio_format' => 'inputAudioFormat',
        'output_audio_format' => 'outputAudioFormat',
        'input_audio_transcription' => 'inputAudioTranscription',
        'turn_detection' => 'turnDetection',
        'tool_choice' => 'toolChoice',
        'max_response_output_tokens' => 'maxResponseOutputTokens'
    };

    public Map<String, String> getPropertyMappings() {
        return propertyMappings;
    }

    private static final Map<String, String> propertyMappings = new Map<String, String>{
        'input_audio_format' => 'inputAudioFormat',
        'output_audio_format' => 'outputAudioFormat',
        'input_audio_transcription' => 'inputAudioTranscription',
        'turn_detection' => 'turnDetection',
        'tool_choice' => 'toolChoice',
        'max_response_output_tokens' => 'maxResponseOutputTokens'
    };

    public Map<String, String> getPropertyMappings() {
        return propertyMappings;
    }

    private static final Map<String, String> propertyMappings = new Map<String, String>{
        'input_audio_format' => 'inputAudioFormat',
        'output_audio_format' => 'outputAudioFormat',
        'input_audio_transcription' => 'inputAudioTranscription',
        'turn_detection' => 'turnDetection',
        'tool_choice' => 'toolChoice',
        'max_response_output_tokens' => 'maxResponseOutputTokens'
    };

    public Map<String, String> getPropertyMappings() {
        return propertyMappings;
    }

    private static final Map<String, String> propertyMappings = new Map<String, String>{
        'input_audio_format' => 'inputAudioFormat',
        'output_audio_format' => 'outputAudioFormat',
        'input_audio_transcription' => 'inputAudioTranscription',
        'turn_detection' => 'turnDetection',
        'tool_choice' => 'toolChoice',
        'max_response_output_tokens' => 'maxResponseOutputTokens'
    };

    public Map<String, String> getPropertyMappings() {
        return propertyMappings;
    }

    public OASRealtimeSessionCreateRequest() {
        modalities = new List<String>();
        tools = new List<OASRealtimeResponseCreateParamsTools>();
    }

    public static OASRealtimeSessionCreateRequest getExample() {
        OASRealtimeSessionCreateRequest realtimeSessionCreateRequest = new OASRealtimeSessionCreateRequest();
          realtimeSessionCreateRequest.modalities = List<ModalitiesEnum>.LIST_MODALITIESENUM_NEW_LIST_STRING_TEXT_;
          realtimeSessionCreateRequest.model = ModelEnum.GPT_4O_REALTIME_PREVIEW;
          realtimeSessionCreateRequest.instructions = '';
          realtimeSessionCreateRequest.voice = VoiceEnum.ALLOY;
          realtimeSessionCreateRequest.inputAudioFormat = InputAudioFormatEnum.PCM16;
          realtimeSessionCreateRequest.outputAudioFormat = OutputAudioFormatEnum.PCM16;
          realtimeSessionCreateRequest.inputAudioTranscription = OASRealtimeSessionInputAudioTranscri.getExample();
          realtimeSessionCreateRequest.turnDetection = OASRealtimeSessionCreateRequestTurnD.getExample();
          realtimeSessionCreateRequest.tools = new List<OASRealtimeResponseCreateParamsTools>{OASRealtimeResponseCreateParamsTools.getExample()};
          realtimeSessionCreateRequest.toolChoice = '';
          realtimeSessionCreateRequest.temperature = 1.3579;
          realtimeSessionCreateRequest.maxResponseOutputTokens = OASRealtimeResponseCreateParamsMaxRe.getExample();
        return realtimeSessionCreateRequest;
    }

    public Boolean equals(Object obj) {
        if (obj instanceof OASRealtimeSessionCreateRequest) {           
            OASRealtimeSessionCreateRequest realtimeSessionCreateRequest = (OASRealtimeSessionCreateRequest) obj;
            return this.modalities == realtimeSessionCreateRequest.modalities
                && this.model == realtimeSessionCreateRequest.model
                && this.instructions == realtimeSessionCreateRequest.instructions
                && this.voice == realtimeSessionCreateRequest.voice
                && this.inputAudioFormat == realtimeSessionCreateRequest.inputAudioFormat
                && this.outputAudioFormat == realtimeSessionCreateRequest.outputAudioFormat
                && this.inputAudioTranscription == realtimeSessionCreateRequest.inputAudioTranscription
                && this.turnDetection == realtimeSessionCreateRequest.turnDetection
                && this.tools == realtimeSessionCreateRequest.tools
                && this.toolChoice == realtimeSessionCreateRequest.toolChoice
                && this.temperature == realtimeSessionCreateRequest.temperature
                && this.maxResponseOutputTokens == realtimeSessionCreateRequest.maxResponseOutputTokens;
        }
        return false;
    }

    public Integer hashCode() {
        Integer hashCode = 43;
        hashCode = (17 * hashCode) + (modalities == null ? 0 : System.hashCode(modalities));
        hashCode = (17 * hashCode) + (model == null ? 0 : System.hashCode(model));
        hashCode = (17 * hashCode) + (instructions == null ? 0 : System.hashCode(instructions));
        hashCode = (17 * hashCode) + (voice == null ? 0 : System.hashCode(voice));
        hashCode = (17 * hashCode) + (inputAudioFormat == null ? 0 : System.hashCode(inputAudioFormat));
        hashCode = (17 * hashCode) + (outputAudioFormat == null ? 0 : System.hashCode(outputAudioFormat));
        hashCode = (17 * hashCode) + (inputAudioTranscription == null ? 0 : System.hashCode(inputAudioTranscription));
        hashCode = (17 * hashCode) + (turnDetection == null ? 0 : System.hashCode(turnDetection));
        hashCode = (17 * hashCode) + (tools == null ? 0 : System.hashCode(tools));
        hashCode = (17 * hashCode) + (toolChoice == null ? 0 : System.hashCode(toolChoice));
        hashCode = (17 * hashCode) + (temperature == null ? 0 : System.hashCode(temperature));
        hashCode = (17 * hashCode) + (maxResponseOutputTokens == null ? 0 : System.hashCode(maxResponseOutputTokens));
        return hashCode;
    }
}

