/**
* OpenAI API
* The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
*
* The version of the OpenAPI document: 2.3.0
* Contact: blah+oapicf@cliffano.com
*
* NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
* https://openapi-generator.tech
* Do not edit the class manually.
*/
/*
 * CompletionUsage.h
 *
 * Usage statistics for the completion request.
 */

#ifndef CompletionUsage_H_
#define CompletionUsage_H_


#include "CompletionUsage_prompt_tokens_details.h"
#include "CompletionUsage_completion_tokens_details.h"
#include <nlohmann/json.hpp>

namespace org::openapitools::server::model
{

/// <summary>
/// Usage statistics for the completion request.
/// </summary>
class  CompletionUsage
{
public:
    CompletionUsage();
    virtual ~CompletionUsage() = default;


    /// <summary>
    /// Validate the current data in the model. Throws a ValidationException on failure.
    /// </summary>
    void validate() const;

    /// <summary>
    /// Validate the current data in the model. Returns false on error and writes an error
    /// message into the given stringstream.
    /// </summary>
    bool validate(std::stringstream& msg) const;

    /// <summary>
    /// Helper overload for validate. Used when one model stores another model and calls it's validate.
    /// Not meant to be called outside that case.
    /// </summary>
    bool validate(std::stringstream& msg, const std::string& pathPrefix) const;

    bool operator==(const CompletionUsage& rhs) const;
    bool operator!=(const CompletionUsage& rhs) const;

    /////////////////////////////////////////////
    /// CompletionUsage members

    /// <summary>
    /// Number of tokens in the generated completion.
    /// </summary>
    int32_t getCompletionTokens() const;
    void setCompletionTokens(int32_t const value);
    /// <summary>
    /// Number of tokens in the prompt.
    /// </summary>
    int32_t getPromptTokens() const;
    void setPromptTokens(int32_t const value);
    /// <summary>
    /// Total number of tokens used in the request (prompt + completion).
    /// </summary>
    int32_t getTotalTokens() const;
    void setTotalTokens(int32_t const value);
    /// <summary>
    /// 
    /// </summary>
    org::openapitools::server::model::CompletionUsage_completion_tokens_details getCompletionTokensDetails() const;
    void setCompletionTokensDetails(org::openapitools::server::model::CompletionUsage_completion_tokens_details const& value);
    bool completionTokensDetailsIsSet() const;
    void unsetCompletion_tokens_details();
    /// <summary>
    /// 
    /// </summary>
    org::openapitools::server::model::CompletionUsage_prompt_tokens_details getPromptTokensDetails() const;
    void setPromptTokensDetails(org::openapitools::server::model::CompletionUsage_prompt_tokens_details const& value);
    bool promptTokensDetailsIsSet() const;
    void unsetPrompt_tokens_details();

    friend  void to_json(nlohmann::json& j, const CompletionUsage& o);
    friend  void from_json(const nlohmann::json& j, CompletionUsage& o);
protected:
    int32_t m_Completion_tokens;

    int32_t m_Prompt_tokens;

    int32_t m_Total_tokens;

    org::openapitools::server::model::CompletionUsage_completion_tokens_details m_Completion_tokens_details;
    bool m_Completion_tokens_detailsIsSet;
    org::openapitools::server::model::CompletionUsage_prompt_tokens_details m_Prompt_tokens_details;
    bool m_Prompt_tokens_detailsIsSet;
    
};

} // namespace org::openapitools::server::model

#endif /* CompletionUsage_H_ */
