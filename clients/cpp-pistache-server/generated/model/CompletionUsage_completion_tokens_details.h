/**
* OpenAI API
* The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
*
* The version of the OpenAPI document: 2.3.0
* Contact: blah+oapicf@cliffano.com
*
* NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
* https://openapi-generator.tech
* Do not edit the class manually.
*/
/*
 * CompletionUsage_completion_tokens_details.h
 *
 * Breakdown of tokens used in a completion.
 */

#ifndef CompletionUsage_completion_tokens_details_H_
#define CompletionUsage_completion_tokens_details_H_


#include <nlohmann/json.hpp>

namespace org::openapitools::server::model
{

/// <summary>
/// Breakdown of tokens used in a completion.
/// </summary>
class  CompletionUsage_completion_tokens_details
{
public:
    CompletionUsage_completion_tokens_details();
    virtual ~CompletionUsage_completion_tokens_details() = default;


    /// <summary>
    /// Validate the current data in the model. Throws a ValidationException on failure.
    /// </summary>
    void validate() const;

    /// <summary>
    /// Validate the current data in the model. Returns false on error and writes an error
    /// message into the given stringstream.
    /// </summary>
    bool validate(std::stringstream& msg) const;

    /// <summary>
    /// Helper overload for validate. Used when one model stores another model and calls it's validate.
    /// Not meant to be called outside that case.
    /// </summary>
    bool validate(std::stringstream& msg, const std::string& pathPrefix) const;

    bool operator==(const CompletionUsage_completion_tokens_details& rhs) const;
    bool operator!=(const CompletionUsage_completion_tokens_details& rhs) const;

    /////////////////////////////////////////////
    /// CompletionUsage_completion_tokens_details members

    /// <summary>
    /// When using Predicted Outputs, the number of tokens in the prediction that appeared in the completion. 
    /// </summary>
    int32_t getAcceptedPredictionTokens() const;
    void setAcceptedPredictionTokens(int32_t const value);
    bool acceptedPredictionTokensIsSet() const;
    void unsetAccepted_prediction_tokens();
    /// <summary>
    /// Audio input tokens generated by the model.
    /// </summary>
    int32_t getAudioTokens() const;
    void setAudioTokens(int32_t const value);
    bool audioTokensIsSet() const;
    void unsetAudio_tokens();
    /// <summary>
    /// Tokens generated by the model for reasoning.
    /// </summary>
    int32_t getReasoningTokens() const;
    void setReasoningTokens(int32_t const value);
    bool reasoningTokensIsSet() const;
    void unsetReasoning_tokens();
    /// <summary>
    /// When using Predicted Outputs, the number of tokens in the prediction that did not appear in the completion. However, like reasoning tokens, these tokens are still counted in the total completion tokens for purposes of billing, output, and context window limits. 
    /// </summary>
    int32_t getRejectedPredictionTokens() const;
    void setRejectedPredictionTokens(int32_t const value);
    bool rejectedPredictionTokensIsSet() const;
    void unsetRejected_prediction_tokens();

    friend  void to_json(nlohmann::json& j, const CompletionUsage_completion_tokens_details& o);
    friend  void from_json(const nlohmann::json& j, CompletionUsage_completion_tokens_details& o);
protected:
    int32_t m_Accepted_prediction_tokens;
    bool m_Accepted_prediction_tokensIsSet;
    int32_t m_Audio_tokens;
    bool m_Audio_tokensIsSet;
    int32_t m_Reasoning_tokens;
    bool m_Reasoning_tokensIsSet;
    int32_t m_Rejected_prediction_tokens;
    bool m_Rejected_prediction_tokensIsSet;
    
};

} // namespace org::openapitools::server::model

#endif /* CompletionUsage_completion_tokens_details_H_ */
