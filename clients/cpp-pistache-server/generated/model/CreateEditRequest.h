/**
* OpenAI API
* APIs for sampling from and fine-tuning language models
*
* The version of the OpenAPI document: 2.0.0
* Contact: blah+oapicf@cliffano.com
*
* NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
* https://openapi-generator.tech
* Do not edit the class manually.
*/
/*
 * CreateEditRequest.h
 *
 * 
 */

#ifndef CreateEditRequest_H_
#define CreateEditRequest_H_


#include "CreateEditRequest_model.h"
#include <string>
#include <nlohmann/json.hpp>

namespace org::openapitools::server::model
{

/// <summary>
/// 
/// </summary>
class  CreateEditRequest
{
public:
    CreateEditRequest();
    virtual ~CreateEditRequest() = default;


    /// <summary>
    /// Validate the current data in the model. Throws a ValidationException on failure.
    /// </summary>
    void validate() const;

    /// <summary>
    /// Validate the current data in the model. Returns false on error and writes an error
    /// message into the given stringstream.
    /// </summary>
    bool validate(std::stringstream& msg) const;

    /// <summary>
    /// Helper overload for validate. Used when one model stores another model and calls it's validate.
    /// Not meant to be called outside that case.
    /// </summary>
    bool validate(std::stringstream& msg, const std::string& pathPrefix) const;

    bool operator==(const CreateEditRequest& rhs) const;
    bool operator!=(const CreateEditRequest& rhs) const;

    /////////////////////////////////////////////
    /// CreateEditRequest members

    /// <summary>
    /// 
    /// </summary>
    org::openapitools::server::model::CreateEditRequest_model getModel() const;
    void setModel(org::openapitools::server::model::CreateEditRequest_model const& value);
    /// <summary>
    /// The input text to use as a starting point for the edit.
    /// </summary>
    std::string getInput() const;
    void setInput(std::string const& value);
    bool inputIsSet() const;
    void unsetInput();
    /// <summary>
    /// The instruction that tells the model how to edit the prompt.
    /// </summary>
    std::string getInstruction() const;
    void setInstruction(std::string const& value);
    /// <summary>
    /// How many edits to generate for the input and instruction.
    /// </summary>
    int32_t getN() const;
    void setN(int32_t const value);
    bool NIsSet() const;
    void unsetn();
    /// <summary>
    /// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.  We generally recommend altering this or &#x60;top_p&#x60; but not both. 
    /// </summary>
    double getTemperature() const;
    void setTemperature(double const value);
    bool temperatureIsSet() const;
    void unsetTemperature();
    /// <summary>
    /// An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.  We generally recommend altering this or &#x60;temperature&#x60; but not both. 
    /// </summary>
    double getTopP() const;
    void setTopP(double const value);
    bool topPIsSet() const;
    void unsetTop_p();

    friend  void to_json(nlohmann::json& j, const CreateEditRequest& o);
    friend  void from_json(const nlohmann::json& j, CreateEditRequest& o);
protected:
    org::openapitools::server::model::CreateEditRequest_model m_Model;

    std::string m_Input;
    bool m_InputIsSet;
    std::string m_Instruction;

    int32_t m_n;
    bool m_nIsSet;
    double m_Temperature;
    bool m_TemperatureIsSet;
    double m_Top_p;
    bool m_Top_pIsSet;
    
};

} // namespace org::openapitools::server::model

#endif /* CreateEditRequest_H_ */
