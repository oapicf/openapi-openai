/**
* OpenAI API
* The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
*
* The version of the OpenAPI document: 2.0.0
* Contact: blah+oapicf@cliffano.com
*
* NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
* https://openapi-generator.tech
* Do not edit the class manually.
*/


#include "CreateRunRequest.h"
#include "Helpers.h"

#include <sstream>

namespace org::openapitools::server::model
{

CreateRunRequest::CreateRunRequest()
{
    m_Assistant_id = "";
    m_ModelIsSet = false;
    m_Instructions = "";
    m_InstructionsIsSet = false;
    m_Additional_instructions = "";
    m_Additional_instructionsIsSet = false;
    m_Additional_messagesIsSet = false;
    m_ToolsIsSet = false;
    m_MetadataIsSet = false;
    m_Temperature = 1;
    m_TemperatureIsSet = false;
    m_Stream = false;
    m_StreamIsSet = false;
    m_Max_prompt_tokens = 0;
    m_Max_prompt_tokensIsSet = false;
    m_Max_completion_tokens = 0;
    m_Max_completion_tokensIsSet = false;
    m_Truncation_strategyIsSet = false;
    m_Tool_choiceIsSet = false;
    m_Response_formatIsSet = false;
    
}

void CreateRunRequest::validate() const
{
    std::stringstream msg;
    if (!validate(msg))
    {
        throw org::openapitools::server::helpers::ValidationException(msg.str());
    }
}

bool CreateRunRequest::validate(std::stringstream& msg) const
{
    return validate(msg, "");
}

bool CreateRunRequest::validate(std::stringstream& msg, const std::string& pathPrefix) const
{
    bool success = true;
    const std::string _pathPrefix = pathPrefix.empty() ? "CreateRunRequest" : pathPrefix;

                         
    if (additionalMessagesIsSet())
    {
        const std::vector<org::openapitools::server::model::CreateMessageRequest>& value = m_Additional_messages;
        const std::string currentValuePath = _pathPrefix + ".additionalMessages";
                
        
        { // Recursive validation of array elements
            const std::string oldValuePath = currentValuePath;
            int i = 0;
            for (const org::openapitools::server::model::CreateMessageRequest& value : value)
            { 
                const std::string currentValuePath = oldValuePath + "[" + std::to_string(i) + "]";
                        
        success = value.validate(msg, currentValuePath + ".additionalMessages") && success;
 
                i++;
            }
        }

    }
         
    if (toolsIsSet())
    {
        const std::vector<org::openapitools::server::model::AssistantObject_tools_inner>& value = m_Tools;
        const std::string currentValuePath = _pathPrefix + ".tools";
                
        
        if (value.size() > 20)
        {
            success = false;
            msg << currentValuePath << ": must have at most 20 elements;";
        }
        { // Recursive validation of array elements
            const std::string oldValuePath = currentValuePath;
            int i = 0;
            for (const org::openapitools::server::model::AssistantObject_tools_inner& value : value)
            { 
                const std::string currentValuePath = oldValuePath + "[" + std::to_string(i) + "]";
                        
        success = value.validate(msg, currentValuePath + ".tools") && success;
 
                i++;
            }
        }

    }
             
    if (temperatureIsSet())
    {
        const double& value = m_Temperature;
        const std::string currentValuePath = _pathPrefix + ".temperature";
                
        
        if (value < 0)
        {
            success = false;
            msg << currentValuePath << ": must be greater than or equal to 0;";
        }
        if (value > 2)
        {
            success = false;
            msg << currentValuePath << ": must be less than or equal to 2;";
        }

    }
             
    if (maxPromptTokensIsSet())
    {
        const int32_t& value = m_Max_prompt_tokens;
        const std::string currentValuePath = _pathPrefix + ".maxPromptTokens";
                
        
        if (value < 256)
        {
            success = false;
            msg << currentValuePath << ": must be greater than or equal to 256;";
        }

    }
         
    if (maxCompletionTokensIsSet())
    {
        const int32_t& value = m_Max_completion_tokens;
        const std::string currentValuePath = _pathPrefix + ".maxCompletionTokens";
                
        
        if (value < 256)
        {
            success = false;
            msg << currentValuePath << ": must be greater than or equal to 256;";
        }

    }
                
    return success;
}

bool CreateRunRequest::operator==(const CreateRunRequest& rhs) const
{
    return
    
    
    (getAssistantId() == rhs.getAssistantId())
     &&
    
    
    ((!modelIsSet() && !rhs.modelIsSet()) || (modelIsSet() && rhs.modelIsSet() && getModel() == rhs.getModel())) &&
    
    
    ((!instructionsIsSet() && !rhs.instructionsIsSet()) || (instructionsIsSet() && rhs.instructionsIsSet() && getInstructions() == rhs.getInstructions())) &&
    
    
    ((!additionalInstructionsIsSet() && !rhs.additionalInstructionsIsSet()) || (additionalInstructionsIsSet() && rhs.additionalInstructionsIsSet() && getAdditionalInstructions() == rhs.getAdditionalInstructions())) &&
    
    
    ((!additionalMessagesIsSet() && !rhs.additionalMessagesIsSet()) || (additionalMessagesIsSet() && rhs.additionalMessagesIsSet() && getAdditionalMessages() == rhs.getAdditionalMessages())) &&
    
    
    ((!toolsIsSet() && !rhs.toolsIsSet()) || (toolsIsSet() && rhs.toolsIsSet() && getTools() == rhs.getTools())) &&
    
    
    ((!metadataIsSet() && !rhs.metadataIsSet()) || (metadataIsSet() && rhs.metadataIsSet() && getMetadata() == rhs.getMetadata())) &&
    
    
    ((!temperatureIsSet() && !rhs.temperatureIsSet()) || (temperatureIsSet() && rhs.temperatureIsSet() && getTemperature() == rhs.getTemperature())) &&
    
    
    ((!streamIsSet() && !rhs.streamIsSet()) || (streamIsSet() && rhs.streamIsSet() && isStream() == rhs.isStream())) &&
    
    
    ((!maxPromptTokensIsSet() && !rhs.maxPromptTokensIsSet()) || (maxPromptTokensIsSet() && rhs.maxPromptTokensIsSet() && getMaxPromptTokens() == rhs.getMaxPromptTokens())) &&
    
    
    ((!maxCompletionTokensIsSet() && !rhs.maxCompletionTokensIsSet()) || (maxCompletionTokensIsSet() && rhs.maxCompletionTokensIsSet() && getMaxCompletionTokens() == rhs.getMaxCompletionTokens())) &&
    
    
    ((!truncationStrategyIsSet() && !rhs.truncationStrategyIsSet()) || (truncationStrategyIsSet() && rhs.truncationStrategyIsSet() && getTruncationStrategy() == rhs.getTruncationStrategy())) &&
    
    
    ((!toolChoiceIsSet() && !rhs.toolChoiceIsSet()) || (toolChoiceIsSet() && rhs.toolChoiceIsSet() && getToolChoice() == rhs.getToolChoice())) &&
    
    
    ((!responseFormatIsSet() && !rhs.responseFormatIsSet()) || (responseFormatIsSet() && rhs.responseFormatIsSet() && getResponseFormat() == rhs.getResponseFormat()))
    
    ;
}

bool CreateRunRequest::operator!=(const CreateRunRequest& rhs) const
{
    return !(*this == rhs);
}

void to_json(nlohmann::json& j, const CreateRunRequest& o)
{
    j = nlohmann::json::object();
    j["assistant_id"] = o.m_Assistant_id;
    if(o.modelIsSet())
        j["model"] = o.m_Model;
    if(o.instructionsIsSet())
        j["instructions"] = o.m_Instructions;
    if(o.additionalInstructionsIsSet())
        j["additional_instructions"] = o.m_Additional_instructions;
    if(o.additionalMessagesIsSet() || !o.m_Additional_messages.empty())
        j["additional_messages"] = o.m_Additional_messages;
    if(o.toolsIsSet() || !o.m_Tools.empty())
        j["tools"] = o.m_Tools;
    if(o.metadataIsSet())
        j["metadata"] = o.m_Metadata;
    if(o.temperatureIsSet())
        j["temperature"] = o.m_Temperature;
    if(o.streamIsSet())
        j["stream"] = o.m_Stream;
    if(o.maxPromptTokensIsSet())
        j["max_prompt_tokens"] = o.m_Max_prompt_tokens;
    if(o.maxCompletionTokensIsSet())
        j["max_completion_tokens"] = o.m_Max_completion_tokens;
    if(o.truncationStrategyIsSet())
        j["truncation_strategy"] = o.m_Truncation_strategy;
    if(o.toolChoiceIsSet())
        j["tool_choice"] = o.m_Tool_choice;
    if(o.responseFormatIsSet())
        j["response_format"] = o.m_Response_format;
    
}

void from_json(const nlohmann::json& j, CreateRunRequest& o)
{
    j.at("assistant_id").get_to(o.m_Assistant_id);
    if(j.find("model") != j.end())
    {
        j.at("model").get_to(o.m_Model);
        o.m_ModelIsSet = true;
    } 
    if(j.find("instructions") != j.end())
    {
        j.at("instructions").get_to(o.m_Instructions);
        o.m_InstructionsIsSet = true;
    } 
    if(j.find("additional_instructions") != j.end())
    {
        j.at("additional_instructions").get_to(o.m_Additional_instructions);
        o.m_Additional_instructionsIsSet = true;
    } 
    if(j.find("additional_messages") != j.end())
    {
        j.at("additional_messages").get_to(o.m_Additional_messages);
        o.m_Additional_messagesIsSet = true;
    } 
    if(j.find("tools") != j.end())
    {
        j.at("tools").get_to(o.m_Tools);
        o.m_ToolsIsSet = true;
    } 
    if(j.find("metadata") != j.end())
    {
        j.at("metadata").get_to(o.m_Metadata);
        o.m_MetadataIsSet = true;
    } 
    if(j.find("temperature") != j.end())
    {
        j.at("temperature").get_to(o.m_Temperature);
        o.m_TemperatureIsSet = true;
    } 
    if(j.find("stream") != j.end())
    {
        j.at("stream").get_to(o.m_Stream);
        o.m_StreamIsSet = true;
    } 
    if(j.find("max_prompt_tokens") != j.end())
    {
        j.at("max_prompt_tokens").get_to(o.m_Max_prompt_tokens);
        o.m_Max_prompt_tokensIsSet = true;
    } 
    if(j.find("max_completion_tokens") != j.end())
    {
        j.at("max_completion_tokens").get_to(o.m_Max_completion_tokens);
        o.m_Max_completion_tokensIsSet = true;
    } 
    if(j.find("truncation_strategy") != j.end())
    {
        j.at("truncation_strategy").get_to(o.m_Truncation_strategy);
        o.m_Truncation_strategyIsSet = true;
    } 
    if(j.find("tool_choice") != j.end())
    {
        j.at("tool_choice").get_to(o.m_Tool_choice);
        o.m_Tool_choiceIsSet = true;
    } 
    if(j.find("response_format") != j.end())
    {
        j.at("response_format").get_to(o.m_Response_format);
        o.m_Response_formatIsSet = true;
    } 
    
}

std::string CreateRunRequest::getAssistantId() const
{
    return m_Assistant_id;
}
void CreateRunRequest::setAssistantId(std::string const& value)
{
    m_Assistant_id = value;
}
org::openapitools::server::model::CreateRunRequest_model CreateRunRequest::getModel() const
{
    return m_Model;
}
void CreateRunRequest::setModel(org::openapitools::server::model::CreateRunRequest_model const& value)
{
    m_Model = value;
    m_ModelIsSet = true;
}
bool CreateRunRequest::modelIsSet() const
{
    return m_ModelIsSet;
}
void CreateRunRequest::unsetModel()
{
    m_ModelIsSet = false;
}
std::string CreateRunRequest::getInstructions() const
{
    return m_Instructions;
}
void CreateRunRequest::setInstructions(std::string const& value)
{
    m_Instructions = value;
    m_InstructionsIsSet = true;
}
bool CreateRunRequest::instructionsIsSet() const
{
    return m_InstructionsIsSet;
}
void CreateRunRequest::unsetInstructions()
{
    m_InstructionsIsSet = false;
}
std::string CreateRunRequest::getAdditionalInstructions() const
{
    return m_Additional_instructions;
}
void CreateRunRequest::setAdditionalInstructions(std::string const& value)
{
    m_Additional_instructions = value;
    m_Additional_instructionsIsSet = true;
}
bool CreateRunRequest::additionalInstructionsIsSet() const
{
    return m_Additional_instructionsIsSet;
}
void CreateRunRequest::unsetAdditional_instructions()
{
    m_Additional_instructionsIsSet = false;
}
std::vector<org::openapitools::server::model::CreateMessageRequest> CreateRunRequest::getAdditionalMessages() const
{
    return m_Additional_messages;
}
void CreateRunRequest::setAdditionalMessages(std::vector<org::openapitools::server::model::CreateMessageRequest> const& value)
{
    m_Additional_messages = value;
    m_Additional_messagesIsSet = true;
}
bool CreateRunRequest::additionalMessagesIsSet() const
{
    return m_Additional_messagesIsSet;
}
void CreateRunRequest::unsetAdditional_messages()
{
    m_Additional_messagesIsSet = false;
}
std::vector<org::openapitools::server::model::AssistantObject_tools_inner> CreateRunRequest::getTools() const
{
    return m_Tools;
}
void CreateRunRequest::setTools(std::vector<org::openapitools::server::model::AssistantObject_tools_inner> const& value)
{
    m_Tools = value;
    m_ToolsIsSet = true;
}
bool CreateRunRequest::toolsIsSet() const
{
    return m_ToolsIsSet;
}
void CreateRunRequest::unsetTools()
{
    m_ToolsIsSet = false;
}
org::openapitools::server::model::Object CreateRunRequest::getMetadata() const
{
    return m_Metadata;
}
void CreateRunRequest::setMetadata(org::openapitools::server::model::Object const& value)
{
    m_Metadata = value;
    m_MetadataIsSet = true;
}
bool CreateRunRequest::metadataIsSet() const
{
    return m_MetadataIsSet;
}
void CreateRunRequest::unsetMetadata()
{
    m_MetadataIsSet = false;
}
double CreateRunRequest::getTemperature() const
{
    return m_Temperature;
}
void CreateRunRequest::setTemperature(double const value)
{
    m_Temperature = value;
    m_TemperatureIsSet = true;
}
bool CreateRunRequest::temperatureIsSet() const
{
    return m_TemperatureIsSet;
}
void CreateRunRequest::unsetTemperature()
{
    m_TemperatureIsSet = false;
}
bool CreateRunRequest::isStream() const
{
    return m_Stream;
}
void CreateRunRequest::setStream(bool const value)
{
    m_Stream = value;
    m_StreamIsSet = true;
}
bool CreateRunRequest::streamIsSet() const
{
    return m_StreamIsSet;
}
void CreateRunRequest::unsetStream()
{
    m_StreamIsSet = false;
}
int32_t CreateRunRequest::getMaxPromptTokens() const
{
    return m_Max_prompt_tokens;
}
void CreateRunRequest::setMaxPromptTokens(int32_t const value)
{
    m_Max_prompt_tokens = value;
    m_Max_prompt_tokensIsSet = true;
}
bool CreateRunRequest::maxPromptTokensIsSet() const
{
    return m_Max_prompt_tokensIsSet;
}
void CreateRunRequest::unsetMax_prompt_tokens()
{
    m_Max_prompt_tokensIsSet = false;
}
int32_t CreateRunRequest::getMaxCompletionTokens() const
{
    return m_Max_completion_tokens;
}
void CreateRunRequest::setMaxCompletionTokens(int32_t const value)
{
    m_Max_completion_tokens = value;
    m_Max_completion_tokensIsSet = true;
}
bool CreateRunRequest::maxCompletionTokensIsSet() const
{
    return m_Max_completion_tokensIsSet;
}
void CreateRunRequest::unsetMax_completion_tokens()
{
    m_Max_completion_tokensIsSet = false;
}
org::openapitools::server::model::TruncationObject CreateRunRequest::getTruncationStrategy() const
{
    return m_Truncation_strategy;
}
void CreateRunRequest::setTruncationStrategy(org::openapitools::server::model::TruncationObject const& value)
{
    m_Truncation_strategy = value;
    m_Truncation_strategyIsSet = true;
}
bool CreateRunRequest::truncationStrategyIsSet() const
{
    return m_Truncation_strategyIsSet;
}
void CreateRunRequest::unsetTruncation_strategy()
{
    m_Truncation_strategyIsSet = false;
}
org::openapitools::server::model::AssistantsApiToolChoiceOption CreateRunRequest::getToolChoice() const
{
    return m_Tool_choice;
}
void CreateRunRequest::setToolChoice(org::openapitools::server::model::AssistantsApiToolChoiceOption const& value)
{
    m_Tool_choice = value;
    m_Tool_choiceIsSet = true;
}
bool CreateRunRequest::toolChoiceIsSet() const
{
    return m_Tool_choiceIsSet;
}
void CreateRunRequest::unsetTool_choice()
{
    m_Tool_choiceIsSet = false;
}
org::openapitools::server::model::AssistantsApiResponseFormatOption CreateRunRequest::getResponseFormat() const
{
    return m_Response_format;
}
void CreateRunRequest::setResponseFormat(org::openapitools::server::model::AssistantsApiResponseFormatOption const& value)
{
    m_Response_format = value;
    m_Response_formatIsSet = true;
}
bool CreateRunRequest::responseFormatIsSet() const
{
    return m_Response_formatIsSet;
}
void CreateRunRequest::unsetResponse_format()
{
    m_Response_formatIsSet = false;
}


} // namespace org::openapitools::server::model

