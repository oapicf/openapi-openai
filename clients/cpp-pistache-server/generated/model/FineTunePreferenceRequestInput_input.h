/**
* OpenAI API
* The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
*
* The version of the OpenAPI document: 2.3.0
* Contact: blah+oapicf@cliffano.com
*
* NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
* https://openapi-generator.tech
* Do not edit the class manually.
*/
/*
 * FineTunePreferenceRequestInput_input.h
 *
 * 
 */

#ifndef FineTunePreferenceRequestInput_input_H_
#define FineTunePreferenceRequestInput_input_H_


#include "FineTuneChatRequestInput_messages_inner.h"
#include "ChatCompletionTool.h"
#include <vector>
#include <nlohmann/json.hpp>

namespace org::openapitools::server::model
{

/// <summary>
/// 
/// </summary>
class  FineTunePreferenceRequestInput_input
{
public:
    FineTunePreferenceRequestInput_input();
    virtual ~FineTunePreferenceRequestInput_input() = default;


    /// <summary>
    /// Validate the current data in the model. Throws a ValidationException on failure.
    /// </summary>
    void validate() const;

    /// <summary>
    /// Validate the current data in the model. Returns false on error and writes an error
    /// message into the given stringstream.
    /// </summary>
    bool validate(std::stringstream& msg) const;

    /// <summary>
    /// Helper overload for validate. Used when one model stores another model and calls it's validate.
    /// Not meant to be called outside that case.
    /// </summary>
    bool validate(std::stringstream& msg, const std::string& pathPrefix) const;

    bool operator==(const FineTunePreferenceRequestInput_input& rhs) const;
    bool operator!=(const FineTunePreferenceRequestInput_input& rhs) const;

    /////////////////////////////////////////////
    /// FineTunePreferenceRequestInput_input members

    /// <summary>
    /// 
    /// </summary>
    std::vector<org::openapitools::server::model::FineTuneChatRequestInput_messages_inner> getMessages() const;
    void setMessages(std::vector<org::openapitools::server::model::FineTuneChatRequestInput_messages_inner> const& value);
    bool messagesIsSet() const;
    void unsetMessages();
    /// <summary>
    /// A list of tools the model may generate JSON inputs for.
    /// </summary>
    std::vector<org::openapitools::server::model::ChatCompletionTool> getTools() const;
    void setTools(std::vector<org::openapitools::server::model::ChatCompletionTool> const& value);
    bool toolsIsSet() const;
    void unsetTools();
    /// <summary>
    /// Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.
    /// </summary>
    bool isParallelToolCalls() const;
    void setParallelToolCalls(bool const value);
    bool parallelToolCallsIsSet() const;
    void unsetParallel_tool_calls();

    friend  void to_json(nlohmann::json& j, const FineTunePreferenceRequestInput_input& o);
    friend  void from_json(const nlohmann::json& j, FineTunePreferenceRequestInput_input& o);
protected:
    std::vector<org::openapitools::server::model::FineTuneChatRequestInput_messages_inner> m_Messages;
    bool m_MessagesIsSet;
    std::vector<org::openapitools::server::model::ChatCompletionTool> m_Tools;
    bool m_ToolsIsSet;
    bool m_Parallel_tool_calls;
    bool m_Parallel_tool_callsIsSet;
    
};

} // namespace org::openapitools::server::model

#endif /* FineTunePreferenceRequestInput_input_H_ */
