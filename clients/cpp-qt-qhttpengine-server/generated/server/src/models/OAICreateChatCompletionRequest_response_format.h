/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * OAICreateChatCompletionRequest_response_format.h
 *
 * An object specifying the format that the model must output.  Setting to &#x60;{ \&quot;type\&quot;: \&quot;json_schema\&quot;, \&quot;json_schema\&quot;: {...} }&#x60; enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).  Setting to &#x60;{ \&quot;type\&quot;: \&quot;json_object\&quot; }&#x60; enables JSON mode, which ensures the message the model generates is valid JSON.  **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \&quot;stuck\&quot; request. Also note that the message content may be partially cut off if &#x60;finish_reason&#x3D;\&quot;length\&quot;&#x60;, which indicates the generation exceeded &#x60;max_tokens&#x60; or the conversation exceeded the max context length. 
 */

#ifndef OAICreateChatCompletionRequest_response_format_H
#define OAICreateChatCompletionRequest_response_format_H

#include <QJsonObject>

#include "OAIResponseFormatJsonObject.h"
#include "OAIResponseFormatJsonSchema.h"
#include "OAIResponseFormatJsonSchema_json_schema.h"
#include "OAIResponseFormatText.h"
#include <QString>

#include "OAIEnum.h"
#include "OAIObject.h"

namespace OpenAPI {

class OAICreateChatCompletionRequest_response_format : public OAIObject {
public:
    OAICreateChatCompletionRequest_response_format();
    OAICreateChatCompletionRequest_response_format(QString json);
    ~OAICreateChatCompletionRequest_response_format() override;

    QString asJson() const override;
    QJsonObject asJsonObject() const override;
    void fromJsonObject(QJsonObject json) override;
    void fromJson(QString jsonString) override;

    QString getType() const;
    void setType(const QString &type);
    bool is_type_Set() const;
    bool is_type_Valid() const;

    OAIResponseFormatJsonSchema_json_schema getJsonSchema() const;
    void setJsonSchema(const OAIResponseFormatJsonSchema_json_schema &json_schema);
    bool is_json_schema_Set() const;
    bool is_json_schema_Valid() const;

    virtual bool isSet() const override;
    virtual bool isValid() const override;

private:
    void initializeModel();

    QString type;
    bool m_type_isSet;
    bool m_type_isValid;

    OAIResponseFormatJsonSchema_json_schema json_schema;
    bool m_json_schema_isSet;
    bool m_json_schema_isValid;
};

} // namespace OpenAPI

Q_DECLARE_METATYPE(OpenAPI::OAICreateChatCompletionRequest_response_format)

#endif // OAICreateChatCompletionRequest_response_format_H
