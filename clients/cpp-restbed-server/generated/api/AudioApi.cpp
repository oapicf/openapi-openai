/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.0.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.4.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


#include <corvusoft/restbed/byte.hpp>
#include <corvusoft/restbed/string.hpp>
#include <corvusoft/restbed/settings.hpp>
#include <corvusoft/restbed/request.hpp>
#include <corvusoft/restbed/uri.hpp>
#include <boost/property_tree/ptree.hpp>
#include <boost/property_tree/json_parser.hpp>
#include <boost/lexical_cast.hpp>
#include <boost/algorithm/string.hpp>

#include "AudioApi.h"

namespace org {
namespace openapitools {
namespace server {
namespace api {

using namespace org::openapitools::server::model;

namespace {
[[maybe_unused]]
std::string selectPreferredContentType(const std::vector<std::string>& contentTypes) {
    if (contentTypes.size() == 0) {
        return "application/json";
    }

    if (contentTypes.size() == 1) {
        return contentTypes.at(0);
    }

    static const std::array<std::string, 2> preferredTypes = {"json", "xml"};
    for (const auto& preferredType: preferredTypes) {
        const auto ret = std::find_if(contentTypes.cbegin(),
        contentTypes.cend(),
        [preferredType](const std::string& str) {
            return str.find(preferredType) != std::string::npos;});
        if (ret != contentTypes.cend()) {
            return *ret;
        }
    }

    return contentTypes.at(0);
}
}

AudioApiException::AudioApiException(int status_code, std::string what)
  : m_status(status_code),
    m_what(what)
{

}
int AudioApiException::getStatus() const
{
    return m_status;
}
const char* AudioApiException::what() const noexcept
{
    return m_what.c_str();
}


template<class MODEL_T>
MODEL_T extractJsonModelBodyParam(const std::string& bodyContent)
{
    std::stringstream sstream(bodyContent);
    boost::property_tree::ptree pt;
    boost::property_tree::json_parser::read_json(sstream, pt);

    auto model = MODEL_T(pt);
    return model;
}

template<class MODEL_T>
std::vector<MODEL_T> extractJsonArrayBodyParam(const std::string& bodyContent)
{
    std::stringstream sstream(bodyContent);
    boost::property_tree::ptree pt;
    boost::property_tree::json_parser::read_json(sstream, pt);

    auto arrayRet = std::vector<MODEL_T>();
    for (const auto& child: pt) {
        arrayRet.emplace_back(MODEL_T(child.second));
    }
    return arrayRet;
}

template <class KEY_T, class VAL_T>
std::string convertMapResponse(const std::map<KEY_T, VAL_T>& map)
{
    boost::property_tree::ptree pt;
    for(const auto &kv: map) {
    pt.push_back(boost::property_tree::ptree::value_type(
        boost::lexical_cast<std::string>(kv.first),
        boost::property_tree::ptree(
        boost::lexical_cast<std::string>(kv.second))));
    }
    std::stringstream sstream;
    write_json(sstream, pt);
    std::string result = sstream.str();
    return result;
}

namespace AudioApiResources {
AudioSpeechResource::AudioSpeechResource(const std::string& context /* = "/v1" */)
{
	this->set_path(context + "/audio/speech");
	this->set_method_handler("POST",
		std::bind(&AudioSpeechResource::handler_POST_internal, this,
			std::placeholders::_1));
}

std::pair<int, std::string> AudioSpeechResource::handleAudioApiException(const AudioApiException& e)
{
    return std::make_pair<int, std::string>(e.getStatus(), e.what());
}

std::pair<int, std::string> AudioSpeechResource::handleStdException(const std::exception& e)
{
    return std::make_pair<int, std::string>(500, e.what());
}

std::pair<int, std::string> AudioSpeechResource::handleUnspecifiedException()
{
    return std::make_pair<int, std::string>(500, "Unknown exception occurred");
}

void AudioSpeechResource::setResponseHeader(const std::shared_ptr<restbed::Session>& session, const std::string& header)
{
    session->set_header(header, "");
}

void AudioSpeechResource::returnResponse(const std::shared_ptr<restbed::Session>& session, const int status, const std::string& result, std::multimap<std::string, std::string>& responseHeaders)
{
    responseHeaders.insert(std::make_pair("Connection", "close"));
    session->close(status, result, responseHeaders);
}

void AudioSpeechResource::defaultSessionClose(const std::shared_ptr<restbed::Session>& session, const int status, const std::string& result)
{
    session->close(status, result, { {"Connection", "close"} });
}

void AudioSpeechResource::handler_POST_internal(const std::shared_ptr<restbed::Session> session)
{
    const auto request = session->get_request();
    // body params or form params here from the body content string
    std::string bodyContent = extractBodyContent(session);
    auto createSpeechRequest = extractJsonModelBodyParam<CreateSpeechRequest>(bodyContent);
    
    int status_code = 500;
    std::string resultObject = "";
    std::string result = "";
    
    try {
        std::tie(status_code, resultObject) =
            handler_POST(createSpeechRequest);
    }
    catch(const AudioApiException& e) {
        std::tie(status_code, result) = handleAudioApiException(e);
    }
    catch(const std::exception& e) {
        std::tie(status_code, result) = handleStdException(e);
    }
    catch(...) {
        std::tie(status_code, result) = handleUnspecifiedException();
    }
    
    std::multimap< std::string, std::string > responseHeaders {};
    static const std::vector<std::string> contentTypes{
        "application/octet-stream",
    };
    static const std::string acceptTypes{
        "application/json, "
    };
    
    if (status_code == 200) {
        responseHeaders.insert(std::make_pair("Content-Type", selectPreferredContentType(contentTypes)));
        if (!acceptTypes.empty()) {
            responseHeaders.insert(std::make_pair("Accept", acceptTypes));
        }
    
        result = resultObject.toJsonString();
        // Description: chunked
        setResponseHeader(session, "Transfer-Encoding");
        returnResponse(session, 200, result.empty() ? "{}" : result, responseHeaders);
        return;
    }
    defaultSessionClose(session, status_code, result);
    
    
}


std::pair<int, std::string> AudioSpeechResource::handler_POST(
        CreateSpeechRequest & createSpeechRequest)
{
    return handler_POST_func(createSpeechRequest);
}


std::string AudioSpeechResource::extractBodyContent(const std::shared_ptr<restbed::Session>& session) {
  const auto request = session->get_request();
  int content_length = request->get_header("Content-Length", 0);
  std::string bodyContent;
  session->fetch(content_length,
                 [&bodyContent](const std::shared_ptr<restbed::Session> session,
                                const restbed::Bytes &body) {
                   bodyContent = restbed::String::format(
                       "%.*s\n", (int)body.size(), body.data());
                 });
  return bodyContent;
}

std::string AudioSpeechResource::extractFormParamsFromBody(const std::string& paramName, const std::string& body) {
    const auto uri = restbed::Uri("urlencoded?" + body, true);
    const auto params = uri.get_query_parameters();
    const auto result = params.find(paramName);
    if (result != params.cend()) {
        return result->second;
    }
    return "";
}
AudioTranscriptionsResource::AudioTranscriptionsResource(const std::string& context /* = "/v1" */)
{
	this->set_path(context + "/audio/transcriptions");
	this->set_method_handler("POST",
		std::bind(&AudioTranscriptionsResource::handler_POST_internal, this,
			std::placeholders::_1));
}

std::pair<int, std::string> AudioTranscriptionsResource::handleAudioApiException(const AudioApiException& e)
{
    return std::make_pair<int, std::string>(e.getStatus(), e.what());
}

std::pair<int, std::string> AudioTranscriptionsResource::handleStdException(const std::exception& e)
{
    return std::make_pair<int, std::string>(500, e.what());
}

std::pair<int, std::string> AudioTranscriptionsResource::handleUnspecifiedException()
{
    return std::make_pair<int, std::string>(500, "Unknown exception occurred");
}

void AudioTranscriptionsResource::setResponseHeader(const std::shared_ptr<restbed::Session>& session, const std::string& header)
{
    session->set_header(header, "");
}

void AudioTranscriptionsResource::returnResponse(const std::shared_ptr<restbed::Session>& session, const int status, const std::string& result, std::multimap<std::string, std::string>& responseHeaders)
{
    responseHeaders.insert(std::make_pair("Connection", "close"));
    session->close(status, result, responseHeaders);
}

void AudioTranscriptionsResource::defaultSessionClose(const std::shared_ptr<restbed::Session>& session, const int status, const std::string& result)
{
    session->close(status, result, { {"Connection", "close"} });
}

void AudioTranscriptionsResource::handler_POST_internal(const std::shared_ptr<restbed::Session> session)
{
    const auto request = session->get_request();
    auto file = boost::lexical_cast<std::string>(extractFormParamsFromBody("file", extractBodyContent(session)));
    auto model = boost::lexical_cast<CreateTranscriptionRequest_model>(extractFormParamsFromBody("model", extractBodyContent(session)));
    auto language = boost::lexical_cast<std::string>(extractFormParamsFromBody("language", extractBodyContent(session)));
    auto prompt = boost::lexical_cast<std::string>(extractFormParamsFromBody("prompt", extractBodyContent(session)));
    auto responseFormat = boost::lexical_cast<std::string>(extractFormParamsFromBody("responseFormat", extractBodyContent(session)));
    auto temperature = boost::lexical_cast<double>(extractFormParamsFromBody("temperature", extractBodyContent(session)));
    std::string timestampGranularitiesLeft_Square_BracketRight_Square_Bracket_raw = extractFormParamsFromBody("timestampGranularitiesLeft_Square_BracketRight_Square_Bracket", extractBodyContent(session));
    std::vector<std::string> timestampGranularitiesLeft_Square_BracketRight_Square_Bracket;
    boost::split(timestampGranularitiesLeft_Square_BracketRight_Square_Bracket, timestampGranularitiesLeft_Square_BracketRight_Square_Bracket_raw, boost::is_any_of(","));
    
    int status_code = 500;
    CreateTranscription_200_response resultObject = CreateTranscription_200_response{};
    std::string result = "";
    
    try {
        std::tie(status_code, resultObject) =
            handler_POST(file, model, language, prompt, responseFormat, temperature, timestampGranularitiesLeft_Square_BracketRight_Square_Bracket);
    }
    catch(const AudioApiException& e) {
        std::tie(status_code, result) = handleAudioApiException(e);
    }
    catch(const std::exception& e) {
        std::tie(status_code, result) = handleStdException(e);
    }
    catch(...) {
        std::tie(status_code, result) = handleUnspecifiedException();
    }
    
    std::multimap< std::string, std::string > responseHeaders {};
    static const std::vector<std::string> contentTypes{
        "application/json",
    };
    static const std::string acceptTypes{
        "multipart/form-data, "
    };
    
    if (status_code == 200) {
        responseHeaders.insert(std::make_pair("Content-Type", selectPreferredContentType(contentTypes)));
        if (!acceptTypes.empty()) {
            responseHeaders.insert(std::make_pair("Accept", acceptTypes));
        }
    
        result = resultObject.toJsonString();
        returnResponse(session, 200, result.empty() ? "{}" : result, responseHeaders);
        return;
    }
    defaultSessionClose(session, status_code, result);
    
    
}


std::pair<int, CreateTranscription_200_response> AudioTranscriptionsResource::handler_POST(
        std::string & file, CreateTranscriptionRequest_model & model, std::string & language, std::string & prompt, std::string & responseFormat, double & temperature, std::vector<std::string> & timestampGranularitiesLeft_Square_BracketRight_Square_Bracket)
{
    return handler_POST_func(file, model, language, prompt, responseFormat, temperature, timestampGranularitiesLeft_Square_BracketRight_Square_Bracket);
}


std::string AudioTranscriptionsResource::extractBodyContent(const std::shared_ptr<restbed::Session>& session) {
  const auto request = session->get_request();
  int content_length = request->get_header("Content-Length", 0);
  std::string bodyContent;
  session->fetch(content_length,
                 [&bodyContent](const std::shared_ptr<restbed::Session> session,
                                const restbed::Bytes &body) {
                   bodyContent = restbed::String::format(
                       "%.*s\n", (int)body.size(), body.data());
                 });
  return bodyContent;
}

std::string AudioTranscriptionsResource::extractFormParamsFromBody(const std::string& paramName, const std::string& body) {
    const auto uri = restbed::Uri("urlencoded?" + body, true);
    const auto params = uri.get_query_parameters();
    const auto result = params.find(paramName);
    if (result != params.cend()) {
        return result->second;
    }
    return "";
}
AudioTranslationsResource::AudioTranslationsResource(const std::string& context /* = "/v1" */)
{
	this->set_path(context + "/audio/translations");
	this->set_method_handler("POST",
		std::bind(&AudioTranslationsResource::handler_POST_internal, this,
			std::placeholders::_1));
}

std::pair<int, std::string> AudioTranslationsResource::handleAudioApiException(const AudioApiException& e)
{
    return std::make_pair<int, std::string>(e.getStatus(), e.what());
}

std::pair<int, std::string> AudioTranslationsResource::handleStdException(const std::exception& e)
{
    return std::make_pair<int, std::string>(500, e.what());
}

std::pair<int, std::string> AudioTranslationsResource::handleUnspecifiedException()
{
    return std::make_pair<int, std::string>(500, "Unknown exception occurred");
}

void AudioTranslationsResource::setResponseHeader(const std::shared_ptr<restbed::Session>& session, const std::string& header)
{
    session->set_header(header, "");
}

void AudioTranslationsResource::returnResponse(const std::shared_ptr<restbed::Session>& session, const int status, const std::string& result, std::multimap<std::string, std::string>& responseHeaders)
{
    responseHeaders.insert(std::make_pair("Connection", "close"));
    session->close(status, result, responseHeaders);
}

void AudioTranslationsResource::defaultSessionClose(const std::shared_ptr<restbed::Session>& session, const int status, const std::string& result)
{
    session->close(status, result, { {"Connection", "close"} });
}

void AudioTranslationsResource::handler_POST_internal(const std::shared_ptr<restbed::Session> session)
{
    const auto request = session->get_request();
    auto file = boost::lexical_cast<std::string>(extractFormParamsFromBody("file", extractBodyContent(session)));
    auto model = boost::lexical_cast<CreateTranscriptionRequest_model>(extractFormParamsFromBody("model", extractBodyContent(session)));
    auto prompt = boost::lexical_cast<std::string>(extractFormParamsFromBody("prompt", extractBodyContent(session)));
    auto responseFormat = boost::lexical_cast<std::string>(extractFormParamsFromBody("responseFormat", extractBodyContent(session)));
    auto temperature = boost::lexical_cast<double>(extractFormParamsFromBody("temperature", extractBodyContent(session)));
    
    int status_code = 500;
    CreateTranslation_200_response resultObject = CreateTranslation_200_response{};
    std::string result = "";
    
    try {
        std::tie(status_code, resultObject) =
            handler_POST(file, model, prompt, responseFormat, temperature);
    }
    catch(const AudioApiException& e) {
        std::tie(status_code, result) = handleAudioApiException(e);
    }
    catch(const std::exception& e) {
        std::tie(status_code, result) = handleStdException(e);
    }
    catch(...) {
        std::tie(status_code, result) = handleUnspecifiedException();
    }
    
    std::multimap< std::string, std::string > responseHeaders {};
    static const std::vector<std::string> contentTypes{
        "application/json",
    };
    static const std::string acceptTypes{
        "multipart/form-data, "
    };
    
    if (status_code == 200) {
        responseHeaders.insert(std::make_pair("Content-Type", selectPreferredContentType(contentTypes)));
        if (!acceptTypes.empty()) {
            responseHeaders.insert(std::make_pair("Accept", acceptTypes));
        }
    
        result = resultObject.toJsonString();
        returnResponse(session, 200, result.empty() ? "{}" : result, responseHeaders);
        return;
    }
    defaultSessionClose(session, status_code, result);
    
    
}


std::pair<int, CreateTranslation_200_response> AudioTranslationsResource::handler_POST(
        std::string & file, CreateTranscriptionRequest_model & model, std::string & prompt, std::string & responseFormat, double & temperature)
{
    return handler_POST_func(file, model, prompt, responseFormat, temperature);
}


std::string AudioTranslationsResource::extractBodyContent(const std::shared_ptr<restbed::Session>& session) {
  const auto request = session->get_request();
  int content_length = request->get_header("Content-Length", 0);
  std::string bodyContent;
  session->fetch(content_length,
                 [&bodyContent](const std::shared_ptr<restbed::Session> session,
                                const restbed::Bytes &body) {
                   bodyContent = restbed::String::format(
                       "%.*s\n", (int)body.size(), body.data());
                 });
  return bodyContent;
}

std::string AudioTranslationsResource::extractFormParamsFromBody(const std::string& paramName, const std::string& body) {
    const auto uri = restbed::Uri("urlencoded?" + body, true);
    const auto params = uri.get_query_parameters();
    const auto result = params.find(paramName);
    if (result != params.cend()) {
        return result->second;
    }
    return "";
}

} /* namespace AudioApiResources */

AudioApi::AudioApi(std::shared_ptr<restbed::Service> const& restbedService)
: m_service(restbedService)
{
}

AudioApi::~AudioApi() {}

std::shared_ptr<AudioApiResources::AudioSpeechResource> AudioApi::getAudioSpeechResource() {
    if (!m_spAudioSpeechResource) {
        setResource(std::make_shared<AudioApiResources::AudioSpeechResource>());
    }
    return m_spAudioSpeechResource;
}
std::shared_ptr<AudioApiResources::AudioTranscriptionsResource> AudioApi::getAudioTranscriptionsResource() {
    if (!m_spAudioTranscriptionsResource) {
        setResource(std::make_shared<AudioApiResources::AudioTranscriptionsResource>());
    }
    return m_spAudioTranscriptionsResource;
}
std::shared_ptr<AudioApiResources::AudioTranslationsResource> AudioApi::getAudioTranslationsResource() {
    if (!m_spAudioTranslationsResource) {
        setResource(std::make_shared<AudioApiResources::AudioTranslationsResource>());
    }
    return m_spAudioTranslationsResource;
}
void AudioApi::setResource(std::shared_ptr<AudioApiResources::AudioSpeechResource> resource) {
    m_spAudioSpeechResource = resource;
    m_service->publish(m_spAudioSpeechResource);
}
void AudioApi::setResource(std::shared_ptr<AudioApiResources::AudioTranscriptionsResource> resource) {
    m_spAudioTranscriptionsResource = resource;
    m_service->publish(m_spAudioTranscriptionsResource);
}
void AudioApi::setResource(std::shared_ptr<AudioApiResources::AudioTranslationsResource> resource) {
    m_spAudioTranslationsResource = resource;
    m_service->publish(m_spAudioTranslationsResource);
}
void AudioApi::setAudioApiAudioSpeechResource(std::shared_ptr<AudioApiResources::AudioSpeechResource> spAudioSpeechResource) {
    m_spAudioSpeechResource = spAudioSpeechResource;
    m_service->publish(m_spAudioSpeechResource);
}
void AudioApi::setAudioApiAudioTranscriptionsResource(std::shared_ptr<AudioApiResources::AudioTranscriptionsResource> spAudioTranscriptionsResource) {
    m_spAudioTranscriptionsResource = spAudioTranscriptionsResource;
    m_service->publish(m_spAudioTranscriptionsResource);
}
void AudioApi::setAudioApiAudioTranslationsResource(std::shared_ptr<AudioApiResources::AudioTranslationsResource> spAudioTranslationsResource) {
    m_spAudioTranslationsResource = spAudioTranslationsResource;
    m_service->publish(m_spAudioTranslationsResource);
}


void AudioApi::publishDefaultResources() {
    if (!m_spAudioSpeechResource) {
        setResource(std::make_shared<AudioApiResources::AudioSpeechResource>());
    }
    if (!m_spAudioTranscriptionsResource) {
        setResource(std::make_shared<AudioApiResources::AudioTranscriptionsResource>());
    }
    if (!m_spAudioTranslationsResource) {
        setResource(std::make_shared<AudioApiResources::AudioTranslationsResource>());
    }
}

std::shared_ptr<restbed::Service> AudioApi::service() {
    return m_service;
}


}
}
}
}

