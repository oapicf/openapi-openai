/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.18.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * AssistantsApiResponseFormatOption.h
 *
 * Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since &#x60;gpt-3.5-turbo-1106&#x60;.  Setting to &#x60;{ \&quot;type\&quot;: \&quot;json_schema\&quot;, \&quot;json_schema\&quot;: {...} }&#x60; enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).  Setting to &#x60;{ \&quot;type\&quot;: \&quot;json_object\&quot; }&#x60; enables JSON mode, which ensures the message the model generates is valid JSON.  **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \&quot;stuck\&quot; request. Also note that the message content may be partially cut off if &#x60;finish_reason&#x3D;\&quot;length\&quot;&#x60;, which indicates the generation exceeded &#x60;max_tokens&#x60; or the conversation exceeded the max context length. 
 */

#ifndef AssistantsApiResponseFormatOption_H_
#define AssistantsApiResponseFormatOption_H_



#include <string>
#include "ResponseFormatJsonSchema.h"
#include "ResponseFormatText.h"
#include "ResponseFormatJsonObject.h"
#include "ResponseFormatJsonSchema_json_schema.h"
#include <memory>
#include <vector>
#include <array>
#include <boost/property_tree/ptree.hpp>
#include "ResponseFormatText.h"
#include "ResponseFormatJsonObject.h"
#include "ResponseFormatJsonSchema.h"
#include "helpers.h"

namespace org {
namespace openapitools {
namespace server {
namespace model {

/// <summary>
/// Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since &#x60;gpt-3.5-turbo-1106&#x60;.  Setting to &#x60;{ \&quot;type\&quot;: \&quot;json_schema\&quot;, \&quot;json_schema\&quot;: {...} }&#x60; enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).  Setting to &#x60;{ \&quot;type\&quot;: \&quot;json_object\&quot; }&#x60; enables JSON mode, which ensures the message the model generates is valid JSON.  **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \&quot;stuck\&quot; request. Also note that the message content may be partially cut off if &#x60;finish_reason&#x3D;\&quot;length\&quot;&#x60;, which indicates the generation exceeded &#x60;max_tokens&#x60; or the conversation exceeded the max context length. 
/// </summary>
class  AssistantsApiResponseFormatOption : public ResponseFormatText, public ResponseFormatJsonObject, public ResponseFormatJsonSchema
{
public:
    AssistantsApiResponseFormatOption() = default;
    explicit AssistantsApiResponseFormatOption(boost::property_tree::ptree const& pt);
    virtual ~AssistantsApiResponseFormatOption() = default;

    AssistantsApiResponseFormatOption(const AssistantsApiResponseFormatOption& other) = default; // copy constructor
    AssistantsApiResponseFormatOption(AssistantsApiResponseFormatOption&& other) noexcept = default; // move constructor

    AssistantsApiResponseFormatOption& operator=(const AssistantsApiResponseFormatOption& other) = default; // copy assignment
    AssistantsApiResponseFormatOption& operator=(AssistantsApiResponseFormatOption&& other) noexcept = default; // move assignment

    std::string toJsonString(bool prettyJson = false) const;
    void fromJsonString(std::string const& jsonString);
    boost::property_tree::ptree toPropertyTree() const;
    void fromPropertyTree(boost::property_tree::ptree const& pt);


    /////////////////////////////////////////////
    /// AssistantsApiResponseFormatOption members

    /// <summary>
    /// The type of response format being defined: &#x60;text&#x60;
    /// </summary>
    std::string getType() const;
    void setType(std::string value);

    /// <summary>
    /// 
    /// </summary>
    ResponseFormatJsonSchema_json_schema getJsonSchema() const;
    void setJsonSchema(ResponseFormatJsonSchema_json_schema value);

protected:
    std::string m_Type = "";
    ResponseFormatJsonSchema_json_schema m_Json_schema;
};

std::vector<AssistantsApiResponseFormatOption> createAssistantsApiResponseFormatOptionVectorFromJsonString(const std::string& json);

template<>
inline boost::property_tree::ptree toPt<AssistantsApiResponseFormatOption>(const AssistantsApiResponseFormatOption& val) {
    return val.toPropertyTree();
}

template<>
inline AssistantsApiResponseFormatOption fromPt<AssistantsApiResponseFormatOption>(const boost::property_tree::ptree& pt) {
    AssistantsApiResponseFormatOption ret;
    ret.fromPropertyTree(pt);
    return ret;
}

}
}
}
}

#endif /* AssistantsApiResponseFormatOption_H_ */
