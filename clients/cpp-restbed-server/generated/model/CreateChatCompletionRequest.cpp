/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.18.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */



#include "CreateChatCompletionRequest.h"

#include <string>
#include <vector>
#include <map>
#include <sstream>
#include <stdexcept>
#include <regex>
#include <algorithm>
#include <boost/lexical_cast.hpp>
#include <boost/property_tree/ptree.hpp>
#include <boost/property_tree/json_parser.hpp>
#include "helpers.h"

using boost::property_tree::ptree;
using boost::property_tree::read_json;
using boost::property_tree::write_json;

namespace org {
namespace openapitools {
namespace server {
namespace model {

CreateChatCompletionRequest::CreateChatCompletionRequest(boost::property_tree::ptree const& pt)
{
        fromPropertyTree(pt);
}


std::string CreateChatCompletionRequest::toJsonString(bool prettyJson /* = false */) const
{
	std::stringstream ss;
	write_json(ss, this->toPropertyTree(), prettyJson);
    // workaround inspired by: https://stackoverflow.com/a/56395440
    std::regex reg("\\\"([0-9]+\\.{0,1}[0-9]*)\\\"");
    std::string result = std::regex_replace(ss.str(), reg, "$1");
    return result;
}

void CreateChatCompletionRequest::fromJsonString(std::string const& jsonString)
{
	std::stringstream ss(jsonString);
	ptree pt;
	read_json(ss,pt);
	this->fromPropertyTree(pt);
}

ptree CreateChatCompletionRequest::toPropertyTree() const
{
	ptree pt;
	ptree tmp_node;
	// generate tree for Messages
    tmp_node.clear();
	if (!m_Messages.empty()) {
        tmp_node = toPt(m_Messages);
		pt.add_child("messages", tmp_node);
		tmp_node.clear();
	}
	pt.add_child("model", m_Model.toPropertyTree());
	pt.put("store", m_Store);
	pt.put("reasoning_effort", m_Reasoning_effort);
	// generate tree for Metadata
    if (!m_Metadata.empty()) {
        tmp_node = toPt(m_Metadata);
        pt.add_child("metadata", tmp_node);
    }
    tmp_node.clear();
	pt.put("frequency_penalty", m_Frequency_penalty);
	// generate tree for Logit_bias
    if (!m_Logit_bias.empty()) {
        tmp_node = toPt(m_Logit_bias);
        pt.add_child("logit_bias", tmp_node);
    }
    tmp_node.clear();
	pt.put("logprobs", m_Logprobs);
	pt.put("top_logprobs", m_Top_logprobs);
	pt.put("max_tokens", m_Max_tokens);
	pt.put("max_completion_tokens", m_Max_completion_tokens);
	pt.put("n", m_n);
	// generate tree for Modalities
    tmp_node.clear();
	if (!m_Modalities.empty()) {
        tmp_node = toPt(m_Modalities);
		pt.add_child("modalities", tmp_node);
		tmp_node.clear();
	}
	pt.add_child("prediction", m_Prediction.toPropertyTree());
	pt.add_child("audio", m_Audio.toPropertyTree());
	pt.put("presence_penalty", m_Presence_penalty);
	pt.add_child("response_format", m_Response_format.toPropertyTree());
	pt.put("seed", m_Seed);
	pt.put("service_tier", m_Service_tier);
	pt.add_child("stop", m_Stop.toPropertyTree());
	pt.put("stream", m_Stream);
	pt.add_child("stream_options", m_Stream_options.toPropertyTree());
	pt.put("temperature", m_Temperature);
	pt.put("top_p", m_Top_p);
	// generate tree for Tools
    tmp_node.clear();
	if (!m_Tools.empty()) {
        tmp_node = toPt(m_Tools);
		pt.add_child("tools", tmp_node);
		tmp_node.clear();
	}
	pt.add_child("tool_choice", m_Tool_choice.toPropertyTree());
	pt.put("parallel_tool_calls", m_Parallel_tool_calls);
	pt.put("user", m_User);
	pt.add_child("function_call", m_Function_call.toPropertyTree());
	// generate tree for Functions
    tmp_node.clear();
	if (!m_Functions.empty()) {
        tmp_node = toPt(m_Functions);
		pt.add_child("functions", tmp_node);
		tmp_node.clear();
	}
	return pt;
}

void CreateChatCompletionRequest::fromPropertyTree(ptree const &pt)
{
	ptree tmp_node;
	// push all items of Messages into member
	if (pt.get_child_optional("messages")) {
        m_Messages = fromPt<std::vector<ChatCompletionRequestMessage>>(pt.get_child("messages"));
	}
	if (pt.get_child_optional("model")) {
        m_Model = fromPt<CreateChatCompletionRequest_model>(pt.get_child("model"));
	}
	m_Store = pt.get("store", false);
	setReasoningEffort(pt.get("reasoning_effort", "medium"));
    if (pt.get_child_optional("metadata")) {
        m_Metadata = fromPt<std::map<std::string, std::string>>(pt.get_child("metadata"));
    }
	m_Frequency_penalty = pt.get("frequency_penalty", 0);
    if (pt.get_child_optional("logit_bias")) {
        m_Logit_bias = fromPt<std::map<std::string, int32_t>>(pt.get_child("logit_bias"));
    }
	m_Logprobs = pt.get("logprobs", false);
	m_Top_logprobs = pt.get("top_logprobs", 0);
	m_Max_tokens = pt.get("max_tokens", 0);
	m_Max_completion_tokens = pt.get("max_completion_tokens", 0);
	m_n = pt.get("n", 1);
	// push all items of Modalities into member
	if (pt.get_child_optional("modalities")) {
        m_Modalities = fromPt<std::vector<std::string>>(pt.get_child("modalities"));
	}
	if (pt.get_child_optional("prediction")) {
        m_Prediction = fromPt<PredictionContent>(pt.get_child("prediction"));
	}
	if (pt.get_child_optional("audio")) {
        m_Audio = fromPt<CreateChatCompletionRequest_audio>(pt.get_child("audio"));
	}
	m_Presence_penalty = pt.get("presence_penalty", 0);
	if (pt.get_child_optional("response_format")) {
        m_Response_format = fromPt<CreateChatCompletionRequest_response_format>(pt.get_child("response_format"));
	}
	m_Seed = pt.get("seed", 0);
	setServiceTier(pt.get("service_tier", "auto"));
	if (pt.get_child_optional("stop")) {
        m_Stop = fromPt<CreateChatCompletionRequest_stop>(pt.get_child("stop"));
	}
	m_Stream = pt.get("stream", false);
	if (pt.get_child_optional("stream_options")) {
        m_Stream_options = fromPt<ChatCompletionStreamOptions>(pt.get_child("stream_options"));
	}
	m_Temperature = pt.get("temperature", 1);
	m_Top_p = pt.get("top_p", 1);
	// push all items of Tools into member
	if (pt.get_child_optional("tools")) {
        m_Tools = fromPt<std::vector<ChatCompletionTool>>(pt.get_child("tools"));
	}
	if (pt.get_child_optional("tool_choice")) {
        m_Tool_choice = fromPt<ChatCompletionToolChoiceOption>(pt.get_child("tool_choice"));
	}
	m_Parallel_tool_calls = pt.get("parallel_tool_calls", true);
	m_User = pt.get("user", "");
	if (pt.get_child_optional("function_call")) {
        m_Function_call = fromPt<CreateChatCompletionRequest_function_call>(pt.get_child("function_call"));
	}
	// push all items of Functions into member
	if (pt.get_child_optional("functions")) {
        m_Functions = fromPt<std::vector<ChatCompletionFunctions>>(pt.get_child("functions"));
	}
}

std::vector<ChatCompletionRequestMessage> CreateChatCompletionRequest::getMessages() const
{
    return m_Messages;
}

void CreateChatCompletionRequest::setMessages(std::vector<ChatCompletionRequestMessage> value)
{
    m_Messages = value;
}


CreateChatCompletionRequest_model CreateChatCompletionRequest::getModel() const
{
    return m_Model;
}

void CreateChatCompletionRequest::setModel(CreateChatCompletionRequest_model value)
{
    m_Model = value;
}


bool CreateChatCompletionRequest::isStore() const
{
    return m_Store;
}

void CreateChatCompletionRequest::setStore(bool value)
{
    m_Store = value;
}


std::string CreateChatCompletionRequest::getReasoningEffort() const
{
    return m_Reasoning_effort;
}

void CreateChatCompletionRequest::setReasoningEffort(std::string value)
{
    static const std::array<std::string, 3> allowedValues = {
        "low", "medium", "high"
    };

    if (std::find(allowedValues.begin(), allowedValues.end(), value) != allowedValues.end()) {
		m_Reasoning_effort = value;
	} else {
		throw std::runtime_error("Value " + boost::lexical_cast<std::string>(value) + " not allowed");
	}
}


std::map<std::string, std::string> CreateChatCompletionRequest::getMetadata() const
{
    return m_Metadata;
}

void CreateChatCompletionRequest::setMetadata(std::map<std::string, std::string> value)
{
    m_Metadata = value;
}


double CreateChatCompletionRequest::getFrequencyPenalty() const
{
    return m_Frequency_penalty;
}

void CreateChatCompletionRequest::setFrequencyPenalty(double value)
{
    m_Frequency_penalty = value;
}


std::map<std::string, int32_t> CreateChatCompletionRequest::getLogitBias() const
{
    return m_Logit_bias;
}

void CreateChatCompletionRequest::setLogitBias(std::map<std::string, int32_t> value)
{
    m_Logit_bias = value;
}


bool CreateChatCompletionRequest::isLogprobs() const
{
    return m_Logprobs;
}

void CreateChatCompletionRequest::setLogprobs(bool value)
{
    m_Logprobs = value;
}


int32_t CreateChatCompletionRequest::getTopLogprobs() const
{
    return m_Top_logprobs;
}

void CreateChatCompletionRequest::setTopLogprobs(int32_t value)
{
    m_Top_logprobs = value;
}


int32_t CreateChatCompletionRequest::getMaxTokens() const
{
    return m_Max_tokens;
}

void CreateChatCompletionRequest::setMaxTokens(int32_t value)
{
    m_Max_tokens = value;
}


int32_t CreateChatCompletionRequest::getMaxCompletionTokens() const
{
    return m_Max_completion_tokens;
}

void CreateChatCompletionRequest::setMaxCompletionTokens(int32_t value)
{
    m_Max_completion_tokens = value;
}


int32_t CreateChatCompletionRequest::getN() const
{
    return m_n;
}

void CreateChatCompletionRequest::setN(int32_t value)
{
    m_n = value;
}


std::vector<std::string> CreateChatCompletionRequest::getModalities() const
{
    return m_Modalities;
}

void CreateChatCompletionRequest::setModalities(std::vector<std::string> value)
{
    static const std::array<std::string, 2> allowedValues = {
        "text", "audio"
    };

    for (const auto &v: value) {
        if (std::find(allowedValues.begin(), allowedValues.end(), v) == allowedValues.end()) {
            throw std::runtime_error("Value " + boost::lexical_cast<std::string>(v) + " not allowed");
        }
    }
}


PredictionContent CreateChatCompletionRequest::getPrediction() const
{
    return m_Prediction;
}

void CreateChatCompletionRequest::setPrediction(PredictionContent value)
{
    m_Prediction = value;
}


CreateChatCompletionRequest_audio CreateChatCompletionRequest::getAudio() const
{
    return m_Audio;
}

void CreateChatCompletionRequest::setAudio(CreateChatCompletionRequest_audio value)
{
    m_Audio = value;
}


double CreateChatCompletionRequest::getPresencePenalty() const
{
    return m_Presence_penalty;
}

void CreateChatCompletionRequest::setPresencePenalty(double value)
{
    m_Presence_penalty = value;
}


CreateChatCompletionRequest_response_format CreateChatCompletionRequest::getResponseFormat() const
{
    return m_Response_format;
}

void CreateChatCompletionRequest::setResponseFormat(CreateChatCompletionRequest_response_format value)
{
    m_Response_format = value;
}


int32_t CreateChatCompletionRequest::getSeed() const
{
    return m_Seed;
}

void CreateChatCompletionRequest::setSeed(int32_t value)
{
    m_Seed = value;
}


std::string CreateChatCompletionRequest::getServiceTier() const
{
    return m_Service_tier;
}

void CreateChatCompletionRequest::setServiceTier(std::string value)
{
    static const std::array<std::string, 2> allowedValues = {
        "auto", "default"
    };

    if (std::find(allowedValues.begin(), allowedValues.end(), value) != allowedValues.end()) {
		m_Service_tier = value;
	} else {
		throw std::runtime_error("Value " + boost::lexical_cast<std::string>(value) + " not allowed");
	}
}


CreateChatCompletionRequest_stop CreateChatCompletionRequest::getStop() const
{
    return m_Stop;
}

void CreateChatCompletionRequest::setStop(CreateChatCompletionRequest_stop value)
{
    m_Stop = value;
}


bool CreateChatCompletionRequest::isStream() const
{
    return m_Stream;
}

void CreateChatCompletionRequest::setStream(bool value)
{
    m_Stream = value;
}


ChatCompletionStreamOptions CreateChatCompletionRequest::getStreamOptions() const
{
    return m_Stream_options;
}

void CreateChatCompletionRequest::setStreamOptions(ChatCompletionStreamOptions value)
{
    m_Stream_options = value;
}


double CreateChatCompletionRequest::getTemperature() const
{
    return m_Temperature;
}

void CreateChatCompletionRequest::setTemperature(double value)
{
    m_Temperature = value;
}


double CreateChatCompletionRequest::getTopP() const
{
    return m_Top_p;
}

void CreateChatCompletionRequest::setTopP(double value)
{
    m_Top_p = value;
}


std::vector<ChatCompletionTool> CreateChatCompletionRequest::getTools() const
{
    return m_Tools;
}

void CreateChatCompletionRequest::setTools(std::vector<ChatCompletionTool> value)
{
    m_Tools = value;
}


ChatCompletionToolChoiceOption CreateChatCompletionRequest::getToolChoice() const
{
    return m_Tool_choice;
}

void CreateChatCompletionRequest::setToolChoice(ChatCompletionToolChoiceOption value)
{
    m_Tool_choice = value;
}


bool CreateChatCompletionRequest::isParallelToolCalls() const
{
    return m_Parallel_tool_calls;
}

void CreateChatCompletionRequest::setParallelToolCalls(bool value)
{
    m_Parallel_tool_calls = value;
}


std::string CreateChatCompletionRequest::getUser() const
{
    return m_User;
}

void CreateChatCompletionRequest::setUser(std::string value)
{
    m_User = value;
}


CreateChatCompletionRequest_function_call CreateChatCompletionRequest::getFunctionCall() const
{
    return m_Function_call;
}

void CreateChatCompletionRequest::setFunctionCall(CreateChatCompletionRequest_function_call value)
{
    m_Function_call = value;
}


std::vector<ChatCompletionFunctions> CreateChatCompletionRequest::getFunctions() const
{
    return m_Functions;
}

void CreateChatCompletionRequest::setFunctions(std::vector<ChatCompletionFunctions> value)
{
    m_Functions = value;
}



std::vector<CreateChatCompletionRequest> createCreateChatCompletionRequestVectorFromJsonString(const std::string& json)
{
    std::stringstream sstream(json);
    boost::property_tree::ptree pt;
    boost::property_tree::json_parser::read_json(sstream,pt);

    auto vec = std::vector<CreateChatCompletionRequest>();
    for (const auto& child: pt) {
        vec.emplace_back(CreateChatCompletionRequest(child.second));
    }

    return vec;
}

}
}
}
}

