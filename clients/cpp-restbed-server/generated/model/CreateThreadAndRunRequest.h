/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.0.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.4.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * CreateThreadAndRunRequest.h
 *
 * 
 */

#ifndef CreateThreadAndRunRequest_H_
#define CreateThreadAndRunRequest_H_



#include "CreateThreadRequest.h"
#include "CreateRunRequest_model.h"
#include "CreateThreadAndRunRequest_tools_inner.h"
#include "TruncationObject.h"
#include <string>
#include "AssistantsApiResponseFormatOption.h"
#include "AssistantsApiToolChoiceOption.h"
#include <vector>
#include <memory>
#include <vector>
#include <boost/property_tree/ptree.hpp>
#include "helpers.h"

namespace org {
namespace openapitools {
namespace server {
namespace model {

/// <summary>
/// 
/// </summary>
class  CreateThreadAndRunRequest 
{
public:
    CreateThreadAndRunRequest() = default;
    explicit CreateThreadAndRunRequest(boost::property_tree::ptree const& pt);
    virtual ~CreateThreadAndRunRequest() = default;

    CreateThreadAndRunRequest(const CreateThreadAndRunRequest& other) = default; // copy constructor
    CreateThreadAndRunRequest(CreateThreadAndRunRequest&& other) noexcept = default; // move constructor

    CreateThreadAndRunRequest& operator=(const CreateThreadAndRunRequest& other) = default; // copy assignment
    CreateThreadAndRunRequest& operator=(CreateThreadAndRunRequest&& other) noexcept = default; // move assignment

    std::string toJsonString(bool prettyJson = false) const;
    void fromJsonString(std::string const& jsonString);
    boost::property_tree::ptree toPropertyTree() const;
    void fromPropertyTree(boost::property_tree::ptree const& pt);


    /////////////////////////////////////////////
    /// CreateThreadAndRunRequest members

    /// <summary>
    /// The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.
    /// </summary>
    std::string getAssistantId() const;
    void setAssistantId(std::string value);

    /// <summary>
    /// 
    /// </summary>
    CreateThreadRequest getThread() const;
    void setThread(CreateThreadRequest value);

    /// <summary>
    /// 
    /// </summary>
    CreateRunRequest_model getModel() const;
    void setModel(CreateRunRequest_model value);

    /// <summary>
    /// Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.
    /// </summary>
    std::string getInstructions() const;
    void setInstructions(std::string value);

    /// <summary>
    /// Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
    /// </summary>
    std::vector<CreateThreadAndRunRequest_tools_inner> getTools() const;
    void setTools(std::vector<CreateThreadAndRunRequest_tools_inner> value);

    /// <summary>
    /// Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long. 
    /// </summary>
    std::string getMetadata() const;
    void setMetadata(std::string value);

    /// <summary>
    /// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. 
    /// </summary>
    double getTemperature() const;
    void setTemperature(double value);

    /// <summary>
    /// If &#x60;true&#x60;, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a &#x60;data: [DONE]&#x60; message. 
    /// </summary>
    bool isStream() const;
    void setStream(bool value);

    /// <summary>
    /// The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status &#x60;complete&#x60;. See &#x60;incomplete_details&#x60; for more info. 
    /// </summary>
    int32_t getMaxPromptTokens() const;
    void setMaxPromptTokens(int32_t value);

    /// <summary>
    /// The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status &#x60;incomplete&#x60;. See &#x60;incomplete_details&#x60; for more info. 
    /// </summary>
    int32_t getMaxCompletionTokens() const;
    void setMaxCompletionTokens(int32_t value);

    /// <summary>
    /// 
    /// </summary>
    TruncationObject getTruncationStrategy() const;
    void setTruncationStrategy(TruncationObject value);

    /// <summary>
    /// 
    /// </summary>
    AssistantsApiToolChoiceOption getToolChoice() const;
    void setToolChoice(AssistantsApiToolChoiceOption value);

    /// <summary>
    /// 
    /// </summary>
    AssistantsApiResponseFormatOption getResponseFormat() const;
    void setResponseFormat(AssistantsApiResponseFormatOption value);

protected:
    std::string m_Assistant_id = "";
    CreateThreadRequest m_Thread;
    CreateRunRequest_model m_Model;
    std::string m_Instructions = "";
    std::vector<CreateThreadAndRunRequest_tools_inner> m_Tools;
    std::string m_Metadata = std::string{};
    double m_Temperature = 1;
    bool m_Stream = false;
    int32_t m_Max_prompt_tokens = 0;
    int32_t m_Max_completion_tokens = 0;
    TruncationObject m_Truncation_strategy;
    AssistantsApiToolChoiceOption m_Tool_choice;
    AssistantsApiResponseFormatOption m_Response_format;
};

std::vector<CreateThreadAndRunRequest> createCreateThreadAndRunRequestVectorFromJsonString(const std::string& json);

template<>
inline boost::property_tree::ptree toPt<CreateThreadAndRunRequest>(const CreateThreadAndRunRequest& val) {
    return val.toPropertyTree();
}

template<>
inline CreateThreadAndRunRequest fromPt<CreateThreadAndRunRequest>(const boost::property_tree::ptree& pt) {
    CreateThreadAndRunRequest ret;
    ret.fromPropertyTree(pt);
    return ret;
}

}
}
}
}

#endif /* CreateThreadAndRunRequest_H_ */
