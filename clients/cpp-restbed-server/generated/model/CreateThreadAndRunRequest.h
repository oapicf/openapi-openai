/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.18.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * CreateThreadAndRunRequest.h
 *
 * 
 */

#ifndef CreateThreadAndRunRequest_H_
#define CreateThreadAndRunRequest_H_



#include "CreateThreadRequest.h"
#include "CreateRunRequest_model.h"
#include "CreateThreadAndRunRequest_tools_inner.h"
#include "TruncationObject.h"
#include <string>
#include "CreateThreadAndRunRequest_tool_resources.h"
#include "AssistantsApiResponseFormatOption.h"
#include "AssistantsApiToolChoiceOption.h"
#include <vector>
#include <memory>
#include <vector>
#include <boost/property_tree/ptree.hpp>
#include "helpers.h"

namespace org {
namespace openapitools {
namespace server {
namespace model {

/// <summary>
/// 
/// </summary>
class  CreateThreadAndRunRequest 
{
public:
    CreateThreadAndRunRequest() = default;
    explicit CreateThreadAndRunRequest(boost::property_tree::ptree const& pt);
    virtual ~CreateThreadAndRunRequest() = default;

    CreateThreadAndRunRequest(const CreateThreadAndRunRequest& other) = default; // copy constructor
    CreateThreadAndRunRequest(CreateThreadAndRunRequest&& other) noexcept = default; // move constructor

    CreateThreadAndRunRequest& operator=(const CreateThreadAndRunRequest& other) = default; // copy assignment
    CreateThreadAndRunRequest& operator=(CreateThreadAndRunRequest&& other) noexcept = default; // move assignment

    std::string toJsonString(bool prettyJson = false) const;
    void fromJsonString(std::string const& jsonString);
    boost::property_tree::ptree toPropertyTree() const;
    void fromPropertyTree(boost::property_tree::ptree const& pt);


    /////////////////////////////////////////////
    /// CreateThreadAndRunRequest members

    /// <summary>
    /// The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.
    /// </summary>
    std::string getAssistantId() const;
    void setAssistantId(std::string value);

    /// <summary>
    /// 
    /// </summary>
    CreateThreadRequest getThread() const;
    void setThread(CreateThreadRequest value);

    /// <summary>
    /// 
    /// </summary>
    CreateRunRequest_model getModel() const;
    void setModel(CreateRunRequest_model value);

    /// <summary>
    /// Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.
    /// </summary>
    std::string getInstructions() const;
    void setInstructions(std::string value);

    /// <summary>
    /// Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
    /// </summary>
    std::vector<CreateThreadAndRunRequest_tools_inner> getTools() const;
    void setTools(std::vector<CreateThreadAndRunRequest_tools_inner> value);

    /// <summary>
    /// 
    /// </summary>
    CreateThreadAndRunRequest_tool_resources getToolResources() const;
    void setToolResources(CreateThreadAndRunRequest_tool_resources value);

    /// <summary>
    /// Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long. 
    /// </summary>
    std::string getMetadata() const;
    void setMetadata(std::string value);

    /// <summary>
    /// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. 
    /// </summary>
    double getTemperature() const;
    void setTemperature(double value);

    /// <summary>
    /// An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.  We generally recommend altering this or temperature but not both. 
    /// </summary>
    double getTopP() const;
    void setTopP(double value);

    /// <summary>
    /// If &#x60;true&#x60;, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a &#x60;data: [DONE]&#x60; message. 
    /// </summary>
    bool isStream() const;
    void setStream(bool value);

    /// <summary>
    /// The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status &#x60;incomplete&#x60;. See &#x60;incomplete_details&#x60; for more info. 
    /// </summary>
    int32_t getMaxPromptTokens() const;
    void setMaxPromptTokens(int32_t value);

    /// <summary>
    /// The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status &#x60;incomplete&#x60;. See &#x60;incomplete_details&#x60; for more info. 
    /// </summary>
    int32_t getMaxCompletionTokens() const;
    void setMaxCompletionTokens(int32_t value);

    /// <summary>
    /// 
    /// </summary>
    TruncationObject getTruncationStrategy() const;
    void setTruncationStrategy(TruncationObject value);

    /// <summary>
    /// 
    /// </summary>
    AssistantsApiToolChoiceOption getToolChoice() const;
    void setToolChoice(AssistantsApiToolChoiceOption value);

    /// <summary>
    /// Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.
    /// </summary>
    bool isParallelToolCalls() const;
    void setParallelToolCalls(bool value);

    /// <summary>
    /// 
    /// </summary>
    AssistantsApiResponseFormatOption getResponseFormat() const;
    void setResponseFormat(AssistantsApiResponseFormatOption value);

protected:
    std::string m_Assistant_id = "";
    CreateThreadRequest m_Thread;
    CreateRunRequest_model m_Model;
    std::string m_Instructions = "";
    std::vector<CreateThreadAndRunRequest_tools_inner> m_Tools;
    CreateThreadAndRunRequest_tool_resources m_Tool_resources;
    std::string m_Metadata = std::string{};
    double m_Temperature = 1;
    double m_Top_p = 1;
    bool m_Stream = false;
    int32_t m_Max_prompt_tokens = 0;
    int32_t m_Max_completion_tokens = 0;
    TruncationObject m_Truncation_strategy;
    AssistantsApiToolChoiceOption m_Tool_choice;
    bool m_Parallel_tool_calls = true;
    AssistantsApiResponseFormatOption m_Response_format;
};

std::vector<CreateThreadAndRunRequest> createCreateThreadAndRunRequestVectorFromJsonString(const std::string& json);

template<>
inline boost::property_tree::ptree toPt<CreateThreadAndRunRequest>(const CreateThreadAndRunRequest& val) {
    return val.toPropertyTree();
}

template<>
inline CreateThreadAndRunRequest fromPt<CreateThreadAndRunRequest>(const boost::property_tree::ptree& pt) {
    CreateThreadAndRunRequest ret;
    ret.fromPropertyTree(pt);
    return ret;
}

}
}
}
}

#endif /* CreateThreadAndRunRequest_H_ */
