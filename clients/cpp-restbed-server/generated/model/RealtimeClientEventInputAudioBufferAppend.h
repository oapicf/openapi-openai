/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.18.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * RealtimeClientEventInputAudioBufferAppend.h
 *
 * Send this event to append audio bytes to the input audio buffer. The audio  buffer is temporary storage you can write to and later commit. In Server VAD  mode, the audio buffer is used to detect speech and the server will decide  when to commit. When Server VAD is disabled, you must commit the audio buffer manually.  The client may choose how much audio to place in each event up to a maximum  of 15 MiB, for example streaming smaller chunks from the client may allow the  VAD to be more responsive. Unlike made other client events, the server will  not send a confirmation response to this event. 
 */

#ifndef RealtimeClientEventInputAudioBufferAppend_H_
#define RealtimeClientEventInputAudioBufferAppend_H_



#include <string>
#include <memory>
#include <vector>
#include <array>
#include <boost/property_tree/ptree.hpp>
#include "helpers.h"

namespace org {
namespace openapitools {
namespace server {
namespace model {

/// <summary>
/// Send this event to append audio bytes to the input audio buffer. The audio  buffer is temporary storage you can write to and later commit. In Server VAD  mode, the audio buffer is used to detect speech and the server will decide  when to commit. When Server VAD is disabled, you must commit the audio buffer manually.  The client may choose how much audio to place in each event up to a maximum  of 15 MiB, for example streaming smaller chunks from the client may allow the  VAD to be more responsive. Unlike made other client events, the server will  not send a confirmation response to this event. 
/// </summary>
class  RealtimeClientEventInputAudioBufferAppend 
{
public:
    RealtimeClientEventInputAudioBufferAppend() = default;
    explicit RealtimeClientEventInputAudioBufferAppend(boost::property_tree::ptree const& pt);
    virtual ~RealtimeClientEventInputAudioBufferAppend() = default;

    RealtimeClientEventInputAudioBufferAppend(const RealtimeClientEventInputAudioBufferAppend& other) = default; // copy constructor
    RealtimeClientEventInputAudioBufferAppend(RealtimeClientEventInputAudioBufferAppend&& other) noexcept = default; // move constructor

    RealtimeClientEventInputAudioBufferAppend& operator=(const RealtimeClientEventInputAudioBufferAppend& other) = default; // copy assignment
    RealtimeClientEventInputAudioBufferAppend& operator=(RealtimeClientEventInputAudioBufferAppend&& other) noexcept = default; // move assignment

    std::string toJsonString(bool prettyJson = false) const;
    void fromJsonString(std::string const& jsonString);
    boost::property_tree::ptree toPropertyTree() const;
    void fromPropertyTree(boost::property_tree::ptree const& pt);


    /////////////////////////////////////////////
    /// RealtimeClientEventInputAudioBufferAppend members

    /// <summary>
    /// Optional client-generated ID used to identify this event.
    /// </summary>
    std::string getEventId() const;
    void setEventId(std::string value);

    /// <summary>
    /// The event type, must be &#x60;input_audio_buffer.append&#x60;.
    /// </summary>
    std::string getType() const;
    void setType(std::string value);

    /// <summary>
    /// Base64-encoded audio bytes. This must be in the format specified by the  &#x60;input_audio_format&#x60; field in the session configuration. 
    /// </summary>
    std::string getAudio() const;
    void setAudio(std::string value);

protected:
    std::string m_Event_id = "";
    std::string m_Type = "";
    std::string m_Audio = "";
};

std::vector<RealtimeClientEventInputAudioBufferAppend> createRealtimeClientEventInputAudioBufferAppendVectorFromJsonString(const std::string& json);

template<>
inline boost::property_tree::ptree toPt<RealtimeClientEventInputAudioBufferAppend>(const RealtimeClientEventInputAudioBufferAppend& val) {
    return val.toPropertyTree();
}

template<>
inline RealtimeClientEventInputAudioBufferAppend fromPt<RealtimeClientEventInputAudioBufferAppend>(const boost::property_tree::ptree& pt) {
    RealtimeClientEventInputAudioBufferAppend ret;
    ret.fromPropertyTree(pt);
    return ret;
}

}
}
}
}

#endif /* RealtimeClientEventInputAudioBufferAppend_H_ */
