/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.18.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * RealtimeServerEventConversationItemInputAudioTranscriptionCompleted.h
 *
 * This event is the output of audio transcription for user audio written to the  user audio buffer. Transcription begins when the input audio buffer is  committed by the client or server (in &#x60;server_vad&#x60; mode). Transcription runs  asynchronously with Response creation, so this event may come before or after  the Response events.  Realtime API models accept audio natively, and thus input transcription is a  separate process run on a separate ASR (Automatic Speech Recognition) model,  currently always &#x60;whisper-1&#x60;. Thus the transcript may diverge somewhat from  the model&#39;s interpretation, and should be treated as a rough guide. 
 */

#ifndef RealtimeServerEventConversationItemInputAudioTranscriptionCompleted_H_
#define RealtimeServerEventConversationItemInputAudioTranscriptionCompleted_H_



#include <string>
#include <memory>
#include <vector>
#include <array>
#include <boost/property_tree/ptree.hpp>
#include "helpers.h"

namespace org {
namespace openapitools {
namespace server {
namespace model {

/// <summary>
/// This event is the output of audio transcription for user audio written to the  user audio buffer. Transcription begins when the input audio buffer is  committed by the client or server (in &#x60;server_vad&#x60; mode). Transcription runs  asynchronously with Response creation, so this event may come before or after  the Response events.  Realtime API models accept audio natively, and thus input transcription is a  separate process run on a separate ASR (Automatic Speech Recognition) model,  currently always &#x60;whisper-1&#x60;. Thus the transcript may diverge somewhat from  the model&#39;s interpretation, and should be treated as a rough guide. 
/// </summary>
class  RealtimeServerEventConversationItemInputAudioTranscriptionCompleted 
{
public:
    RealtimeServerEventConversationItemInputAudioTranscriptionCompleted() = default;
    explicit RealtimeServerEventConversationItemInputAudioTranscriptionCompleted(boost::property_tree::ptree const& pt);
    virtual ~RealtimeServerEventConversationItemInputAudioTranscriptionCompleted() = default;

    RealtimeServerEventConversationItemInputAudioTranscriptionCompleted(const RealtimeServerEventConversationItemInputAudioTranscriptionCompleted& other) = default; // copy constructor
    RealtimeServerEventConversationItemInputAudioTranscriptionCompleted(RealtimeServerEventConversationItemInputAudioTranscriptionCompleted&& other) noexcept = default; // move constructor

    RealtimeServerEventConversationItemInputAudioTranscriptionCompleted& operator=(const RealtimeServerEventConversationItemInputAudioTranscriptionCompleted& other) = default; // copy assignment
    RealtimeServerEventConversationItemInputAudioTranscriptionCompleted& operator=(RealtimeServerEventConversationItemInputAudioTranscriptionCompleted&& other) noexcept = default; // move assignment

    std::string toJsonString(bool prettyJson = false) const;
    void fromJsonString(std::string const& jsonString);
    boost::property_tree::ptree toPropertyTree() const;
    void fromPropertyTree(boost::property_tree::ptree const& pt);


    /////////////////////////////////////////////
    /// RealtimeServerEventConversationItemInputAudioTranscriptionCompleted members

    /// <summary>
    /// The unique ID of the server event.
    /// </summary>
    std::string getEventId() const;
    void setEventId(std::string value);

    /// <summary>
    /// The event type, must be &#x60;conversation.item.input_audio_transcription.completed&#x60;. 
    /// </summary>
    std::string getType() const;
    void setType(std::string value);

    /// <summary>
    /// The ID of the user message item containing the audio.
    /// </summary>
    std::string getItemId() const;
    void setItemId(std::string value);

    /// <summary>
    /// The index of the content part containing the audio.
    /// </summary>
    int32_t getContentIndex() const;
    void setContentIndex(int32_t value);

    /// <summary>
    /// The transcribed text.
    /// </summary>
    std::string getTranscript() const;
    void setTranscript(std::string value);

protected:
    std::string m_Event_id = "";
    std::string m_Type = "";
    std::string m_Item_id = "";
    int32_t m_Content_index = 0;
    std::string m_Transcript = "";
};

std::vector<RealtimeServerEventConversationItemInputAudioTranscriptionCompleted> createRealtimeServerEventConversationItemInputAudioTranscriptionCompletedVectorFromJsonString(const std::string& json);

template<>
inline boost::property_tree::ptree toPt<RealtimeServerEventConversationItemInputAudioTranscriptionCompleted>(const RealtimeServerEventConversationItemInputAudioTranscriptionCompleted& val) {
    return val.toPropertyTree();
}

template<>
inline RealtimeServerEventConversationItemInputAudioTranscriptionCompleted fromPt<RealtimeServerEventConversationItemInputAudioTranscriptionCompleted>(const boost::property_tree::ptree& pt) {
    RealtimeServerEventConversationItemInputAudioTranscriptionCompleted ret;
    ret.fromPropertyTree(pt);
    return ret;
}

}
}
}
}

#endif /* RealtimeServerEventConversationItemInputAudioTranscriptionCompleted_H_ */
