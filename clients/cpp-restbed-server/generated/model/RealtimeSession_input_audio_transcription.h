/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.18.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * RealtimeSession_input_audio_transcription.h
 *
 * Configuration for input audio transcription, defaults to off and can be  set to &#x60;null&#x60; to turn off once on. Input audio transcription is not native  to the model, since the model consumes audio directly. Transcription runs  asynchronously through Whisper and should be treated as rough guidance  rather than the representation understood by the model. 
 */

#ifndef RealtimeSession_input_audio_transcription_H_
#define RealtimeSession_input_audio_transcription_H_



#include <string>
#include <memory>
#include <vector>
#include <boost/property_tree/ptree.hpp>
#include "helpers.h"

namespace org {
namespace openapitools {
namespace server {
namespace model {

/// <summary>
/// Configuration for input audio transcription, defaults to off and can be  set to &#x60;null&#x60; to turn off once on. Input audio transcription is not native  to the model, since the model consumes audio directly. Transcription runs  asynchronously through Whisper and should be treated as rough guidance  rather than the representation understood by the model. 
/// </summary>
class  RealtimeSession_input_audio_transcription 
{
public:
    RealtimeSession_input_audio_transcription() = default;
    explicit RealtimeSession_input_audio_transcription(boost::property_tree::ptree const& pt);
    virtual ~RealtimeSession_input_audio_transcription() = default;

    RealtimeSession_input_audio_transcription(const RealtimeSession_input_audio_transcription& other) = default; // copy constructor
    RealtimeSession_input_audio_transcription(RealtimeSession_input_audio_transcription&& other) noexcept = default; // move constructor

    RealtimeSession_input_audio_transcription& operator=(const RealtimeSession_input_audio_transcription& other) = default; // copy assignment
    RealtimeSession_input_audio_transcription& operator=(RealtimeSession_input_audio_transcription&& other) noexcept = default; // move assignment

    std::string toJsonString(bool prettyJson = false) const;
    void fromJsonString(std::string const& jsonString);
    boost::property_tree::ptree toPropertyTree() const;
    void fromPropertyTree(boost::property_tree::ptree const& pt);


    /////////////////////////////////////////////
    /// RealtimeSession_input_audio_transcription members

    /// <summary>
    /// The model to use for transcription, &#x60;whisper-1&#x60; is the only currently  supported model. 
    /// </summary>
    std::string getModel() const;
    void setModel(std::string value);

protected:
    std::string m_Model = "";
};

std::vector<RealtimeSession_input_audio_transcription> createRealtimeSession_input_audio_transcriptionVectorFromJsonString(const std::string& json);

template<>
inline boost::property_tree::ptree toPt<RealtimeSession_input_audio_transcription>(const RealtimeSession_input_audio_transcription& val) {
    return val.toPropertyTree();
}

template<>
inline RealtimeSession_input_audio_transcription fromPt<RealtimeSession_input_audio_transcription>(const boost::property_tree::ptree& pt) {
    RealtimeSession_input_audio_transcription ret;
    ret.fromPropertyTree(pt);
    return ret;
}

}
}
}
}

#endif /* RealtimeSession_input_audio_transcription_H_ */
