/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.18.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * CreateChatCompletionStreamResponse_usage.h
 *
 * An optional field that will only be present when you set &#x60;stream_options: {\&quot;include_usage\&quot;: true}&#x60; in your request. When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request. 
 */

#ifndef ORG_OPENAPITOOLS_CLIENT_MODEL_CreateChatCompletionStreamResponse_usage_H_
#define ORG_OPENAPITOOLS_CLIENT_MODEL_CreateChatCompletionStreamResponse_usage_H_

#include <boost/optional.hpp>

#include "CppRestOpenAPIClient/ModelBase.h"


namespace org {
namespace openapitools {
namespace client {
namespace model {



/// <summary>
/// An optional field that will only be present when you set &#x60;stream_options: {\&quot;include_usage\&quot;: true}&#x60; in your request. When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request. 
/// </summary>
class  CreateChatCompletionStreamResponse_usage
    : public ModelBase
{
public:
    CreateChatCompletionStreamResponse_usage();
    virtual ~CreateChatCompletionStreamResponse_usage();

    /////////////////////////////////////////////
    /// ModelBase overrides

    void validate() override;

    web::json::value toJson() const override;
    bool fromJson(const web::json::value& json) override;

    void toMultipart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& namePrefix) const override;
    bool fromMultiPart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& namePrefix) override;


    /////////////////////////////////////////////
    /// CreateChatCompletionStreamResponse_usage members


    /// <summary>
    /// Number of tokens in the generated completion.
    /// </summary>
    int32_t getCompletionTokens() const;
    bool completionTokensIsSet() const;
    void unsetCompletion_tokens();
    void setCompletionTokens(int32_t value);

    /// <summary>
    /// Number of tokens in the prompt.
    /// </summary>
    int32_t getPromptTokens() const;
    bool promptTokensIsSet() const;
    void unsetPrompt_tokens();
    void setPromptTokens(int32_t value);

    /// <summary>
    /// Total number of tokens used in the request (prompt + completion).
    /// </summary>
    int32_t getTotalTokens() const;
    bool totalTokensIsSet() const;
    void unsetTotal_tokens();
    void setTotalTokens(int32_t value);


protected:
    int32_t m_Completion_tokens;
    bool m_Completion_tokensIsSet;

    int32_t m_Prompt_tokens;
    bool m_Prompt_tokensIsSet;

    int32_t m_Total_tokens;
    bool m_Total_tokensIsSet;

};


}
}
}
}

#endif /* ORG_OPENAPITOOLS_CLIENT_MODEL_CreateChatCompletionStreamResponse_usage_H_ */
