/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.18.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * RealtimeServerEventConversationItemInputAudioTranscriptionCompleted.h
 *
 * This event is the output of audio transcription for user audio written to the  user audio buffer. Transcription begins when the input audio buffer is  committed by the client or server (in &#x60;server_vad&#x60; mode). Transcription runs  asynchronously with Response creation, so this event may come before or after  the Response events.  Realtime API models accept audio natively, and thus input transcription is a  separate process run on a separate ASR (Automatic Speech Recognition) model,  currently always &#x60;whisper-1&#x60;. Thus the transcript may diverge somewhat from  the model&#39;s interpretation, and should be treated as a rough guide. 
 */

#ifndef ORG_OPENAPITOOLS_CLIENT_MODEL_RealtimeServerEventConversationItemInputAudioTranscriptionCompleted_H_
#define ORG_OPENAPITOOLS_CLIENT_MODEL_RealtimeServerEventConversationItemInputAudioTranscriptionCompleted_H_

#include <stdexcept>
#include <boost/optional.hpp>

#include "CppRestOpenAPIClient/ModelBase.h"

#include <cpprest/details/basic_types.h>

namespace org {
namespace openapitools {
namespace client {
namespace model {



/// <summary>
/// This event is the output of audio transcription for user audio written to the  user audio buffer. Transcription begins when the input audio buffer is  committed by the client or server (in &#x60;server_vad&#x60; mode). Transcription runs  asynchronously with Response creation, so this event may come before or after  the Response events.  Realtime API models accept audio natively, and thus input transcription is a  separate process run on a separate ASR (Automatic Speech Recognition) model,  currently always &#x60;whisper-1&#x60;. Thus the transcript may diverge somewhat from  the model&#39;s interpretation, and should be treated as a rough guide. 
/// </summary>
class  RealtimeServerEventConversationItemInputAudioTranscriptionCompleted
    : public ModelBase
{
public:
    RealtimeServerEventConversationItemInputAudioTranscriptionCompleted();
    virtual ~RealtimeServerEventConversationItemInputAudioTranscriptionCompleted();

    /////////////////////////////////////////////
    /// ModelBase overrides

    void validate() override;

    web::json::value toJson() const override;
    bool fromJson(const web::json::value& json) override;

    void toMultipart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& namePrefix) const override;
    bool fromMultiPart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& namePrefix) override;


    /////////////////////////////////////////////
    /// RealtimeServerEventConversationItemInputAudioTranscriptionCompleted members

    enum class TypeEnum
    {
        CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_COMPLETED,
    };
    /// <summary>
    /// The event type, must be &#x60;conversation.item.input_audio_transcription.completed&#x60;. 
    /// </summary>

    TypeEnum toTypeEnum(const utility::string_t& value) const;
    const utility::string_t fromTypeEnum(const TypeEnum value) const;


    /// <summary>
    /// The unique ID of the server event.
    /// </summary>
    utility::string_t getEventId() const;
    bool eventIdIsSet() const;
    void unsetEvent_id();
    void setEventId(const utility::string_t& value);

    /// <summary>
    /// The event type, must be &#x60;conversation.item.input_audio_transcription.completed&#x60;. 
    /// </summary>
    TypeEnum getType() const;
    bool typeIsSet() const;
    void unsetType();
    void setType(const TypeEnum value);

    /// <summary>
    /// The ID of the user message item containing the audio.
    /// </summary>
    utility::string_t getItemId() const;
    bool itemIdIsSet() const;
    void unsetItem_id();
    void setItemId(const utility::string_t& value);

    /// <summary>
    /// The index of the content part containing the audio.
    /// </summary>
    int32_t getContentIndex() const;
    bool contentIndexIsSet() const;
    void unsetContent_index();
    void setContentIndex(int32_t value);

    /// <summary>
    /// The transcribed text.
    /// </summary>
    utility::string_t getTranscript() const;
    bool transcriptIsSet() const;
    void unsetTranscript();
    void setTranscript(const utility::string_t& value);


protected:
    utility::string_t m_Event_id;
    bool m_Event_idIsSet;

    TypeEnum m_Type;
    bool m_TypeIsSet;

    utility::string_t m_Item_id;
    bool m_Item_idIsSet;

    int32_t m_Content_index;
    bool m_Content_indexIsSet;

    utility::string_t m_Transcript;
    bool m_TranscriptIsSet;

};


}
}
}
}

#endif /* ORG_OPENAPITOOLS_CLIENT_MODEL_RealtimeServerEventConversationItemInputAudioTranscriptionCompleted_H_ */
