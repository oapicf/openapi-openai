/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.18.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * RealtimeServerEventInputAudioBufferSpeechStarted.h
 *
 * Sent by the server when in &#x60;server_vad&#x60; mode to indicate that speech has been  detected in the audio buffer. This can happen any time audio is added to the  buffer (unless speech is already detected). The client may want to use this  event to interrupt audio playback or provide visual feedback to the user.   The client should expect to receive a &#x60;input_audio_buffer.speech_stopped&#x60; event  when speech stops. The &#x60;item_id&#x60; property is the ID of the user message item  that will be created when speech stops and will also be included in the  &#x60;input_audio_buffer.speech_stopped&#x60; event (unless the client manually commits  the audio buffer during VAD activation). 
 */

#ifndef ORG_OPENAPITOOLS_CLIENT_MODEL_RealtimeServerEventInputAudioBufferSpeechStarted_H_
#define ORG_OPENAPITOOLS_CLIENT_MODEL_RealtimeServerEventInputAudioBufferSpeechStarted_H_

#include <stdexcept>
#include <boost/optional.hpp>

#include "CppRestOpenAPIClient/ModelBase.h"

#include <cpprest/details/basic_types.h>

namespace org {
namespace openapitools {
namespace client {
namespace model {



/// <summary>
/// Sent by the server when in &#x60;server_vad&#x60; mode to indicate that speech has been  detected in the audio buffer. This can happen any time audio is added to the  buffer (unless speech is already detected). The client may want to use this  event to interrupt audio playback or provide visual feedback to the user.   The client should expect to receive a &#x60;input_audio_buffer.speech_stopped&#x60; event  when speech stops. The &#x60;item_id&#x60; property is the ID of the user message item  that will be created when speech stops and will also be included in the  &#x60;input_audio_buffer.speech_stopped&#x60; event (unless the client manually commits  the audio buffer during VAD activation). 
/// </summary>
class  RealtimeServerEventInputAudioBufferSpeechStarted
    : public ModelBase
{
public:
    RealtimeServerEventInputAudioBufferSpeechStarted();
    virtual ~RealtimeServerEventInputAudioBufferSpeechStarted();

    /////////////////////////////////////////////
    /// ModelBase overrides

    void validate() override;

    web::json::value toJson() const override;
    bool fromJson(const web::json::value& json) override;

    void toMultipart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& namePrefix) const override;
    bool fromMultiPart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& namePrefix) override;


    /////////////////////////////////////////////
    /// RealtimeServerEventInputAudioBufferSpeechStarted members

    enum class TypeEnum
    {
        INPUT_AUDIO_BUFFER_SPEECH_STARTED,
    };
    /// <summary>
    /// The event type, must be &#x60;input_audio_buffer.speech_started&#x60;.
    /// </summary>

    TypeEnum toTypeEnum(const utility::string_t& value) const;
    const utility::string_t fromTypeEnum(const TypeEnum value) const;


    /// <summary>
    /// The unique ID of the server event.
    /// </summary>
    utility::string_t getEventId() const;
    bool eventIdIsSet() const;
    void unsetEvent_id();
    void setEventId(const utility::string_t& value);

    /// <summary>
    /// The event type, must be &#x60;input_audio_buffer.speech_started&#x60;.
    /// </summary>
    TypeEnum getType() const;
    bool typeIsSet() const;
    void unsetType();
    void setType(const TypeEnum value);

    /// <summary>
    /// Milliseconds from the start of all audio written to the buffer during the  session when speech was first detected. This will correspond to the  beginning of audio sent to the model, and thus includes the  &#x60;prefix_padding_ms&#x60; configured in the Session. 
    /// </summary>
    int32_t getAudioStartMs() const;
    bool audioStartMsIsSet() const;
    void unsetAudio_start_ms();
    void setAudioStartMs(int32_t value);

    /// <summary>
    /// The ID of the user message item that will be created when speech stops. 
    /// </summary>
    utility::string_t getItemId() const;
    bool itemIdIsSet() const;
    void unsetItem_id();
    void setItemId(const utility::string_t& value);


protected:
    utility::string_t m_Event_id;
    bool m_Event_idIsSet;

    TypeEnum m_Type;
    bool m_TypeIsSet;

    int32_t m_Audio_start_ms;
    bool m_Audio_start_msIsSet;

    utility::string_t m_Item_id;
    bool m_Item_idIsSet;

};


}
}
}
}

#endif /* ORG_OPENAPITOOLS_CLIENT_MODEL_RealtimeServerEventInputAudioBufferSpeechStarted_H_ */
