/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.18.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * RealtimeSession.h
 *
 * Realtime session object configuration.
 */

#ifndef ORG_OPENAPITOOLS_CLIENT_MODEL_RealtimeSession_H_
#define ORG_OPENAPITOOLS_CLIENT_MODEL_RealtimeSession_H_

#include <stdexcept>
#include <boost/optional.hpp>

#include "CppRestOpenAPIClient/ModelBase.h"

#include "CppRestOpenAPIClient/model/RealtimeResponseCreateParams_max_response_output_tokens.h"
#include "CppRestOpenAPIClient/model/RealtimeSession_input_audio_transcription.h"
#include "CppRestOpenAPIClient/model/RealtimeSession_model.h"
#include "CppRestOpenAPIClient/model/RealtimeSession_turn_detection.h"
#include "CppRestOpenAPIClient/model/RealtimeResponseCreateParams_tools_inner.h"
#include <cpprest/details/basic_types.h>
#include <vector>

namespace org {
namespace openapitools {
namespace client {
namespace model {

class RealtimeSession_input_audio_transcription;
class RealtimeSession_turn_detection;
class RealtimeResponseCreateParams_tools_inner;


/// <summary>
/// Realtime session object configuration.
/// </summary>
class  RealtimeSession
    : public ModelBase
{
public:
    RealtimeSession();
    virtual ~RealtimeSession();

    /////////////////////////////////////////////
    /// ModelBase overrides

    void validate() override;

    web::json::value toJson() const override;
    bool fromJson(const web::json::value& json) override;

    void toMultipart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& namePrefix) const override;
    bool fromMultiPart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& namePrefix) override;


    /////////////////////////////////////////////
    /// RealtimeSession members

    enum class ModalitiesEnum
    {
        TEXT,
        AUDIO,
    };
    /// <summary>
    /// The set of modalities the model can respond with. To disable audio, set this to [\&quot;text\&quot;]. 
    /// </summary>
    enum class VoiceEnum
    {
        ALLOY,
        ASH,
        BALLAD,
        CORAL,
        ECHO,
        SAGE,
        SHIMMER,
        VERSE,
    };
    /// <summary>
    /// The voice the model uses to respond. Voice cannot be changed during the  session once the model has responded with audio at least once. Current  voice options are &#x60;alloy&#x60;, &#x60;ash&#x60;, &#x60;ballad&#x60;, &#x60;coral&#x60;, &#x60;echo&#x60; &#x60;sage&#x60;,  &#x60;shimmer&#x60; and &#x60;verse&#x60;. 
    /// </summary>
    enum class Input_audio_formatEnum
    {
        PCM16,
        G711_ULAW,
        G711_ALAW,
    };
    /// <summary>
    /// The format of input audio. Options are &#x60;pcm16&#x60;, &#x60;g711_ulaw&#x60;, or &#x60;g711_alaw&#x60;. 
    /// </summary>
    enum class Output_audio_formatEnum
    {
        PCM16,
        G711_ULAW,
        G711_ALAW,
    };
    /// <summary>
    /// The format of output audio. Options are &#x60;pcm16&#x60;, &#x60;g711_ulaw&#x60;, or &#x60;g711_alaw&#x60;. 
    /// </summary>
    ModalitiesEnum toModalitiesEnum(const utility::string_t& value) const;
    const utility::string_t fromModalitiesEnum(const ModalitiesEnum value) const;
    std::vector<ModalitiesEnum> toModalitiesEnum(const std::vector<utility::string_t>& value) const;
    std::vector<utility::string_t> fromModalitiesEnum(const std::vector<ModalitiesEnum>& value) const;
    

    VoiceEnum toVoiceEnum(const utility::string_t& value) const;
    const utility::string_t fromVoiceEnum(const VoiceEnum value) const;


    Input_audio_formatEnum toInput_audio_formatEnum(const utility::string_t& value) const;
    const utility::string_t fromInput_audio_formatEnum(const Input_audio_formatEnum value) const;


    Output_audio_formatEnum toOutput_audio_formatEnum(const utility::string_t& value) const;
    const utility::string_t fromOutput_audio_formatEnum(const Output_audio_formatEnum value) const;


    /// <summary>
    /// Unique identifier for the session object. 
    /// </summary>
    utility::string_t getId() const;
    bool idIsSet() const;
    void unsetId();
    void setId(const utility::string_t& value);

    /// <summary>
    /// The set of modalities the model can respond with. To disable audio, set this to [\&quot;text\&quot;]. 
    /// </summary>
    std::vector<ModalitiesEnum> getModalities() const;
    bool modalitiesIsSet() const;
    void unsetModalities();
    void setModalities(const std::vector<ModalitiesEnum> value);

    std::shared_ptr<RealtimeSession_model> getModel() const;
    bool modelIsSet() const;
    void unsetModel();
    void setModel(const std::shared_ptr<RealtimeSession_model>& value);

    /// <summary>
    /// The default system instructions (i.e. system message) prepended to model  calls. This field allows the client to guide the model on desired  responses. The model can be instructed on response content and format,  (e.g. \&quot;be extremely succinct\&quot;, \&quot;act friendly\&quot;, \&quot;here are examples of good  responses\&quot;) and on audio behavior (e.g. \&quot;talk quickly\&quot;, \&quot;inject emotion  into your voice\&quot;, \&quot;laugh frequently\&quot;). The instructions are not guaranteed  to be followed by the model, but they provide guidance to the model on the  desired behavior.  Note that the server sets default instructions which will be used if this  field is not set and are visible in the &#x60;session.created&#x60; event at the  start of the session. 
    /// </summary>
    utility::string_t getInstructions() const;
    bool instructionsIsSet() const;
    void unsetInstructions();
    void setInstructions(const utility::string_t& value);

    /// <summary>
    /// The voice the model uses to respond. Voice cannot be changed during the  session once the model has responded with audio at least once. Current  voice options are &#x60;alloy&#x60;, &#x60;ash&#x60;, &#x60;ballad&#x60;, &#x60;coral&#x60;, &#x60;echo&#x60; &#x60;sage&#x60;,  &#x60;shimmer&#x60; and &#x60;verse&#x60;. 
    /// </summary>
    VoiceEnum getVoice() const;
    bool voiceIsSet() const;
    void unsetVoice();
    void setVoice(const VoiceEnum value);

    /// <summary>
    /// The format of input audio. Options are &#x60;pcm16&#x60;, &#x60;g711_ulaw&#x60;, or &#x60;g711_alaw&#x60;. 
    /// </summary>
    Input_audio_formatEnum getInputAudioFormat() const;
    bool inputAudioFormatIsSet() const;
    void unsetInput_audio_format();
    void setInputAudioFormat(const Input_audio_formatEnum value);

    /// <summary>
    /// The format of output audio. Options are &#x60;pcm16&#x60;, &#x60;g711_ulaw&#x60;, or &#x60;g711_alaw&#x60;. 
    /// </summary>
    Output_audio_formatEnum getOutputAudioFormat() const;
    bool outputAudioFormatIsSet() const;
    void unsetOutput_audio_format();
    void setOutputAudioFormat(const Output_audio_formatEnum value);

    std::shared_ptr<RealtimeSession_input_audio_transcription> getInputAudioTranscription() const;
    bool inputAudioTranscriptionIsSet() const;
    void unsetInput_audio_transcription();
    void setInputAudioTranscription(const std::shared_ptr<RealtimeSession_input_audio_transcription>& value);

    std::shared_ptr<RealtimeSession_turn_detection> getTurnDetection() const;
    bool turnDetectionIsSet() const;
    void unsetTurn_detection();
    void setTurnDetection(const std::shared_ptr<RealtimeSession_turn_detection>& value);

    /// <summary>
    /// Tools (functions) available to the model.
    /// </summary>
    std::vector<std::shared_ptr<RealtimeResponseCreateParams_tools_inner>> getTools() const;
    bool toolsIsSet() const;
    void unsetTools();
    void setTools(const std::vector<std::shared_ptr<RealtimeResponseCreateParams_tools_inner>>& value);

    /// <summary>
    /// How the model chooses tools. Options are &#x60;auto&#x60;, &#x60;none&#x60;, &#x60;required&#x60;, or  specify a function. 
    /// </summary>
    utility::string_t getToolChoice() const;
    bool toolChoiceIsSet() const;
    void unsetTool_choice();
    void setToolChoice(const utility::string_t& value);

    /// <summary>
    /// Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8. 
    /// </summary>
    double getTemperature() const;
    bool temperatureIsSet() const;
    void unsetTemperature();
    void setTemperature(double value);

    std::shared_ptr<RealtimeResponseCreateParams_max_response_output_tokens> getMaxResponseOutputTokens() const;
    bool maxResponseOutputTokensIsSet() const;
    void unsetMax_response_output_tokens();
    void setMaxResponseOutputTokens(const std::shared_ptr<RealtimeResponseCreateParams_max_response_output_tokens>& value);


protected:
    utility::string_t m_Id;
    bool m_IdIsSet;

    std::vector<ModalitiesEnum> m_Modalities;
    bool m_ModalitiesIsSet;

    std::shared_ptr<RealtimeSession_model> m_Model;
    bool m_ModelIsSet;

    utility::string_t m_Instructions;
    bool m_InstructionsIsSet;

    VoiceEnum m_Voice;
    bool m_VoiceIsSet;

    Input_audio_formatEnum m_Input_audio_format;
    bool m_Input_audio_formatIsSet;

    Output_audio_formatEnum m_Output_audio_format;
    bool m_Output_audio_formatIsSet;

    std::shared_ptr<RealtimeSession_input_audio_transcription> m_Input_audio_transcription;
    bool m_Input_audio_transcriptionIsSet;

    boost::optional<std::shared_ptr<RealtimeSession_turn_detection>> m_Turn_detection;

    std::vector<std::shared_ptr<RealtimeResponseCreateParams_tools_inner>> m_Tools;
    bool m_ToolsIsSet;

    utility::string_t m_Tool_choice;
    bool m_Tool_choiceIsSet;

    double m_Temperature;
    bool m_TemperatureIsSet;

    std::shared_ptr<RealtimeResponseCreateParams_max_response_output_tokens> m_Max_response_output_tokens;
    bool m_Max_response_output_tokensIsSet;

};


}
}
}
}

#endif /* ORG_OPENAPITOOLS_CLIENT_MODEL_RealtimeSession_H_ */
