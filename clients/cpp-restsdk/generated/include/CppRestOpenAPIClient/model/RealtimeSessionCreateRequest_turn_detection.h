/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI-Generator 7.18.0.
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/*
 * RealtimeSessionCreateRequest_turn_detection.h
 *
 * Configuration for turn detection. Can be set to &#x60;null&#x60; to turn off. Server  VAD means that the model will detect the start and end of speech based on  audio volume and respond at the end of user speech. 
 */

#ifndef ORG_OPENAPITOOLS_CLIENT_MODEL_RealtimeSessionCreateRequest_turn_detection_H_
#define ORG_OPENAPITOOLS_CLIENT_MODEL_RealtimeSessionCreateRequest_turn_detection_H_

#include <boost/optional.hpp>

#include "CppRestOpenAPIClient/ModelBase.h"

#include <cpprest/details/basic_types.h>

namespace org {
namespace openapitools {
namespace client {
namespace model {



/// <summary>
/// Configuration for turn detection. Can be set to &#x60;null&#x60; to turn off. Server  VAD means that the model will detect the start and end of speech based on  audio volume and respond at the end of user speech. 
/// </summary>
class  RealtimeSessionCreateRequest_turn_detection
    : public ModelBase
{
public:
    RealtimeSessionCreateRequest_turn_detection();
    virtual ~RealtimeSessionCreateRequest_turn_detection();

    /////////////////////////////////////////////
    /// ModelBase overrides

    void validate() override;

    web::json::value toJson() const override;
    bool fromJson(const web::json::value& json) override;

    void toMultipart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& namePrefix) const override;
    bool fromMultiPart(std::shared_ptr<MultipartFormData> multipart, const utility::string_t& namePrefix) override;


    /////////////////////////////////////////////
    /// RealtimeSessionCreateRequest_turn_detection members


    /// <summary>
    /// Type of turn detection, only &#x60;server_vad&#x60; is currently supported. 
    /// </summary>
    utility::string_t getType() const;
    bool typeIsSet() const;
    void unsetType();
    void setType(const utility::string_t& value);

    /// <summary>
    /// Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A  higher threshold will require louder audio to activate the model, and  thus might perform better in noisy environments. 
    /// </summary>
    double getThreshold() const;
    bool thresholdIsSet() const;
    void unsetThreshold();
    void setThreshold(double value);

    /// <summary>
    /// Amount of audio to include before the VAD detected speech (in  milliseconds). Defaults to 300ms. 
    /// </summary>
    int32_t getPrefixPaddingMs() const;
    bool prefixPaddingMsIsSet() const;
    void unsetPrefix_padding_ms();
    void setPrefixPaddingMs(int32_t value);

    /// <summary>
    /// Duration of silence to detect speech stop (in milliseconds). Defaults  to 500ms. With shorter values the model will respond more quickly,  but may jump in on short pauses from the user. 
    /// </summary>
    int32_t getSilenceDurationMs() const;
    bool silenceDurationMsIsSet() const;
    void unsetSilence_duration_ms();
    void setSilenceDurationMs(int32_t value);

    /// <summary>
    /// Whether or not to automatically generate a response when VAD is enabled. &#x60;true&#x60; by default. 
    /// </summary>
    bool isCreateResponse() const;
    bool createResponseIsSet() const;
    void unsetCreate_response();
    void setCreateResponse(bool value);


protected:
    utility::string_t m_Type;
    bool m_TypeIsSet;

    double m_Threshold;
    bool m_ThresholdIsSet;

    int32_t m_Prefix_padding_ms;
    bool m_Prefix_padding_msIsSet;

    int32_t m_Silence_duration_ms;
    bool m_Silence_duration_msIsSet;

    bool m_Create_response;
    bool m_Create_responseIsSet;

};


}
}
}
}

#endif /* ORG_OPENAPITOOLS_CLIENT_MODEL_RealtimeSessionCreateRequest_turn_detection_H_ */
