/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * OpenAPI spec version: 2.0.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator
 * https://github.com/OpenAPITools/openapi-generator
 * Do not edit the class manually.
 */

#pragma once

#include "OpenAPIBaseModel.h"
#include "OpenAPICreateChatCompletionStreamResponseChoicesInner.h"

namespace OpenAPI
{

/*
 * OpenAPICreateChatCompletionStreamResponse
 *
 * Represents a streamed chunk of a chat completion response returned by model, based on the provided input.
 */
class OPENAPI_API OpenAPICreateChatCompletionStreamResponse : public Model
{
public:
    virtual ~OpenAPICreateChatCompletionStreamResponse() {}
	bool FromJson(const TSharedPtr<FJsonValue>& JsonValue) final;
	void WriteJson(JsonWriter& Writer) const final;

	/* A unique identifier for the chat completion. Each chunk has the same ID. */
	FString Id;
	/* A list of chat completion choices. Can be more than one if `n` is greater than 1. */
	TArray<OpenAPICreateChatCompletionStreamResponseChoicesInner> Choices;
	/* The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp. */
	int32 Created = 0;
	/* The model to generate the completion. */
	FString Model;
	/* This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.  */
	TOptional<FString> SystemFingerprint;
	enum class ObjectEnum
	{
		ChatCompletionChunk,
  	};

	static FString EnumToString(const ObjectEnum& EnumValue);
	static bool EnumFromString(const FString& EnumAsString, ObjectEnum& EnumValue);
	/* The object type, which is always `chat.completion.chunk`. */
	ObjectEnum Object;
};

}
