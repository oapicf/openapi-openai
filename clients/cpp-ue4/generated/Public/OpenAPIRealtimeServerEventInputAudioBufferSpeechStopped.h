/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * OpenAPI spec version: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator
 * https://github.com/OpenAPITools/openapi-generator
 * Do not edit the class manually.
 */

#pragma once

#include "OpenAPIBaseModel.h"

namespace OpenAPI
{

/*
 * OpenAPIRealtimeServerEventInputAudioBufferSpeechStopped
 *
 * Returned in &#x60;server_vad&#x60; mode when the server detects the end of speech in  the audio buffer. The server will also send an &#x60;conversation.item.created&#x60;  event with the user message item that is created from the audio buffer. 
 */
class OPENAPI_API OpenAPIRealtimeServerEventInputAudioBufferSpeechStopped : public Model
{
public:
    virtual ~OpenAPIRealtimeServerEventInputAudioBufferSpeechStopped() {}
	bool FromJson(const TSharedPtr<FJsonValue>& JsonValue) final;
	void WriteJson(JsonWriter& Writer) const final;

	/* The unique ID of the server event. */
	FString EventId;
	enum class TypeEnum
	{
		InputAudioBufferSpeechStopped,
  	};

	static FString EnumToString(const TypeEnum& EnumValue);
	static bool EnumFromString(const FString& EnumAsString, TypeEnum& EnumValue);
	/* The event type, must be `input_audio_buffer.speech_stopped`. */
	TypeEnum Type;
	/* Milliseconds since the session started when speech stopped. This will  correspond to the end of audio sent to the model, and thus includes the  `min_silence_duration_ms` configured in the Session.  */
	int32 AudioEndMs = 0;
	/* The ID of the user message item that will be created. */
	FString ItemId;
};

}
