# #OpenAI API
#
##The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
#
#The version of the OpenAPI document: 2.3.0
#Contact: blah+oapicf@cliffano.com
#Generated by: https://openapi-generator.tech
#Generator version: 7.18.0
#

require "big"
require "json"
require "yaml"
require "time"

module OpenAPIClient
  class CreateChatCompletionRequest
    include JSON::Serializable
    include YAML::Serializable

    # Required properties
    # A list of messages comprising the conversation so far. Depending on the [model](/docs/models) you use, different message types (modalities) are supported, like [text](/docs/guides/text-generation), [images](/docs/guides/vision), and [audio](/docs/guides/audio). 
    @[JSON::Field(key: "messages", type: Array(ChatCompletionRequestMessage), nillable: false, emit_null: false)]
    property messages : Array(ChatCompletionRequestMessage)

    @[JSON::Field(key: "model", type: CreateChatCompletionRequestModel, nillable: false, emit_null: false)]
    property model : CreateChatCompletionRequestModel

    # Optional properties
    # Whether or not to store the output of this chat completion request for  use in our [model distillation](/docs/guides/distillation) or [evals](/docs/guides/evals) products. 
    @[JSON::Field(key: "store", type: Bool?, default: false, nillable: true, emit_null: false)]
    property store : Bool?

    # **o1 models only**   Constrains effort on reasoning for  [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `low`, `medium`, and `high`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response. 
    @[JSON::Field(key: "reasoning_effort", type: String?, default: "medium", nillable: true, emit_null: false)]
    property reasoning_effort : String?

    # Developer-defined tags and values used for filtering completions in the [dashboard](https://platform.openai.com/chat-completions). 
    @[JSON::Field(key: "metadata", type: Hash(String, String)?, nillable: true, emit_null: false)]
    property metadata : Hash(String, String)?

    # Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. 
    @[JSON::Field(key: "frequency_penalty", type: Float64?, default: 0, nillable: true, emit_null: false)]
    property frequency_penalty : Float64?

    # Modify the likelihood of specified tokens appearing in the completion.  Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token. 
    @[JSON::Field(key: "logit_bias", type: Hash(String, Int32)?, nillable: true, emit_null: false)]
    property logit_bias : Hash(String, Int32)?

    # Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`. 
    @[JSON::Field(key: "logprobs", type: Bool?, default: false, nillable: true, emit_null: false)]
    property logprobs : Bool?

    # An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used. 
    @[JSON::Field(key: "top_logprobs", type: Int32?, nillable: true, emit_null: false)]
    property top_logprobs : Int32?

    # The maximum number of [tokens](/tokenizer) that can be generated in the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.  This value is now deprecated in favor of `max_completion_tokens`, and is not compatible with [o1 series models](/docs/guides/reasoning). 
    @[JSON::Field(key: "max_tokens", type: Int32?, nillable: true, emit_null: false)]
    property max_tokens : Int32?

    # An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning). 
    @[JSON::Field(key: "max_completion_tokens", type: Int32?, nillable: true, emit_null: false)]
    property max_completion_tokens : Int32?

    # How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.
    @[JSON::Field(key: "n", type: Int32?, default: 1, nillable: true, emit_null: false)]
    property n : Int32?

    # Output types that you would like the model to generate for this request. Most models are capable of generating text, which is the default:  `[\"text\"]`  The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To request that this model generate both text and audio responses, you can use:  `[\"text\", \"audio\"]` 
    @[JSON::Field(key: "modalities", type: Array(String)?, nillable: true, emit_null: false)]
    property modalities : Array(String)?

    @[JSON::Field(key: "prediction", type: PredictionContent?, nillable: true, emit_null: false)]
    property prediction : PredictionContent?

    @[JSON::Field(key: "audio", type: CreateChatCompletionRequestAudio?, nillable: true, emit_null: false)]
    property audio : CreateChatCompletionRequestAudio?

    # Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. 
    @[JSON::Field(key: "presence_penalty", type: Float64?, default: 0, nillable: true, emit_null: false)]
    property presence_penalty : Float64?

    @[JSON::Field(key: "response_format", type: CreateChatCompletionRequestResponseFormat?, nillable: true, emit_null: false)]
    property response_format : CreateChatCompletionRequestResponseFormat?

    # This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result. Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend. 
    @[JSON::Field(key: "seed", type: Int32?, nillable: true, emit_null: false)]
    property seed : Int32?

    # Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:    - If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.   - If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.   - If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.   - When not set, the default behavior is 'auto'.    When this parameter is set, the response body will include the `service_tier` utilized. 
    @[JSON::Field(key: "service_tier", type: String?, default: "auto", nillable: true, emit_null: false)]
    property service_tier : String?

    @[JSON::Field(key: "stop", type: CreateChatCompletionRequestStop?, nillable: true, emit_null: false)]
    property stop : CreateChatCompletionRequestStop?

    # If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions). 
    @[JSON::Field(key: "stream", type: Bool?, default: false, nillable: true, emit_null: false)]
    property stream : Bool?

    @[JSON::Field(key: "stream_options", type: ChatCompletionStreamOptions?, nillable: true, emit_null: false)]
    property stream_options : ChatCompletionStreamOptions?

    # What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. 
    @[JSON::Field(key: "temperature", type: Float64?, default: 1, nillable: true, emit_null: false)]
    property temperature : Float64?

    # An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.  We generally recommend altering this or `temperature` but not both. 
    @[JSON::Field(key: "top_p", type: Float64?, default: 1, nillable: true, emit_null: false)]
    property top_p : Float64?

    # A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported. 
    @[JSON::Field(key: "tools", type: Array(ChatCompletionTool)?, nillable: true, emit_null: false)]
    property tools : Array(ChatCompletionTool)?

    @[JSON::Field(key: "tool_choice", type: ChatCompletionToolChoiceOption?, nillable: true, emit_null: false)]
    property tool_choice : ChatCompletionToolChoiceOption?

    # Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.
    @[JSON::Field(key: "parallel_tool_calls", type: Bool?, default: true, nillable: true, emit_null: false)]
    property parallel_tool_calls : Bool?

    # A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids). 
    @[JSON::Field(key: "user", type: String?, nillable: true, emit_null: false)]
    property user : String?

    @[JSON::Field(key: "function_call", type: CreateChatCompletionRequestFunctionCall?, nillable: true, emit_null: false)]
    property function_call : CreateChatCompletionRequestFunctionCall?

    # Deprecated in favor of `tools`.  A list of functions the model may generate JSON inputs for. 
    @[JSON::Field(key: "functions", type: Array(ChatCompletionFunctions)?, nillable: true, emit_null: false)]
    property functions : Array(ChatCompletionFunctions)?

    abstract class EnumAttributeValidator
      def valid?(value)
        !value || @allowable_values.includes?(value)
      end

      def message
        "invalid value for \"#{@attribute}\", must be one of #{@allowable_values}."
      end

      def to(_type, value)
        case _type
        when Int32
          value.to_i32
        when Int64
          value.to_i64
        when Float32
          value.to_f32
        when Float64
          value.to_f64
        else
          value.to_s
        end
      end
    end

    class EnumAttributeValidatorForReasoning_effort < EnumAttributeValidator
      @attribute : String
      @allowable_values : Array(Int32 | Int64 | Float32 | Float64 | String)

      def initialize
        @attribute = "reasoning_effort"
        @allowable_values = ["low", "medium", "high"].map { |value| to(String, value)}
      end
    end

    class EnumAttributeValidatorForService_tier < EnumAttributeValidator
      @attribute : String
      @allowable_values : Array(Int32 | Int64 | Float32 | Float64 | String)

      def initialize
        @attribute = "service_tier"
        @allowable_values = ["auto", "default"].map { |value| to(String, value)}
      end
    end


    # Initializes the object
    # @param [Hash] attributes Model attributes in the form of hash
    def initialize(@messages : Array(ChatCompletionRequestMessage), @model : CreateChatCompletionRequestModel, @store : Bool? = nil, @reasoning_effort : String? = nil, @metadata : Hash(String, String)? = nil, @frequency_penalty : Float64? = nil, @logit_bias : Hash(String, Int32)? = nil, @logprobs : Bool? = nil, @top_logprobs : Int32? = nil, @max_tokens : Int32? = nil, @max_completion_tokens : Int32? = nil, @n : Int32? = nil, @modalities : Array(String)? = nil, @prediction : PredictionContent? = nil, @audio : CreateChatCompletionRequestAudio? = nil, @presence_penalty : Float64? = nil, @response_format : CreateChatCompletionRequestResponseFormat? = nil, @seed : Int32? = nil, @service_tier : String? = nil, @stop : CreateChatCompletionRequestStop? = nil, @stream : Bool? = nil, @stream_options : ChatCompletionStreamOptions? = nil, @temperature : Float64? = nil, @top_p : Float64? = nil, @tools : Array(ChatCompletionTool)? = nil, @tool_choice : ChatCompletionToolChoiceOption? = nil, @parallel_tool_calls : Bool? = nil, @user : String? = nil, @function_call : CreateChatCompletionRequestFunctionCall? = nil, @functions : Array(ChatCompletionFunctions)? = nil)
    end

    # Show invalid properties with the reasons. Usually used together with valid?
    # @return Array for valid properties with the reasons
    def list_invalid_properties
      invalid_properties = Array(String).new
      if @messages.try &.size.try &.< 1
        invalid_properties.push("invalid value for \"messages\", number of items must be greater than or equal to 1."
      end

      reasoning_effort_validator = EnumAttributeValidatorForReasoning_effort.new
      if !reasoning_effort_validator.valid?(@reasoning_effort)
        message = reasoning_effort_validator.message
        invalid_properties.push(message)
      end

      if !@frequency_penalty.nil? && @frequency_penalty.try &.> 2
        invalid_properties.push("invalid value for \"frequency_penalty\", must be smaller than or equal to 2.")
      end

      if !@frequency_penalty.nil? && @frequency_penalty.try &.< -2
        invalid_properties.push("invalid value for \"frequency_penalty\", must be greater than or equal to -2.")
      end

      if !@top_logprobs.nil? && @top_logprobs.try &.> 20
        invalid_properties.push("invalid value for \"top_logprobs\", must be smaller than or equal to 20.")
      end

      if !@top_logprobs.nil? && @top_logprobs.try &.< 0
        invalid_properties.push("invalid value for \"top_logprobs\", must be greater than or equal to 0.")
      end

      if !@n.nil? && @n.try &.> 128
        invalid_properties.push("invalid value for \"n\", must be smaller than or equal to 128.")
      end

      if !@n.nil? && @n.try &.< 1
        invalid_properties.push("invalid value for \"n\", must be greater than or equal to 1.")
      end

      if !@presence_penalty.nil? && @presence_penalty.try &.> 2
        invalid_properties.push("invalid value for \"presence_penalty\", must be smaller than or equal to 2.")
      end

      if !@presence_penalty.nil? && @presence_penalty.try &.< -2
        invalid_properties.push("invalid value for \"presence_penalty\", must be greater than or equal to -2.")
      end

      if !@seed.nil? && @seed.try &.> 9223372036854776000
        invalid_properties.push("invalid value for \"seed\", must be smaller than or equal to 9223372036854776000.")
      end

      if !@seed.nil? && @seed.try &.< -9223372036854776000
        invalid_properties.push("invalid value for \"seed\", must be greater than or equal to -9223372036854776000.")
      end

      service_tier_validator = EnumAttributeValidatorForService_tier.new
      if !service_tier_validator.valid?(@service_tier)
        message = service_tier_validator.message
        invalid_properties.push(message)
      end

      if !@temperature.nil? && @temperature.try &.> 2
        invalid_properties.push("invalid value for \"temperature\", must be smaller than or equal to 2.")
      end

      if !@temperature.nil? && @temperature.try &.< 0
        invalid_properties.push("invalid value for \"temperature\", must be greater than or equal to 0.")
      end

      if !@top_p.nil? && @top_p.try &.> 1
        invalid_properties.push("invalid value for \"top_p\", must be smaller than or equal to 1.")
      end

      if !@top_p.nil? && @top_p.try &.< 0
        invalid_properties.push("invalid value for \"top_p\", must be greater than or equal to 0.")
      end

      if !@functions.nil? && @functions.try &.size.try &.> 128
        invalid_properties.push("invalid value for \"functions\", number of items must be less than or equal to 128."
      end

      if !@functions.nil? && @functions.try &.size.try &.< 1
        invalid_properties.push("invalid value for \"functions\", number of items must be greater than or equal to 1."
      end

      invalid_properties
    end

    # Check to see if the all the properties in the model are valid
    # @return true if the model is valid
    def valid?
      return false if @messages.try &.size.try &.< 1
      reasoning_effort_validator = EnumAttributeValidatorForReasoning_effort.new
      return false unless reasoning_effort_validator.valid?(@reasoning_effort)
      return false if !@frequency_penalty.nil? && @frequency_penalty.try &.> 2
      return false if !@frequency_penalty.nil? && @frequency_penalty.try &.< -2
      return false if !@top_logprobs.nil? && @top_logprobs.try &.> 20
      return false if !@top_logprobs.nil? && @top_logprobs.try &.< 0
      return false if !@n.nil? && @n.try &.> 128
      return false if !@n.nil? && @n.try &.< 1
      return false if !@presence_penalty.nil? && @presence_penalty.try &.> 2
      return false if !@presence_penalty.nil? && @presence_penalty.try &.< -2
      return false if !@seed.nil? && @seed.try &.> 9223372036854776000
      return false if !@seed.nil? && @seed.try &.< -9223372036854776000
      service_tier_validator = EnumAttributeValidatorForService_tier.new
      return false unless service_tier_validator.valid?(@service_tier)
      return false if !@temperature.nil? && @temperature.try &.> 2
      return false if !@temperature.nil? && @temperature.try &.< 0
      return false if !@top_p.nil? && @top_p.try &.> 1
      return false if !@top_p.nil? && @top_p.try &.< 0
      return false if !@functions.nil? && @functions.try &.size.try &.> 128
      return false if !@functions.nil? && @functions.try &.size.try &.< 1
      true
    end

    # Custom attribute writer method with validation
    # @param [Object] messages Value to be assigned
    def messages=(messages)
      if messages.size < 1
        raise ArgumentError.new("invalid value for \"messages\", number of items must be greater than or equal to 1.")
      end

      @messages = messages
    end

    # Custom attribute writer method checking allowed values (enum).
    # @param [Object] reasoning_effort Object to be assigned
    def reasoning_effort=(reasoning_effort)
      validator = EnumAttributeValidatorForReasoning_effort.new
      unless validator.valid?(reasoning_effort)
        raise ArgumentError.new(validator.message)
      end
      @reasoning_effort = reasoning_effort
    end

    # Custom attribute writer method with validation
    # @param [Object] frequency_penalty Value to be assigned
    def frequency_penalty=(frequency_penalty)
      if !frequency_penalty.nil? && frequency_penalty > 2
        raise ArgumentError.new("invalid value for \"frequency_penalty\", must be smaller than or equal to 2.")
      end

      if !frequency_penalty.nil? && frequency_penalty < -2
        raise ArgumentError.new("invalid value for \"frequency_penalty\", must be greater than or equal to -2.")
      end

      @frequency_penalty = frequency_penalty
    end

    # Custom attribute writer method with validation
    # @param [Object] top_logprobs Value to be assigned
    def top_logprobs=(top_logprobs)
      if !top_logprobs.nil? && top_logprobs > 20
        raise ArgumentError.new("invalid value for \"top_logprobs\", must be smaller than or equal to 20.")
      end

      if !top_logprobs.nil? && top_logprobs < 0
        raise ArgumentError.new("invalid value for \"top_logprobs\", must be greater than or equal to 0.")
      end

      @top_logprobs = top_logprobs
    end

    # Custom attribute writer method with validation
    # @param [Object] n Value to be assigned
    def n=(n)
      if !n.nil? && n > 128
        raise ArgumentError.new("invalid value for \"n\", must be smaller than or equal to 128.")
      end

      if !n.nil? && n < 1
        raise ArgumentError.new("invalid value for \"n\", must be greater than or equal to 1.")
      end

      @n = n
    end

    # Custom attribute writer method with validation
    # @param [Object] presence_penalty Value to be assigned
    def presence_penalty=(presence_penalty)
      if !presence_penalty.nil? && presence_penalty > 2
        raise ArgumentError.new("invalid value for \"presence_penalty\", must be smaller than or equal to 2.")
      end

      if !presence_penalty.nil? && presence_penalty < -2
        raise ArgumentError.new("invalid value for \"presence_penalty\", must be greater than or equal to -2.")
      end

      @presence_penalty = presence_penalty
    end

    # Custom attribute writer method with validation
    # @param [Object] seed Value to be assigned
    def seed=(seed)
      if !seed.nil? && seed > 9223372036854776000
        raise ArgumentError.new("invalid value for \"seed\", must be smaller than or equal to 9223372036854776000.")
      end

      if !seed.nil? && seed < -9223372036854776000
        raise ArgumentError.new("invalid value for \"seed\", must be greater than or equal to -9223372036854776000.")
      end

      @seed = seed
    end

    # Custom attribute writer method checking allowed values (enum).
    # @param [Object] service_tier Object to be assigned
    def service_tier=(service_tier)
      validator = EnumAttributeValidatorForService_tier.new
      unless validator.valid?(service_tier)
        raise ArgumentError.new(validator.message)
      end
      @service_tier = service_tier
    end

    # Custom attribute writer method with validation
    # @param [Object] temperature Value to be assigned
    def temperature=(temperature)
      if !temperature.nil? && temperature > 2
        raise ArgumentError.new("invalid value for \"temperature\", must be smaller than or equal to 2.")
      end

      if !temperature.nil? && temperature < 0
        raise ArgumentError.new("invalid value for \"temperature\", must be greater than or equal to 0.")
      end

      @temperature = temperature
    end

    # Custom attribute writer method with validation
    # @param [Object] top_p Value to be assigned
    def top_p=(top_p)
      if !top_p.nil? && top_p > 1
        raise ArgumentError.new("invalid value for \"top_p\", must be smaller than or equal to 1.")
      end

      if !top_p.nil? && top_p < 0
        raise ArgumentError.new("invalid value for \"top_p\", must be greater than or equal to 0.")
      end

      @top_p = top_p
    end

    # Custom attribute writer method with validation
    # @param [Object] functions Value to be assigned
    def functions=(functions)
      if !functions.nil? && functions.size > 128
        raise ArgumentError.new("invalid value for \"functions\", number of items must be less than or equal to 128.")
      end

      if !functions.nil? && functions.size < 1
        raise ArgumentError.new("invalid value for \"functions\", number of items must be greater than or equal to 1.")
      end

      @functions = functions
    end

    # Checks equality by comparing each attribute.
    # @param [Object] Object to be compared
    def ==(other)
      return true if self.same?(other)
      self.class == other.class &&
          messages == other.messages &&
          model == other.model &&
          store == other.store &&
          reasoning_effort == other.reasoning_effort &&
          metadata == other.metadata &&
          frequency_penalty == other.frequency_penalty &&
          logit_bias == other.logit_bias &&
          logprobs == other.logprobs &&
          top_logprobs == other.top_logprobs &&
          max_tokens == other.max_tokens &&
          max_completion_tokens == other.max_completion_tokens &&
          n == other.n &&
          modalities == other.modalities &&
          prediction == other.prediction &&
          audio == other.audio &&
          presence_penalty == other.presence_penalty &&
          response_format == other.response_format &&
          seed == other.seed &&
          service_tier == other.service_tier &&
          stop == other.stop &&
          stream == other.stream &&
          stream_options == other.stream_options &&
          temperature == other.temperature &&
          top_p == other.top_p &&
          tools == other.tools &&
          tool_choice == other.tool_choice &&
          parallel_tool_calls == other.parallel_tool_calls &&
          user == other.user &&
          function_call == other.function_call &&
          functions == other.functions
    end

    # @see the `==` method
    # @param [Object] Object to be compared
    def eql?(other)
      self == other
    end

    # Calculates hash code according to all attributes.
    # @return [Integer] Hash code
    def hash
      [messages, model, store, reasoning_effort, metadata, frequency_penalty, logit_bias, logprobs, top_logprobs, max_tokens, max_completion_tokens, n, modalities, prediction, audio, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, top_p, tools, tool_choice, parallel_tool_calls, user, function_call, functions].hash
    end

    # Builds the object from hash
    # @param [Hash] attributes Model attributes in the form of hash
    # @return [Object] Returns the model itself
    def self.build_from_hash(attributes)
      new.build_from_hash(attributes)
    end

    # Builds the object from hash
    # @param [Hash] attributes Model attributes in the form of hash
    # @return [Object] Returns the model itself
    def build_from_hash(attributes)
      return nil unless attributes.is_a?(Hash)
      self.class.openapi_types.each_pair do |key, type|
        if !attributes[self.class.attribute_map[key]]? && self.class.openapi_nullable.includes?(key)
          self.send("#{key}=", nil)
        elsif type =~ /\AArray<(.*)>/i
          # check to ensure the input is an array given that the attribute
          # is documented as an array but the input is not
          if attributes[self.class.attribute_map[key]].is_a?(Array)
            self.send("#{key}=", attributes[self.class.attribute_map[key]].map { |v| _deserialize($1, v) })
          end
        elsif !attributes[self.class.attribute_map[key]].nil?
          self.send("#{key}=", _deserialize(type, attributes[self.class.attribute_map[key]]))
        end
      end

      self
    end

    # Deserializes the data based on type
    # @param string type Data type
    # @param string value Value to be deserialized
    # @return [Object] Deserialized data
    def _deserialize(type, value)
      case type.to_sym
      when :Time
        Time.parse(value)
      when :Date
        Date.parse(value)
      when :String
        value.to_s
      when :Integer
        value.to_i
      when :Float
        value.to_f
      when :Boolean
        if value.to_s =~ /\A(true|t|yes|y|1)\z/i
          true
        else
          false
        end
      when :Object
        # generic object (usually a Hash), return directly
        value
      when /\AArray<(?<inner_type>.+)>\z/
        inner_type = Regexp.last_match[:inner_type]
        value.map { |v| _deserialize(inner_type, v) }
      when /\AHash<(?<k_type>.+?), (?<v_type>.+)>\z/
        k_type = Regexp.last_match[:k_type]
        v_type = Regexp.last_match[:v_type]
        ({} of Symbol => String).tap do |hash|
          value.each do |k, v|
            hash[_deserialize(k_type, k)] = _deserialize(v_type, v)
          end
        end
      else # model
        # models (e.g. Pet) or oneOf
        klass = OpenAPIClient.const_get(type)
        klass.respond_to?(:openapi_one_of) ? klass.build(value) : klass.build_from_hash(value)
      end
    end

    # Returns the string representation of the object
    # @return [String] String presentation of the object
    def to_s
      to_h.to_s
    end

    # to_body is an alias to to_h (backward compatibility)
    # @return [Hash] Returns the object in the form of hash
    def to_body
      to_h
    end

    # Returns the object in the form of hash
    # @return [Hash] Returns the object in the form of hash
    def to_h
      hash = NetboxClient::RecursiveHash.new
      hash["messages"] = _to_h(messages)
      hash["model"] = _to_h(model)
      hash["store"] = _to_h(store)
      hash["reasoning_effort"] = _to_h(reasoning_effort)
      hash["metadata"] = _to_h(metadata)
      hash["frequency_penalty"] = _to_h(frequency_penalty)
      hash["logit_bias"] = _to_h(logit_bias)
      hash["logprobs"] = _to_h(logprobs)
      hash["top_logprobs"] = _to_h(top_logprobs)
      hash["max_tokens"] = _to_h(max_tokens)
      hash["max_completion_tokens"] = _to_h(max_completion_tokens)
      hash["n"] = _to_h(n)
      hash["modalities"] = _to_h(modalities)
      hash["prediction"] = _to_h(prediction)
      hash["audio"] = _to_h(audio)
      hash["presence_penalty"] = _to_h(presence_penalty)
      hash["response_format"] = _to_h(response_format)
      hash["seed"] = _to_h(seed)
      hash["service_tier"] = _to_h(service_tier)
      hash["stop"] = _to_h(stop)
      hash["stream"] = _to_h(stream)
      hash["stream_options"] = _to_h(stream_options)
      hash["temperature"] = _to_h(temperature)
      hash["top_p"] = _to_h(top_p)
      hash["tools"] = _to_h(tools)
      hash["tool_choice"] = _to_h(tool_choice)
      hash["parallel_tool_calls"] = _to_h(parallel_tool_calls)
      hash["user"] = _to_h(user)
      hash["function_call"] = _to_h(function_call)
      hash["functions"] = _to_h(functions)
      hash.to_h
    end

    # Outputs non-array value in the form of hash
    # For object, use to_h. Otherwise, just return the value
    # @param [Object] value Any valid value
    # @return [Hash] Returns the value in the form of hash
    private def _to_h(value)
      if value.is_a?(Hash)
        hash = NetboxClient::RecursiveHash.new
        value.each { |k, v| hash[k] = _to_h(v) }
        hash
      elsif value.is_a?(Array)
        value.compact.map { |v| _to_h(v) }
      elsif value.responds_to?(:to_h)
        value.to_h
      else
        value
      end
    end

  end

end
