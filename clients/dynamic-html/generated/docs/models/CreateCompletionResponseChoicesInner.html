
<h2>CreateCompletionResponseChoicesInner</h2>
<ul class="parameter">
  <li class="param-required-true">finishUnderscorereason : String
    <br/>The reason the model stopped generating tokens. This will be &#x60;stop&#x60; if the model hit a natural stop point or a provided stop sequence, &#x60;length&#x60; if the maximum number of tokens specified in the request was reached, or &#x60;content_filter&#x60; if content was omitted due to a flag from our content filters. 
      <dl class="param-enum">
        <dt>Enum:
            <dd>stop</dd>
            <dd>length</dd>
            <dd>content_filter</dd>
        </dt>
      </dl>
  </li>
</ul>
<ul class="parameter">
  <li class="param-required-true">index : Integer
    <br/>
  </li>
</ul>
<ul class="parameter">
  <li class="param-required-true">logprobs : CreateCompletionResponse_choices_inner_logprobs
    <br/>
  </li>
</ul>
<ul class="parameter">
  <li class="param-required-true">text : String
    <br/>
  </li>
</ul>
