note
 description:"[
		OpenAI API
 		The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
  		The version of the OpenAPI document: 2.0.0
 	    Contact: blah+oapicf@cliffano.com

  	NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).

 		 Do not edit the class manually.
 	]"
	date: "$Date$"
	revision: "$Revision$"
	EIS:"Eiffel openapi generator", "src=https://openapi-generator.tech", "protocol=uri"
class CREATE_CHAT_COMPLETION_REQUEST




feature --Access

    messages: detachable LIST [CHAT_COMPLETION_REQUEST_MESSAGE]
      -- A list of messages comprising the conversation so far. [Example Python code](https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models).
    model: detachable CREATE_CHAT_COMPLETION_REQUEST_MODEL
      
    frequency_penalty: REAL_32
      -- Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.  [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details) 
    logit_bias: detachable STRING_TABLE [INTEGER_32]
      -- Modify the likelihood of specified tokens appearing in the completion.  Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token. 
    logprobs: BOOLEAN
      -- Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.
    top_logprobs: INTEGER_32
      -- An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.
    max_tokens: INTEGER_32
      -- The maximum number of [tokens](/tokenizer) that can be generated in the chat completion.  The total length of input tokens and generated tokens is limited by the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens. 
    n: INTEGER_32
      -- How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.
    presence_penalty: REAL_32
      -- Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.  [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details) 
    response_format: detachable CREATE_CHAT_COMPLETION_REQUEST_RESPONSE_FORMAT
      
    seed: INTEGER_32
      -- This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result. Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend. 
    stop: detachable CREATE_CHAT_COMPLETION_REQUEST_STOP
      
    stream: BOOLEAN
      -- If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions). 
    temperature: REAL_32
      -- What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.  We generally recommend altering this or `top_p` but not both. 
    top_p: REAL_32
      -- An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.  We generally recommend altering this or `temperature` but not both. 
    tools: detachable LIST [CHAT_COMPLETION_TOOL]
      -- A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported. 
    tool_choice: detachable CHAT_COMPLETION_TOOL_CHOICE_OPTION
      
    user: detachable STRING_32
      -- A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids). 
    function_call: detachable CREATE_CHAT_COMPLETION_REQUEST_FUNCTION_CALL
      
    functions: detachable LIST [CHAT_COMPLETION_FUNCTIONS]
      -- Deprecated in favor of `tools`.  A list of functions the model may generate JSON inputs for. 

feature -- Change Element

    set_messages (a_name: like messages)
        -- Set 'messages' with 'a_name'.
      do
        messages := a_name
      ensure
        messages_set: messages = a_name
      end

    set_model (a_name: like model)
        -- Set 'model' with 'a_name'.
      do
        model := a_name
      ensure
        model_set: model = a_name
      end

    set_frequency_penalty (a_name: like frequency_penalty)
        -- Set 'frequency_penalty' with 'a_name'.
      do
        frequency_penalty := a_name
      ensure
        frequency_penalty_set: frequency_penalty = a_name
      end

    set_logit_bias (a_name: like logit_bias)
        -- Set 'logit_bias' with 'a_name'.
      do
        logit_bias := a_name
      ensure
        logit_bias_set: logit_bias = a_name
      end

    set_logprobs (a_name: like logprobs)
        -- Set 'logprobs' with 'a_name'.
      do
        logprobs := a_name
      ensure
        logprobs_set: logprobs = a_name
      end

    set_top_logprobs (a_name: like top_logprobs)
        -- Set 'top_logprobs' with 'a_name'.
      do
        top_logprobs := a_name
      ensure
        top_logprobs_set: top_logprobs = a_name
      end

    set_max_tokens (a_name: like max_tokens)
        -- Set 'max_tokens' with 'a_name'.
      do
        max_tokens := a_name
      ensure
        max_tokens_set: max_tokens = a_name
      end

    set_n (a_name: like n)
        -- Set 'n' with 'a_name'.
      do
        n := a_name
      ensure
        n_set: n = a_name
      end

    set_presence_penalty (a_name: like presence_penalty)
        -- Set 'presence_penalty' with 'a_name'.
      do
        presence_penalty := a_name
      ensure
        presence_penalty_set: presence_penalty = a_name
      end

    set_response_format (a_name: like response_format)
        -- Set 'response_format' with 'a_name'.
      do
        response_format := a_name
      ensure
        response_format_set: response_format = a_name
      end

    set_seed (a_name: like seed)
        -- Set 'seed' with 'a_name'.
      do
        seed := a_name
      ensure
        seed_set: seed = a_name
      end

    set_stop (a_name: like stop)
        -- Set 'stop' with 'a_name'.
      do
        stop := a_name
      ensure
        stop_set: stop = a_name
      end

    set_stream (a_name: like stream)
        -- Set 'stream' with 'a_name'.
      do
        stream := a_name
      ensure
        stream_set: stream = a_name
      end

    set_temperature (a_name: like temperature)
        -- Set 'temperature' with 'a_name'.
      do
        temperature := a_name
      ensure
        temperature_set: temperature = a_name
      end

    set_top_p (a_name: like top_p)
        -- Set 'top_p' with 'a_name'.
      do
        top_p := a_name
      ensure
        top_p_set: top_p = a_name
      end

    set_tools (a_name: like tools)
        -- Set 'tools' with 'a_name'.
      do
        tools := a_name
      ensure
        tools_set: tools = a_name
      end

    set_tool_choice (a_name: like tool_choice)
        -- Set 'tool_choice' with 'a_name'.
      do
        tool_choice := a_name
      ensure
        tool_choice_set: tool_choice = a_name
      end

    set_user (a_name: like user)
        -- Set 'user' with 'a_name'.
      do
        user := a_name
      ensure
        user_set: user = a_name
      end

    set_function_call (a_name: like function_call)
        -- Set 'function_call' with 'a_name'.
      do
        function_call := a_name
      ensure
        function_call_set: function_call = a_name
      end

    set_functions (a_name: like functions)
        -- Set 'functions' with 'a_name'.
      do
        functions := a_name
      ensure
        functions_set: functions = a_name
      end


 feature -- Status Report

    output: STRING
          -- <Precursor>
      do
        create Result.make_empty
        Result.append("%Nclass CREATE_CHAT_COMPLETION_REQUEST%N")
        if attached messages as l_messages then
          across l_messages as ic loop
            Result.append ("%N messages:")
            Result.append (ic.item.out)
            Result.append ("%N")
          end
        end
        if attached model as l_model then
          Result.append ("%Nmodel:")
          Result.append (l_model.out)
          Result.append ("%N")
        end
        if attached frequency_penalty as l_frequency_penalty then
          Result.append ("%Nfrequency_penalty:")
          Result.append (l_frequency_penalty.out)
          Result.append ("%N")
        end
        if attached logit_bias as l_logit_bias then
          Result.append ("%Nlogit_bias:")
          across l_logit_bias as ic loop
            Result.append ("%N")
            Result.append ("key:")
            Result.append (ic.key.out)
            Result.append (" - ")
            Result.append ("val:")
            Result.append (ic.item.out)
            Result.append ("%N")
          end
        end
        if attached logprobs as l_logprobs then
          Result.append ("%Nlogprobs:")
          Result.append (l_logprobs.out)
          Result.append ("%N")
        end
        if attached top_logprobs as l_top_logprobs then
          Result.append ("%Ntop_logprobs:")
          Result.append (l_top_logprobs.out)
          Result.append ("%N")
        end
        if attached max_tokens as l_max_tokens then
          Result.append ("%Nmax_tokens:")
          Result.append (l_max_tokens.out)
          Result.append ("%N")
        end
        if attached n as l_n then
          Result.append ("%Nn:")
          Result.append (l_n.out)
          Result.append ("%N")
        end
        if attached presence_penalty as l_presence_penalty then
          Result.append ("%Npresence_penalty:")
          Result.append (l_presence_penalty.out)
          Result.append ("%N")
        end
        if attached response_format as l_response_format then
          Result.append ("%Nresponse_format:")
          Result.append (l_response_format.out)
          Result.append ("%N")
        end
        if attached seed as l_seed then
          Result.append ("%Nseed:")
          Result.append (l_seed.out)
          Result.append ("%N")
        end
        if attached stop as l_stop then
          Result.append ("%Nstop:")
          Result.append (l_stop.out)
          Result.append ("%N")
        end
        if attached stream as l_stream then
          Result.append ("%Nstream:")
          Result.append (l_stream.out)
          Result.append ("%N")
        end
        if attached temperature as l_temperature then
          Result.append ("%Ntemperature:")
          Result.append (l_temperature.out)
          Result.append ("%N")
        end
        if attached top_p as l_top_p then
          Result.append ("%Ntop_p:")
          Result.append (l_top_p.out)
          Result.append ("%N")
        end
        if attached tools as l_tools then
          across l_tools as ic loop
            Result.append ("%N tools:")
            Result.append (ic.item.out)
            Result.append ("%N")
          end
        end
        if attached tool_choice as l_tool_choice then
          Result.append ("%Ntool_choice:")
          Result.append (l_tool_choice.out)
          Result.append ("%N")
        end
        if attached user as l_user then
          Result.append ("%Nuser:")
          Result.append (l_user.out)
          Result.append ("%N")
        end
        if attached function_call as l_function_call then
          Result.append ("%Nfunction_call:")
          Result.append (l_function_call.out)
          Result.append ("%N")
        end
        if attached functions as l_functions then
          across l_functions as ic loop
            Result.append ("%N functions:")
            Result.append (ic.item.out)
            Result.append ("%N")
          end
        end
      end
end

