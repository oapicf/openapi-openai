# 
# OpenAI API
# 
# 
# The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
# 
# Version: 2.3.0
# Contact: blah+oapicf@cliffano.com
# Generated by OpenAPI Generator: https://openapi-generator.tech

# Represents a streamed chunk of a chat completion response returned by model, based on the provided input.
type CreateChatCompletionStreamResponse {
  # A unique identifier for the chat completion. Each chunk has the same ID.
  id: String!
  # A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the last chunk if you set `stream_options: {\"include_usage\": true}`. 
  choices: [CreateChatCompletionStreamResponseChoicesInner!]
  # The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
  created: Int!
  # The model to generate the completion.
  model: String!
  # The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.
  service_tier: ServiceTierEnum
  # This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism. 
  system_fingerprint: String!
  # The object type, which is always `chat.completion.chunk`.
  object: ObjectEnum
  usage: CreateChatCompletionStreamResponseUsage
}

input CreateChatCompletionStreamResponseInput {
    # A unique identifier for the chat completion. Each chunk has the same ID.
    id: String!
    # A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the last chunk if you set `stream_options: {\"include_usage\": true}`. 
    choices: [CreateChatCompletionStreamResponseChoicesInnerInput]
    # The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
    created: Int!
    # The model to generate the completion.
    model: String!
    # The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.
    service_tier: ServiceTierEnum
    # This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism. 
    system_fingerprint: String!
    # The object type, which is always `chat.completion.chunk`.
    object: ObjectEnum
    usage: CreateChatCompletionStreamResponseUsageInput
}

