/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */

import ApiClient from '../ApiClient';

/**
 * The RealtimeServerEventInputAudioBufferSpeechStarted model module.
 * @module model/RealtimeServerEventInputAudioBufferSpeechStarted
 * @version 1.1.1-pre.0
 */
class RealtimeServerEventInputAudioBufferSpeechStarted {
    /**
     * Constructs a new <code>RealtimeServerEventInputAudioBufferSpeechStarted</code>.
     * Sent by the server when in &#x60;server_vad&#x60; mode to indicate that speech has been  detected in the audio buffer. This can happen any time audio is added to the  buffer (unless speech is already detected). The client may want to use this  event to interrupt audio playback or provide visual feedback to the user.   The client should expect to receive a &#x60;input_audio_buffer.speech_stopped&#x60; event  when speech stops. The &#x60;item_id&#x60; property is the ID of the user message item  that will be created when speech stops and will also be included in the  &#x60;input_audio_buffer.speech_stopped&#x60; event (unless the client manually commits  the audio buffer during VAD activation). 
     * @alias module:model/RealtimeServerEventInputAudioBufferSpeechStarted
     * @param eventId {String} The unique ID of the server event.
     * @param type {module:model/RealtimeServerEventInputAudioBufferSpeechStarted.TypeEnum} The event type, must be `input_audio_buffer.speech_started`.
     * @param audioStartMs {Number} Milliseconds from the start of all audio written to the buffer during the  session when speech was first detected. This will correspond to the  beginning of audio sent to the model, and thus includes the  `prefix_padding_ms` configured in the Session. 
     * @param itemId {String} The ID of the user message item that will be created when speech stops. 
     */
    constructor(eventId, type, audioStartMs, itemId) { 
        
        RealtimeServerEventInputAudioBufferSpeechStarted.initialize(this, eventId, type, audioStartMs, itemId);
    }

    /**
     * Initializes the fields of this object.
     * This method is used by the constructors of any subclasses, in order to implement multiple inheritance (mix-ins).
     * Only for internal use.
     */
    static initialize(obj, eventId, type, audioStartMs, itemId) { 
        obj['event_id'] = eventId;
        obj['type'] = type;
        obj['audio_start_ms'] = audioStartMs;
        obj['item_id'] = itemId;
    }

    /**
     * Constructs a <code>RealtimeServerEventInputAudioBufferSpeechStarted</code> from a plain JavaScript object, optionally creating a new instance.
     * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @param {module:model/RealtimeServerEventInputAudioBufferSpeechStarted} obj Optional instance to populate.
     * @return {module:model/RealtimeServerEventInputAudioBufferSpeechStarted} The populated <code>RealtimeServerEventInputAudioBufferSpeechStarted</code> instance.
     */
    static constructFromObject(data, obj) {
        if (data) {
            obj = obj || new RealtimeServerEventInputAudioBufferSpeechStarted();

            if (data.hasOwnProperty('event_id')) {
                obj['event_id'] = ApiClient.convertToType(data['event_id'], 'String');
            }
            if (data.hasOwnProperty('type')) {
                obj['type'] = ApiClient.convertToType(data['type'], 'String');
            }
            if (data.hasOwnProperty('audio_start_ms')) {
                obj['audio_start_ms'] = ApiClient.convertToType(data['audio_start_ms'], 'Number');
            }
            if (data.hasOwnProperty('item_id')) {
                obj['item_id'] = ApiClient.convertToType(data['item_id'], 'String');
            }
        }
        return obj;
    }

    /**
     * Validates the JSON data with respect to <code>RealtimeServerEventInputAudioBufferSpeechStarted</code>.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @return {boolean} to indicate whether the JSON data is valid with respect to <code>RealtimeServerEventInputAudioBufferSpeechStarted</code>.
     */
    static validateJSON(data) {
        // check to make sure all required properties are present in the JSON string
        for (const property of RealtimeServerEventInputAudioBufferSpeechStarted.RequiredProperties) {
            if (!data.hasOwnProperty(property)) {
                throw new Error("The required field `" + property + "` is not found in the JSON data: " + JSON.stringify(data));
            }
        }
        // ensure the json data is a string
        if (data['event_id'] && !(typeof data['event_id'] === 'string' || data['event_id'] instanceof String)) {
            throw new Error("Expected the field `event_id` to be a primitive type in the JSON string but got " + data['event_id']);
        }
        // ensure the json data is a string
        if (data['type'] && !(typeof data['type'] === 'string' || data['type'] instanceof String)) {
            throw new Error("Expected the field `type` to be a primitive type in the JSON string but got " + data['type']);
        }
        // ensure the json data is a string
        if (data['item_id'] && !(typeof data['item_id'] === 'string' || data['item_id'] instanceof String)) {
            throw new Error("Expected the field `item_id` to be a primitive type in the JSON string but got " + data['item_id']);
        }

        return true;
    }


}

RealtimeServerEventInputAudioBufferSpeechStarted.RequiredProperties = ["event_id", "type", "audio_start_ms", "item_id"];

/**
 * The unique ID of the server event.
 * @member {String} event_id
 */
RealtimeServerEventInputAudioBufferSpeechStarted.prototype['event_id'] = undefined;

/**
 * The event type, must be `input_audio_buffer.speech_started`.
 * @member {module:model/RealtimeServerEventInputAudioBufferSpeechStarted.TypeEnum} type
 */
RealtimeServerEventInputAudioBufferSpeechStarted.prototype['type'] = undefined;

/**
 * Milliseconds from the start of all audio written to the buffer during the  session when speech was first detected. This will correspond to the  beginning of audio sent to the model, and thus includes the  `prefix_padding_ms` configured in the Session. 
 * @member {Number} audio_start_ms
 */
RealtimeServerEventInputAudioBufferSpeechStarted.prototype['audio_start_ms'] = undefined;

/**
 * The ID of the user message item that will be created when speech stops. 
 * @member {String} item_id
 */
RealtimeServerEventInputAudioBufferSpeechStarted.prototype['item_id'] = undefined;





/**
 * Allowed values for the <code>type</code> property.
 * @enum {String}
 * @readonly
 */
RealtimeServerEventInputAudioBufferSpeechStarted['TypeEnum'] = {

    /**
     * value: "input_audio_buffer.speech_started"
     * @const
     */
    "input_audio_buffer.speech_started": "input_audio_buffer.speech_started"
};



export default RealtimeServerEventInputAudioBufferSpeechStarted;

