/**
* OpenAI API
* The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
*
* The version of the OpenAPI document: 2.3.0
* Contact: blah+oapicf@cliffano.com
*
* NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
* https://openapi-generator.tech
* Do not edit the class manually.
*/
package org.openapitools.server.models


import kotlinx.serialization.Serializable
/**
 * Returned in `server_vad` mode when the server detects the end of speech in  the audio buffer. The server will also send an `conversation.item.created`  event with the user message item that is created from the audio buffer. 
 * @param eventId The unique ID of the server event.
 * @param type The event type, must be `input_audio_buffer.speech_stopped`.
 * @param audioEndMs Milliseconds since the session started when speech stopped. This will  correspond to the end of audio sent to the model, and thus includes the  `min_silence_duration_ms` configured in the Session. 
 * @param itemId The ID of the user message item that will be created.
 */
@Serializable
data class RealtimeServerEventInputAudioBufferSpeechStopped(
    /* The unique ID of the server event. */
    val eventId: kotlin.String,
    /* The event type, must be `input_audio_buffer.speech_stopped`. */
    val type: RealtimeServerEventInputAudioBufferSpeechStopped.Type,
    /* Milliseconds since the session started when speech stopped. This will  correspond to the end of audio sent to the model, and thus includes the  `min_silence_duration_ms` configured in the Session.  */
    val audioEndMs: kotlin.Int,
    /* The ID of the user message item that will be created. */
    val itemId: kotlin.String
)
{
    /**
    * The event type, must be `input_audio_buffer.speech_stopped`.
    * Values: input_audio_bufferPeriodSpeech_stopped
    */
    enum class Type(val value: kotlin.String){
        input_audio_bufferPeriodSpeech_stopped("input_audio_buffer.speech_stopped");
    }
}

