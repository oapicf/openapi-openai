/**
* OpenAI API
* The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
*
* The version of the OpenAPI document: 2.3.0
* Contact: blah+oapicf@cliffano.com
*
* NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
* https://openapi-generator.tech
* Do not edit the class manually.
*/
package org.openapitools.server.api.model

import org.openapitools.server.api.model.ResponseFormatJsonObject
import org.openapitools.server.api.model.ResponseFormatJsonSchema
import org.openapitools.server.api.model.ResponseFormatJsonSchemaJsonSchema
import org.openapitools.server.api.model.ResponseFormatText

        
import com.google.gson.annotations.SerializedName
import com.fasterxml.jackson.annotation.JsonIgnoreProperties
import com.fasterxml.jackson.annotation.JsonInclude
/**
 * An object specifying the format that the model must output.  Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).  Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.  **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length. 
 * @param type The type of response format being defined: `text`
 * @param jsonSchema 
 */
@JsonInclude(JsonInclude.Include.NON_NULL)
@JsonIgnoreProperties(ignoreUnknown = true)
data class CreateChatCompletionRequestResponseFormat (
    /* The type of response format being defined: `text` */
    @SerializedName("type") private val _type: CreateChatCompletionRequestResponseFormat.Type?,
    @SerializedName("jsonSchema") private val _jsonSchema: ResponseFormatJsonSchemaJsonSchema?
) {

    /**
    * The type of response format being defined: `text`
    * Values: text,json_object,json_schema
    */
    enum class Type(val value: kotlin.String){
    
        text("text"),
    
        json_object("json_object"),
    
        json_schema("json_schema");
    
    }

        val type get() = _type ?: throw IllegalArgumentException("type is required")
                    
        val jsonSchema get() = _jsonSchema ?: throw IllegalArgumentException("jsonSchema is required")
                    
}

