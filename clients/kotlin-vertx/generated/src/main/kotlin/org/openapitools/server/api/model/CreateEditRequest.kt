/**
* OpenAI API
* APIs for sampling from and fine-tuning language models
*
* The version of the OpenAPI document: 2.0.0
* Contact: blah+oapicf@cliffano.com
*
* NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
* https://openapi-generator.tech
* Do not edit the class manually.
*/
package org.openapitools.server.api.model

import org.openapitools.server.api.model.CreateEditRequestModel

        
import com.google.gson.annotations.SerializedName
import com.fasterxml.jackson.annotation.JsonIgnoreProperties
import com.fasterxml.jackson.annotation.JsonInclude
/**
 * 
 * @param model 
 * @param instruction The instruction that tells the model how to edit the prompt.
 * @param input The input text to use as a starting point for the edit.
 * @param n How many edits to generate for the input and instruction.
 * @param temperature What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.  We generally recommend altering this or `top_p` but not both. 
 * @param topP An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.  We generally recommend altering this or `temperature` but not both. 
 */
@JsonInclude(JsonInclude.Include.NON_NULL)
@JsonIgnoreProperties(ignoreUnknown = true)
data class CreateEditRequest (
    @SerializedName("model") private val _model: CreateEditRequestModel?,
    /* The instruction that tells the model how to edit the prompt. */
    @SerializedName("instruction") private val _instruction: kotlin.String?,
    /* The input text to use as a starting point for the edit. */
    val input: kotlin.String? = "",
    /* How many edits to generate for the input and instruction. */
    val n: kotlin.Int? = 1,
    /* What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.  We generally recommend altering this or `top_p` but not both.  */
    val temperature: java.math.BigDecimal? = 1,
    /* An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.  We generally recommend altering this or `temperature` but not both.  */
    val topP: java.math.BigDecimal? = 1
) {

        val model get() = _model ?: throw IllegalArgumentException("model is required")
                    
        val instruction get() = _instruction ?: throw IllegalArgumentException("instruction is required")
                    
}

