/**
* OpenAI API
* The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
*
* The version of the OpenAPI document: 2.3.0
* Contact: blah+oapicf@cliffano.com
*
* NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
* https://openapi-generator.tech
* Do not edit the class manually.
*/
package org.openapitools.server.api.model


        
import com.google.gson.annotations.SerializedName
import com.fasterxml.jackson.annotation.JsonIgnoreProperties
import com.fasterxml.jackson.annotation.JsonInclude
/**
 * A list of the categories along with the input type(s) that the score applies to.
 * @param hate The applied input type(s) for the category 'hate'.
 * @param hateThreatening The applied input type(s) for the category 'hate/threatening'.
 * @param harassment The applied input type(s) for the category 'harassment'.
 * @param harassmentThreatening The applied input type(s) for the category 'harassment/threatening'.
 * @param illicit The applied input type(s) for the category 'illicit'.
 * @param illicitViolent The applied input type(s) for the category 'illicit/violent'.
 * @param selfHarm The applied input type(s) for the category 'self-harm'.
 * @param selfHarmIntent The applied input type(s) for the category 'self-harm/intent'.
 * @param selfHarmInstructions The applied input type(s) for the category 'self-harm/instructions'.
 * @param sexual The applied input type(s) for the category 'sexual'.
 * @param sexualMinors The applied input type(s) for the category 'sexual/minors'.
 * @param violence The applied input type(s) for the category 'violence'.
 * @param violenceGraphic The applied input type(s) for the category 'violence/graphic'.
 */
@JsonInclude(JsonInclude.Include.NON_NULL)
@JsonIgnoreProperties(ignoreUnknown = true)
data class CreateModerationResponseResultsInnerCategoryAppliedInputTypes (
    /* The applied input type(s) for the category 'hate'. */
    @SerializedName("hate") private val _hate: CreateModerationResponseResultsInnerCategoryAppliedInputTypes.Hate?,
    /* The applied input type(s) for the category 'hate/threatening'. */
    @SerializedName("hateThreatening") private val _hateThreatening: CreateModerationResponseResultsInnerCategoryAppliedInputTypes.HateThreatening?,
    /* The applied input type(s) for the category 'harassment'. */
    @SerializedName("harassment") private val _harassment: CreateModerationResponseResultsInnerCategoryAppliedInputTypes.Harassment?,
    /* The applied input type(s) for the category 'harassment/threatening'. */
    @SerializedName("harassmentThreatening") private val _harassmentThreatening: CreateModerationResponseResultsInnerCategoryAppliedInputTypes.HarassmentThreatening?,
    /* The applied input type(s) for the category 'illicit'. */
    @SerializedName("illicit") private val _illicit: CreateModerationResponseResultsInnerCategoryAppliedInputTypes.Illicit?,
    /* The applied input type(s) for the category 'illicit/violent'. */
    @SerializedName("illicitViolent") private val _illicitViolent: CreateModerationResponseResultsInnerCategoryAppliedInputTypes.IllicitViolent?,
    /* The applied input type(s) for the category 'self-harm'. */
    @SerializedName("selfHarm") private val _selfHarm: CreateModerationResponseResultsInnerCategoryAppliedInputTypes.SelfHarm?,
    /* The applied input type(s) for the category 'self-harm/intent'. */
    @SerializedName("selfHarmIntent") private val _selfHarmIntent: CreateModerationResponseResultsInnerCategoryAppliedInputTypes.SelfHarmIntent?,
    /* The applied input type(s) for the category 'self-harm/instructions'. */
    @SerializedName("selfHarmInstructions") private val _selfHarmInstructions: CreateModerationResponseResultsInnerCategoryAppliedInputTypes.SelfHarmInstructions?,
    /* The applied input type(s) for the category 'sexual'. */
    @SerializedName("sexual") private val _sexual: CreateModerationResponseResultsInnerCategoryAppliedInputTypes.Sexual?,
    /* The applied input type(s) for the category 'sexual/minors'. */
    @SerializedName("sexualMinors") private val _sexualMinors: CreateModerationResponseResultsInnerCategoryAppliedInputTypes.SexualMinors?,
    /* The applied input type(s) for the category 'violence'. */
    @SerializedName("violence") private val _violence: CreateModerationResponseResultsInnerCategoryAppliedInputTypes.Violence?,
    /* The applied input type(s) for the category 'violence/graphic'. */
    @SerializedName("violenceGraphic") private val _violenceGraphic: CreateModerationResponseResultsInnerCategoryAppliedInputTypes.ViolenceGraphic?
) {

    /**
    * The applied input type(s) for the category 'hate'.
    * Values: text
    */
    enum class Hate(val value: kotlin.Array&lt;kotlin.String&gt;){
    
        text("text");
    
    }

    /**
    * The applied input type(s) for the category 'hate/threatening'.
    * Values: text
    */
    enum class HateThreatening(val value: kotlin.Array&lt;kotlin.String&gt;){
    
        text("text");
    
    }

    /**
    * The applied input type(s) for the category 'harassment'.
    * Values: text
    */
    enum class Harassment(val value: kotlin.Array&lt;kotlin.String&gt;){
    
        text("text");
    
    }

    /**
    * The applied input type(s) for the category 'harassment/threatening'.
    * Values: text
    */
    enum class HarassmentThreatening(val value: kotlin.Array&lt;kotlin.String&gt;){
    
        text("text");
    
    }

    /**
    * The applied input type(s) for the category 'illicit'.
    * Values: text
    */
    enum class Illicit(val value: kotlin.Array&lt;kotlin.String&gt;){
    
        text("text");
    
    }

    /**
    * The applied input type(s) for the category 'illicit/violent'.
    * Values: text
    */
    enum class IllicitViolent(val value: kotlin.Array&lt;kotlin.String&gt;){
    
        text("text");
    
    }

    /**
    * The applied input type(s) for the category 'self-harm'.
    * Values: text,image
    */
    enum class SelfHarm(val value: kotlin.Array&lt;kotlin.String&gt;){
    
        text("text"),
    
        image("image");
    
    }

    /**
    * The applied input type(s) for the category 'self-harm/intent'.
    * Values: text,image
    */
    enum class SelfHarmIntent(val value: kotlin.Array&lt;kotlin.String&gt;){
    
        text("text"),
    
        image("image");
    
    }

    /**
    * The applied input type(s) for the category 'self-harm/instructions'.
    * Values: text,image
    */
    enum class SelfHarmInstructions(val value: kotlin.Array&lt;kotlin.String&gt;){
    
        text("text"),
    
        image("image");
    
    }

    /**
    * The applied input type(s) for the category 'sexual'.
    * Values: text,image
    */
    enum class Sexual(val value: kotlin.Array&lt;kotlin.String&gt;){
    
        text("text"),
    
        image("image");
    
    }

    /**
    * The applied input type(s) for the category 'sexual/minors'.
    * Values: text
    */
    enum class SexualMinors(val value: kotlin.Array&lt;kotlin.String&gt;){
    
        text("text");
    
    }

    /**
    * The applied input type(s) for the category 'violence'.
    * Values: text,image
    */
    enum class Violence(val value: kotlin.Array&lt;kotlin.String&gt;){
    
        text("text"),
    
        image("image");
    
    }

    /**
    * The applied input type(s) for the category 'violence/graphic'.
    * Values: text,image
    */
    enum class ViolenceGraphic(val value: kotlin.Array&lt;kotlin.String&gt;){
    
        text("text"),
    
        image("image");
    
    }

        val hate get() = _hate ?: throw IllegalArgumentException("hate is required")
                    
        val hateThreatening get() = _hateThreatening ?: throw IllegalArgumentException("hateThreatening is required")
                    
        val harassment get() = _harassment ?: throw IllegalArgumentException("harassment is required")
                    
        val harassmentThreatening get() = _harassmentThreatening ?: throw IllegalArgumentException("harassmentThreatening is required")
                    
        val illicit get() = _illicit ?: throw IllegalArgumentException("illicit is required")
                    
        val illicitViolent get() = _illicitViolent ?: throw IllegalArgumentException("illicitViolent is required")
                    
        val selfHarm get() = _selfHarm ?: throw IllegalArgumentException("selfHarm is required")
                    
        val selfHarmIntent get() = _selfHarmIntent ?: throw IllegalArgumentException("selfHarmIntent is required")
                    
        val selfHarmInstructions get() = _selfHarmInstructions ?: throw IllegalArgumentException("selfHarmInstructions is required")
                    
        val sexual get() = _sexual ?: throw IllegalArgumentException("sexual is required")
                    
        val sexualMinors get() = _sexualMinors ?: throw IllegalArgumentException("sexualMinors is required")
                    
        val violence get() = _violence ?: throw IllegalArgumentException("violence is required")
                    
        val violenceGraphic get() = _violenceGraphic ?: throw IllegalArgumentException("violenceGraphic is required")
                    
}

