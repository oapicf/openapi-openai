--[[
  OpenAI API

  The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.

  The version of the OpenAPI document: 2.3.0
  Contact: blah+oapicf@cliffano.com
  Generated by: https://openapi-generator.tech
]]

-- create_chat_completion_request class
local create_chat_completion_request = {}
local create_chat_completion_request_mt = {
	__name = "create_chat_completion_request";
	__index = create_chat_completion_request;
}

local function cast_create_chat_completion_request(t)
	return setmetatable(t, create_chat_completion_request_mt)
end

local function new_create_chat_completion_request(messages, model, store, reasoning_effort, metadata, frequency_penalty, logit_bias, logprobs, top_logprobs, max_tokens, max_completion_tokens, n, modalities, prediction, audio, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, top_p, tools, tool_choice, parallel_tool_calls, user, function_call, functions)
	return cast_create_chat_completion_request({
		["messages"] = messages;
		["model"] = model;
		["store"] = store;
		["reasoning_effort"] = reasoning_effort;
		["metadata"] = metadata;
		["frequency_penalty"] = frequency_penalty;
		["logit_bias"] = logit_bias;
		["logprobs"] = logprobs;
		["top_logprobs"] = top_logprobs;
		["max_tokens"] = max_tokens;
		["max_completion_tokens"] = max_completion_tokens;
		["n"] = n;
		["modalities"] = modalities;
		["prediction"] = prediction;
		["audio"] = audio;
		["presence_penalty"] = presence_penalty;
		["response_format"] = response_format;
		["seed"] = seed;
		["service_tier"] = service_tier;
		["stop"] = stop;
		["stream"] = stream;
		["stream_options"] = stream_options;
		["temperature"] = temperature;
		["top_p"] = top_p;
		["tools"] = tools;
		["tool_choice"] = tool_choice;
		["parallel_tool_calls"] = parallel_tool_calls;
		["user"] = user;
		["function_call"] = function_call;
		["functions"] = functions;
	})
end

return {
	cast = cast_create_chat_completion_request;
	new = new_create_chat_completion_request;
}
