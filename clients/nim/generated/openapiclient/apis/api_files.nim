#
# OpenAI API
# 
# The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
# The version of the OpenAPI document: 2.3.0
# Contact: blah+oapicf@cliffano.com
# Generated by: https://openapi-generator.tech
#

import httpclient
import json
import logging
import marshal
import options
import strformat
import strutils
import tables
import typetraits
import uri

import ../models/model_delete_file_response
import ../models/model_list_files_response
import ../models/model_open_ai_file

const basepath = "https://api.openai.com/v1"

template constructResult[T](response: Response): untyped =
  if response.code in {Http200, Http201, Http202, Http204, Http206}:
    try:
      (some(to(parseJson(response.body), T)), response)
    except JsonParsingError:
      # The server returned a malformed response though the response code is 2XX
      # TODO: need better error handling
      error("JsonParsingError")
      (none(T.typedesc), response)
  else:
    (none(T.typedesc), response)


proc createFile*(httpClient: HttpClient, file: string, purpose: string): (Option[OpenAIFile], Response) =
  ## Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.  The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.  The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.  The Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).  Please [contact us](https://help.openai.com/) if you need to increase these storage limits. 
  httpClient.headers["Content-Type"] = "multipart/form-data"
  let multipart_data = newMultipartData({
    "file": $file, # The File object (not file name) to be uploaded. 
    "purpose": $purpose, # The intended purpose of the uploaded file.  Use \\\"assistants\\\" for [Assistants](/docs/api-reference/assistants) and [Message](/docs/api-reference/messages) files, \\\"vision\\\" for Assistants image file inputs, \\\"batch\\\" for [Batch API](/docs/guides/batch), and \\\"fine-tune\\\" for [Fine-tuning](/docs/api-reference/fine-tuning). 
  })

  let response = httpClient.post(basepath & "/files", multipart=multipart_data)
  constructResult[OpenAIFile](response)


proc deleteFile*(httpClient: HttpClient, fileId: string): (Option[DeleteFileResponse], Response) =
  ## Delete a file.

  let response = httpClient.delete(basepath & fmt"/files/{file_id}")
  constructResult[DeleteFileResponse](response)


proc downloadFile*(httpClient: HttpClient, fileId: string): (Option[string], Response) =
  ## Returns the contents of the specified file.

  let response = httpClient.get(basepath & fmt"/files/{file_id}/content")
  constructResult[string](response)


proc listFiles*(httpClient: HttpClient, purpose: string, limit: int, order: string, after: string): (Option[ListFilesResponse], Response) =
  ## Returns a list of files.
  var query_params_list: seq[(string, string)] = @[]
  if $purpose != "":
    query_params_list.add(("purpose", $purpose))
  if $limit != "":
    query_params_list.add(("limit", $limit))
  if $order != "":
    query_params_list.add(("order", $order))
  if $after != "":
    query_params_list.add(("after", $after))
  let url_encoded_query_params = encodeQuery(query_params_list)

  let response = httpClient.get(basepath & "/files" & "?" & url_encoded_query_params)
  constructResult[ListFilesResponse](response)


proc retrieveFile*(httpClient: HttpClient, fileId: string): (Option[OpenAIFile], Response) =
  ## Returns information about a specific file.

  let response = httpClient.get(basepath & fmt"/files/{file_id}")
  constructResult[OpenAIFile](response)

