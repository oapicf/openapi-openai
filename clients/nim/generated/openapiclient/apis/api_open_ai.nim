#
# OpenAI API
# 
# APIs for sampling from and fine-tuning language models
# The version of the OpenAPI document: 2.0.0
# Contact: blah+oapicf@cliffano.com
# Generated by: https://openapi-generator.tech
#

import httpclient
import json
import logging
import marshal
import options
import strformat
import strutils
import tables
import typetraits
import uri

import ../models/model_create_chat_completion_request
import ../models/model_create_chat_completion_response
import ../models/model_create_completion_request
import ../models/model_create_completion_response
import ../models/model_create_edit_request
import ../models/model_create_edit_response
import ../models/model_create_embedding_request
import ../models/model_create_embedding_response
import ../models/model_create_fine_tune_request
import ../models/model_create_image_request
import ../models/model_create_moderation_request
import ../models/model_create_moderation_response
import ../models/model_create_transcription_request_model
import ../models/model_create_transcription_response
import ../models/model_create_translation_response
import ../models/model_delete_file_response
import ../models/model_delete_model_response
import ../models/model_fine_tune
import ../models/model_images_response
import ../models/model_list_files_response
import ../models/model_list_fine_tune_events_response
import ../models/model_list_fine_tunes_response
import ../models/model_list_models_response
import ../models/model_model
import ../models/model_open_ai_file

const basepath = "https://api.openai.com/v1"

template constructResult[T](response: Response): untyped =
  if response.code in {Http200, Http201, Http202, Http204, Http206}:
    try:
      when name(stripGenericParams(T.typedesc).typedesc) == name(Table):
        (some(json.to(parseJson(response.body), T.typedesc)), response)
      else:
        (some(marshal.to[T](response.body)), response)
    except JsonParsingError:
      # The server returned a malformed response though the response code is 2XX
      # TODO: need better error handling
      error("JsonParsingError")
      (none(T.typedesc), response)
  else:
    (none(T.typedesc), response)


proc cancelFineTune*(httpClient: HttpClient, fineTuneId: string): (Option[FineTune], Response) =
  ## Immediately cancel a fine-tune job. 

  let response = httpClient.post(basepath & fmt"/fine-tunes/{fine_tune_id}/cancel")
  constructResult[FineTune](response)


proc createChatCompletion*(httpClient: HttpClient, createChatCompletionRequest: CreateChatCompletionRequest): (Option[CreateChatCompletionResponse], Response) =
  ## Creates a model response for the given chat conversation.
  httpClient.headers["Content-Type"] = "application/json"

  let response = httpClient.post(basepath & "/chat/completions", $(%createChatCompletionRequest))
  constructResult[CreateChatCompletionResponse](response)


proc createCompletion*(httpClient: HttpClient, createCompletionRequest: CreateCompletionRequest): (Option[CreateCompletionResponse], Response) =
  ## Creates a completion for the provided prompt and parameters.
  httpClient.headers["Content-Type"] = "application/json"

  let response = httpClient.post(basepath & "/completions", $(%createCompletionRequest))
  constructResult[CreateCompletionResponse](response)


proc createEdit*(httpClient: HttpClient, createEditRequest: CreateEditRequest): (Option[CreateEditResponse], Response) =
  ## Creates a new edit for the provided input, instruction, and parameters.
  httpClient.headers["Content-Type"] = "application/json"

  let response = httpClient.post(basepath & "/edits", $(%createEditRequest))
  constructResult[CreateEditResponse](response)


proc createEmbedding*(httpClient: HttpClient, createEmbeddingRequest: CreateEmbeddingRequest): (Option[CreateEmbeddingResponse], Response) =
  ## Creates an embedding vector representing the input text.
  httpClient.headers["Content-Type"] = "application/json"

  let response = httpClient.post(basepath & "/embeddings", $(%createEmbeddingRequest))
  constructResult[CreateEmbeddingResponse](response)


proc createFile*(httpClient: HttpClient, file: string, purpose: string): (Option[OpenAIFile], Response) =
  ## Upload a file that contains document(s) to be used across various endpoints/features. Currently, the size of all the files uploaded by one organization can be up to 1 GB. Please contact us if you need to increase the storage limit. 
  httpClient.headers["Content-Type"] = "multipart/form-data"
  let query_for_api_call = newMultipartData({
    "file": $file, # Name of the [JSON Lines](https://jsonlines.readthedocs.io/en/latest/) file to be uploaded.  If the `purpose` is set to \\\"fine-tune\\\", each line is a JSON record with \\\"prompt\\\" and \\\"completion\\\" fields representing your [training examples](/docs/guides/fine-tuning/prepare-training-data). 
    "purpose": $purpose, # The intended purpose of the uploaded documents.  Use \\\"fine-tune\\\" for [Fine-tuning](/docs/api-reference/fine-tunes). This allows us to validate the format of the uploaded file. 
  })

  let response = httpClient.post(basepath & "/files", multipart=query_for_api_call)
  constructResult[OpenAIFile](response)


proc createFineTune*(httpClient: HttpClient, createFineTuneRequest: CreateFineTuneRequest): (Option[FineTune], Response) =
  ## Creates a job that fine-tunes a specified model from a given dataset.  Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.  [Learn more about Fine-tuning](/docs/guides/fine-tuning) 
  httpClient.headers["Content-Type"] = "application/json"

  let response = httpClient.post(basepath & "/fine-tunes", $(%createFineTuneRequest))
  constructResult[FineTune](response)


proc createImage*(httpClient: HttpClient, createImageRequest: CreateImageRequest): (Option[ImagesResponse], Response) =
  ## Creates an image given a prompt.
  httpClient.headers["Content-Type"] = "application/json"

  let response = httpClient.post(basepath & "/images/generations", $(%createImageRequest))
  constructResult[ImagesResponse](response)


proc createImageEdit*(httpClient: HttpClient, image: string, prompt: string, mask: string, n: int, size: string, responseFormat: string, user: string): (Option[ImagesResponse], Response) =
  ## Creates an edited or extended image given an original image and a prompt.
  httpClient.headers["Content-Type"] = "multipart/form-data"
  let query_for_api_call = newMultipartData({
    "image": $image, # The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.
    "mask": $mask, # An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.
    "prompt": $prompt, # A text description of the desired image(s). The maximum length is 1000 characters.
    "n": $n, # The number of images to generate. Must be between 1 and 10.
    "size": $size, # The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.
    "response_format": $responseFormat, # The format in which the generated images are returned. Must be one of `url` or `b64_json`.
    "user": $user, # A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids). 
  })

  let response = httpClient.post(basepath & "/images/edits", multipart=query_for_api_call)
  constructResult[ImagesResponse](response)


proc createImageVariation*(httpClient: HttpClient, image: string, n: int, size: string, responseFormat: string, user: string): (Option[ImagesResponse], Response) =
  ## Creates a variation of a given image.
  httpClient.headers["Content-Type"] = "multipart/form-data"
  let query_for_api_call = newMultipartData({
    "image": $image, # The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.
    "n": $n, # The number of images to generate. Must be between 1 and 10.
    "size": $size, # The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.
    "response_format": $responseFormat, # The format in which the generated images are returned. Must be one of `url` or `b64_json`.
    "user": $user, # A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids). 
  })

  let response = httpClient.post(basepath & "/images/variations", multipart=query_for_api_call)
  constructResult[ImagesResponse](response)


proc createModeration*(httpClient: HttpClient, createModerationRequest: CreateModerationRequest): (Option[CreateModerationResponse], Response) =
  ## Classifies if text violates OpenAI's Content Policy
  httpClient.headers["Content-Type"] = "application/json"

  let response = httpClient.post(basepath & "/moderations", $(%createModerationRequest))
  constructResult[CreateModerationResponse](response)


proc createTranscription*(httpClient: HttpClient, file: string, model: CreateTranscriptionRequest_model, prompt: string, responseFormat: string, temperature: float, language: string): (Option[CreateTranscriptionResponse], Response) =
  ## Transcribes audio into the input language.
  httpClient.headers["Content-Type"] = "multipart/form-data"
  let query_for_api_call = newMultipartData({
    "file": $file, # The audio file object (not file name) to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm. 
    "model": $model, # 
    "prompt": $prompt, # An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language. 
    "response_format": $responseFormat, # The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt. 
    "temperature": $temperature, # The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit. 
    "language": $language, # The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency. 
  })

  let response = httpClient.post(basepath & "/audio/transcriptions", multipart=query_for_api_call)
  constructResult[CreateTranscriptionResponse](response)


proc createTranslation*(httpClient: HttpClient, file: string, model: CreateTranscriptionRequest_model, prompt: string, responseFormat: string, temperature: float): (Option[CreateTranslationResponse], Response) =
  ## Translates audio into English.
  httpClient.headers["Content-Type"] = "multipart/form-data"
  let query_for_api_call = newMultipartData({
    "file": $file, # The audio file object (not file name) translate, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm. 
    "model": $model, # 
    "prompt": $prompt, # An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English. 
    "response_format": $responseFormat, # The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt. 
    "temperature": $temperature, # The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit. 
  })

  let response = httpClient.post(basepath & "/audio/translations", multipart=query_for_api_call)
  constructResult[CreateTranslationResponse](response)


proc deleteFile*(httpClient: HttpClient, fileId: string): (Option[DeleteFileResponse], Response) =
  ## Delete a file.

  let response = httpClient.delete(basepath & fmt"/files/{file_id}")
  constructResult[DeleteFileResponse](response)


proc deleteModel*(httpClient: HttpClient, model: string): (Option[DeleteModelResponse], Response) =
  ## Delete a fine-tuned model. You must have the Owner role in your organization.

  let response = httpClient.delete(basepath & fmt"/models/{model}")
  constructResult[DeleteModelResponse](response)


proc downloadFile*(httpClient: HttpClient, fileId: string): (Option[string], Response) =
  ## Returns the contents of the specified file

  let response = httpClient.get(basepath & fmt"/files/{file_id}/content")
  constructResult[string](response)


proc listFiles*(httpClient: HttpClient): (Option[ListFilesResponse], Response) =
  ## Returns a list of files that belong to the user's organization.

  let response = httpClient.get(basepath & "/files")
  constructResult[ListFilesResponse](response)


proc listFineTuneEvents*(httpClient: HttpClient, fineTuneId: string, stream: bool): (Option[ListFineTuneEventsResponse], Response) =
  ## Get fine-grained status updates for a fine-tune job. 
  let query_for_api_call = encodeQuery([
    ("stream", $stream), # Whether to stream events for the fine-tune job. If set to true, events will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available. The stream will terminate with a `data: [DONE]` message when the job is finished (succeeded, cancelled, or failed).  If set to false, only events generated so far will be returned. 
  ])

  let response = httpClient.get(basepath & fmt"/fine-tunes/{fine_tune_id}/events" & "?" & query_for_api_call)
  constructResult[ListFineTuneEventsResponse](response)


proc listFineTunes*(httpClient: HttpClient): (Option[ListFineTunesResponse], Response) =
  ## List your organization's fine-tuning jobs 

  let response = httpClient.get(basepath & "/fine-tunes")
  constructResult[ListFineTunesResponse](response)


proc listModels*(httpClient: HttpClient): (Option[ListModelsResponse], Response) =
  ## Lists the currently available models, and provides basic information about each one such as the owner and availability.

  let response = httpClient.get(basepath & "/models")
  constructResult[ListModelsResponse](response)


proc retrieveFile*(httpClient: HttpClient, fileId: string): (Option[OpenAIFile], Response) =
  ## Returns information about a specific file.

  let response = httpClient.get(basepath & fmt"/files/{file_id}")
  constructResult[OpenAIFile](response)


proc retrieveFineTune*(httpClient: HttpClient, fineTuneId: string): (Option[FineTune], Response) =
  ## Gets info about the fine-tune job.  [Learn more about Fine-tuning](/docs/guides/fine-tuning) 

  let response = httpClient.get(basepath & fmt"/fine-tunes/{fine_tune_id}")
  constructResult[FineTune](response)


proc retrieveModel*(httpClient: HttpClient, model: string): (Option[Model], Response) =
  ## Retrieves a model instance, providing basic information about the model such as the owner and permissioning.

  let response = httpClient.get(basepath & fmt"/models/{model}")
  constructResult[Model](response)

