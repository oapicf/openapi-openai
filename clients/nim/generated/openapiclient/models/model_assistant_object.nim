#
# OpenAI API
# 
# The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
# The version of the OpenAPI document: 2.3.0
# Contact: blah+oapicf@cliffano.com
# Generated by: https://openapi-generator.tech
#

import json
import tables
import marshal
import options

import model_assistant_object_tool_resources
import model_assistant_object_tools_inner
import model_assistants_api_response_format_option
import model_object

type `Object`* {.pure.} = enum
  Assistant

type AssistantObject* = object
  ## Represents an `assistant` that can call the model and use tools.
  id*: string ## The identifier, which can be referenced in API endpoints.
  `object`*: `Object` ## The object type, which is always `assistant`.
  createdAt*: int ## The Unix timestamp (in seconds) for when the assistant was created.
  name*: Option[string] ## The name of the assistant. The maximum length is 256 characters. 
  description*: Option[string] ## The description of the assistant. The maximum length is 512 characters. 
  model*: string ## ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them. 
  instructions*: Option[string] ## The system instructions that the assistant uses. The maximum length is 256,000 characters. 
  tools*: seq[AssistantObject_tools_inner] ## A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`. 
  toolResources*: Option[AssistantObject_tool_resources]
  metadata*: Option[JsonNode] ## Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long. 
  temperature*: Option[float] ## What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. 
  topP*: Option[float] ## An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.  We generally recommend altering this or temperature but not both. 
  responseFormat*: Option[AssistantsApiResponseFormatOption]

func `%`*(v: `Object`): JsonNode =
  result = case v:
    of `Object`.Assistant: %"assistant"
func `$`*(v: `Object`): string =
  result = case v:
    of `Object`.Assistant: $("assistant")

proc to*(node: JsonNode, T: typedesc[`Object`]): `Object` =
  if node.kind != JString:
    raise newException(ValueError, "Expected string for enum `Object`, got " & $node.kind)
  let strVal = node.getStr()
  case strVal:
  of $("assistant"):
    return `Object`.Assistant
  else:
    raise newException(ValueError, "Invalid enum value for `Object`: " & strVal)


# Custom JSON deserialization for AssistantObject with custom field names
proc to*(node: JsonNode, T: typedesc[AssistantObject]): AssistantObject =
  result = AssistantObject()
  if node.kind == JObject:
    if node.hasKey("id"):
      result.id = to(node["id"], string)
    if node.hasKey("object"):
      result.`object` = to(node["object"], `Object`)
    if node.hasKey("created_at"):
      result.createdAt = to(node["created_at"], int)
    if node.hasKey("name") and node["name"].kind != JNull:
      result.name = some(to(node["name"], typeof(result.name.get())))
    if node.hasKey("description") and node["description"].kind != JNull:
      result.description = some(to(node["description"], typeof(result.description.get())))
    if node.hasKey("model"):
      result.model = to(node["model"], string)
    if node.hasKey("instructions") and node["instructions"].kind != JNull:
      result.instructions = some(to(node["instructions"], typeof(result.instructions.get())))
    if node.hasKey("tools"):
      result.tools = to(node["tools"], seq[AssistantObject_tools_inner])
    if node.hasKey("tool_resources") and node["tool_resources"].kind != JNull:
      result.toolResources = some(to(node["tool_resources"], typeof(result.toolResources.get())))
    if node.hasKey("metadata") and node["metadata"].kind != JNull:
      result.metadata = some(to(node["metadata"], typeof(result.metadata.get())))
    if node.hasKey("temperature") and node["temperature"].kind != JNull:
      result.temperature = some(to(node["temperature"], typeof(result.temperature.get())))
    if node.hasKey("top_p") and node["top_p"].kind != JNull:
      result.topP = some(to(node["top_p"], typeof(result.topP.get())))
    if node.hasKey("response_format") and node["response_format"].kind != JNull:
      result.responseFormat = some(to(node["response_format"], typeof(result.responseFormat.get())))

# Custom JSON serialization for AssistantObject with custom field names
proc `%`*(obj: AssistantObject): JsonNode =
  result = newJObject()
  result["id"] = %obj.id
  result["object"] = %obj.`object`
  result["created_at"] = %obj.createdAt
  if obj.name.isSome():
    result["name"] = %obj.name.get()
  if obj.description.isSome():
    result["description"] = %obj.description.get()
  result["model"] = %obj.model
  if obj.instructions.isSome():
    result["instructions"] = %obj.instructions.get()
  result["tools"] = %obj.tools
  if obj.toolResources.isSome():
    result["tool_resources"] = %obj.toolResources.get()
  if obj.metadata.isSome():
    result["metadata"] = %obj.metadata.get()
  if obj.temperature.isSome():
    result["temperature"] = %obj.temperature.get()
  if obj.topP.isSome():
    result["top_p"] = %obj.topP.get()
  if obj.responseFormat.isSome():
    result["response_format"] = %obj.responseFormat.get()

