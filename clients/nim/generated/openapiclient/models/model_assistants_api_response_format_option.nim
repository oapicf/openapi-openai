#
# OpenAI API
# 
# The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
# The version of the OpenAPI document: 2.3.0
# Contact: blah+oapicf@cliffano.com
# Generated by: https://openapi-generator.tech
#

import json
import tables
import marshal
import options

import model_response_format_json_object
import model_response_format_json_schema
import model_response_format_json_schema_json_schema
import model_response_format_text

# OneOf type
type AssistantsApiResponseFormatOptionKind* {.pure.} = enum
  StringVariant
  ResponseFormatTextVariant
  ResponseFormatJsonObjectVariant
  ResponseFormatJsonSchemaVariant

type AssistantsApiResponseFormatOption* = object
  ## Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.  Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).  Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.  **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length. 
  case kind*: AssistantsApiResponseFormatOptionKind
  of AssistantsApiResponseFormatOptionKind.StringVariant:
    stringValue*: string
  of AssistantsApiResponseFormatOptionKind.ResponseFormatTextVariant:
    ResponseFormatTextValue*: ResponseFormatText
  of AssistantsApiResponseFormatOptionKind.ResponseFormatJsonObjectVariant:
    ResponseFormatJsonObjectValue*: ResponseFormatJsonObject
  of AssistantsApiResponseFormatOptionKind.ResponseFormatJsonSchemaVariant:
    ResponseFormatJsonSchemaValue*: ResponseFormatJsonSchema

proc to*(node: JsonNode, T: typedesc[AssistantsApiResponseFormatOption]): AssistantsApiResponseFormatOption =
  ## Custom deserializer for oneOf type - tries each variant
  try:
    return AssistantsApiResponseFormatOption(kind: AssistantsApiResponseFormatOptionKind.StringVariant, stringValue: to(node, string))
  except Exception as e:
    when defined(debug):
      echo "Failed to deserialize as string: ", e.msg
  try:
    return AssistantsApiResponseFormatOption(kind: AssistantsApiResponseFormatOptionKind.ResponseFormatTextVariant, ResponseFormatTextValue: to(node, ResponseFormatText))
  except Exception as e:
    when defined(debug):
      echo "Failed to deserialize as ResponseFormatText: ", e.msg
  try:
    return AssistantsApiResponseFormatOption(kind: AssistantsApiResponseFormatOptionKind.ResponseFormatJsonObjectVariant, ResponseFormatJsonObjectValue: to(node, ResponseFormatJsonObject))
  except Exception as e:
    when defined(debug):
      echo "Failed to deserialize as ResponseFormatJsonObject: ", e.msg
  try:
    return AssistantsApiResponseFormatOption(kind: AssistantsApiResponseFormatOptionKind.ResponseFormatJsonSchemaVariant, ResponseFormatJsonSchemaValue: to(node, ResponseFormatJsonSchema))
  except Exception as e:
    when defined(debug):
      echo "Failed to deserialize as ResponseFormatJsonSchema: ", e.msg
  raise newException(ValueError, "Unable to deserialize into any variant of AssistantsApiResponseFormatOption. JSON: " & $node)

