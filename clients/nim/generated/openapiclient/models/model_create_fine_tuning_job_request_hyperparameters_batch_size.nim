#
# OpenAI API
# 
# The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
# The version of the OpenAPI document: 2.3.0
# Contact: blah+oapicf@cliffano.com
# Generated by: https://openapi-generator.tech
#

import json
import tables
import marshal
import options


# OneOf type
type CreateFineTuningJobRequestHyperparametersBatchSizeKind* {.pure.} = enum
  StringVariant
  IntegerVariant

type CreateFineTuningJobRequestHyperparametersBatchSize* = object
  ## Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance. 
  case kind*: CreateFineTuningJobRequestHyperparametersBatchSizeKind
  of CreateFineTuningJobRequestHyperparametersBatchSizeKind.StringVariant:
    stringValue*: string
  of CreateFineTuningJobRequestHyperparametersBatchSizeKind.IntegerVariant:
    integerValue*: int

proc to*(node: JsonNode, T: typedesc[CreateFineTuningJobRequestHyperparametersBatchSize]): CreateFineTuningJobRequestHyperparametersBatchSize =
  ## Custom deserializer for oneOf type - tries each variant
  try:
    return CreateFineTuningJobRequestHyperparametersBatchSize(kind: CreateFineTuningJobRequestHyperparametersBatchSizeKind.StringVariant, stringValue: to(node, string))
  except Exception as e:
    when defined(debug):
      echo "Failed to deserialize as string: ", e.msg
  try:
    return CreateFineTuningJobRequestHyperparametersBatchSize(kind: CreateFineTuningJobRequestHyperparametersBatchSizeKind.IntegerVariant, integerValue: to(node, int))
  except Exception as e:
    when defined(debug):
      echo "Failed to deserialize as int: ", e.msg
  raise newException(ValueError, "Unable to deserialize into any variant of CreateFineTuningJobRequestHyperparametersBatchSize. JSON: " & $node)

