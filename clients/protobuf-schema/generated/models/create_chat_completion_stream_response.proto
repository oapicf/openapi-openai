/*
  OpenAI API

  The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.

  The version of the OpenAPI document: 2.3.0

  Contact: blah+oapicf@cliffano.com

  Generated by OpenAPI Generator: https://openapi-generator.tech
*/

syntax = "proto3";

package openapitools;

import public "models/create_chat_completion_stream_response_choices_inner.proto";
import public "models/create_chat_completion_stream_response_usage.proto";

message CreateChatCompletionStreamResponse {

  // A unique identifier for the chat completion. Each chunk has the same ID.
  string id = 3355;

  // A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the last chunk if you set `stream_options: {\"include_usage\": true}`. 
  repeated CreateChatCompletionStreamResponseChoicesInner choices = 214849267;

  // The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
  int32 created = 491683561;

  // The model to generate the completion.
  string model = 104069929;

  // The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.
  enum Service_tier {
    SERVICE_TIER_SCALE = 0;
    SERVICE_TIER_DEFAULT = 1;
  }

  Service_tier service_tier = 360066348;

  // This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism. 
  string system_fingerprint = 319231278;

  // The object type, which is always `chat.completion.chunk`.
  enum Object {
    OBJECT_CHAT_COMPLETION_CHUNK = 0;
  }

  Object object = 486497474;

  CreateChatCompletionStreamResponseUsage usage = 111574433;

}

