"$schema"   = "http://cyaninc.com/json-schemas/tosca-lite-v1/definition-module#"
title       = "openapi_server CreateBatchRequest"
package     = openapi_server
version     = "1.0"
description = "Defines a CreateBatchRequest"
authors     = ["F. Bar (foo@bar.baz)"]

imports {
  Root = tosca.resourceTypes.Root
}
resourceTypes {

  CreateBatchRequest {
    title = CreateBatchRequest
    description = CreateBatchRequest
    derivedFrom = Root
    properties {
        input_file_id {
          type =  string
          description = "The ID of an uploaded file that contains requests for the new batch.  See [upload file](/docs/api-reference/files/create) for how to upload a file.  Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose &#x60;batch&#x60;. The file can contain up to 50,000 requests, and can be up to 200 MB in size. "
          optional = true
        }
        endpoint {
          type =  string
          description = "The endpoint to be used for all requests in the batch. Currently &#x60;/v1/chat/completions&#x60;, &#x60;/v1/embeddings&#x60;, and &#x60;/v1/completions&#x60; are supported. Note that &#x60;/v1/embeddings&#x60; batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch."
          enum = ["/v1/chat/completions", "/v1/embeddings", "/v1/completions"]
          optional = true
        }
        completion_window {
          type =  string
          description = "The time frame within which the batch should be processed. Currently only &#x60;24h&#x60; is supported."
          enum = ["24h"]
          optional = true
        }
        metadata {
          # TODO
          description = "Optional custom metadata for the batch."
          optional = false
        }
    }
  }
}

serviceTemplates {

  CreateBatchRequest {
    title = CreateBatchRequest
    description = CreateBatchRequest
    implements = openapi_server.resourceTypes.CreateBatchRequest

  }
}
