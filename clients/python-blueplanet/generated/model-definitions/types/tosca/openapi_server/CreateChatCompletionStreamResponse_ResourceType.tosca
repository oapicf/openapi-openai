"$schema"   = "http://cyaninc.com/json-schemas/tosca-lite-v1/definition-module#"
title       = "openapi_server CreateChatCompletionStreamResponse"
package     = openapi_server
version     = "1.0"
description = "Defines a CreateChatCompletionStreamResponse"
authors     = ["F. Bar (foo@bar.baz)"]

imports {
  Root = tosca.resourceTypes.Root
  CreateChatCompletionStreamResponseChoicesInner = openapi_server.resourceTypes.CreateChatCompletionStreamResponseChoicesInner
  CreateChatCompletionStreamResponseUsage = openapi_server.resourceTypes.CreateChatCompletionStreamResponseUsage
}
resourceTypes {

  CreateChatCompletionStreamResponse {
    title = CreateChatCompletionStreamResponse
    description = CreateChatCompletionStreamResponse
    derivedFrom = Root
    properties {
        id {
          type =  string
          description = "A unique identifier for the chat completion. Each chunk has the same ID."
          optional = true
        }
        choices {
          type = array
          items.type = CreateChatCompletionStreamResponseChoicesInner
          description = "A list of chat completion choices. Can contain more than one elements if &#x60;n&#x60; is greater than 1. Can also be empty for the last chunk if you set &#x60;stream_options: {\&quot;include_usage\&quot;: true}&#x60;. "
          optional = true
        }
        created {
          type =  integer
          description = "The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp."
          optional = true
        }
        model {
          type =  string
          description = "The model to generate the completion."
          optional = true
        }
        service_tier {
          type =  string
          description = "The service tier used for processing the request. This field is only included if the &#x60;service_tier&#x60; parameter is specified in the request."
          enum = ["scale", "default"]
          optional = false
        }
        system_fingerprint {
          type =  string
          description = "This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the &#x60;seed&#x60; request parameter to understand when backend changes have been made that might impact determinism. "
          optional = false
        }
        object {
          type =  string
          description = "The object type, which is always &#x60;chat.completion.chunk&#x60;."
          enum = ["chat.completion.chunk"]
          optional = true
        }
        usage {
          type = CreateChatCompletionStreamResponseUsage
          description = ""
          optional = false
        }
    }
  }
}

serviceTemplates {

  CreateChatCompletionStreamResponse {
    title = CreateChatCompletionStreamResponse
    description = CreateChatCompletionStreamResponse
    implements = openapi_server.resourceTypes.CreateChatCompletionStreamResponse

  }
}
