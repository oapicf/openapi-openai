"$schema"   = "http://cyaninc.com/json-schemas/tosca-lite-v1/definition-module#"
title       = "openapi_server FineTuneChatCompletionRequestAssistantMessage"
package     = openapi_server
version     = "1.0"
description = "Defines a FineTuneChatCompletionRequestAssistantMessage"
authors     = ["F. Bar (foo@bar.baz)"]

imports {
  Root = tosca.resourceTypes.Root
  ChatCompletionMessageToolCall = openapi_server.resourceTypes.ChatCompletionMessageToolCall
  ChatCompletionRequestAssistantMessageAudio = openapi_server.resourceTypes.ChatCompletionRequestAssistantMessageAudio
  ChatCompletionRequestAssistantMessageContent = openapi_server.resourceTypes.ChatCompletionRequestAssistantMessageContent
  ChatCompletionRequestAssistantMessageFunctionCall = openapi_server.resourceTypes.ChatCompletionRequestAssistantMessageFunctionCall
}
resourceTypes {

  FineTuneChatCompletionRequestAssistantMessage {
    title = FineTuneChatCompletionRequestAssistantMessage
    description = FineTuneChatCompletionRequestAssistantMessage
    derivedFrom = Root
    properties {
        content {
          type = ChatCompletionRequestAssistantMessageContent
          description = ""
          optional = false
        }
        refusal {
          type =  string
          description = "The refusal message by the assistant."
          optional = false
        }
        role {
          type =  string
          description = "The role of the messages author, in this case &#x60;assistant&#x60;."
          enum = ["assistant"]
          optional = true
        }
        name {
          type =  string
          description = "An optional name for the participant. Provides the model information to differentiate between participants of the same role."
          optional = false
        }
        audio {
          type = ChatCompletionRequestAssistantMessageAudio
          description = ""
          optional = false
        }
        tool_calls {
          type = array
          items.type = ChatCompletionMessageToolCall
          description = "The tool calls generated by the model, such as function calls."
          optional = false
        }
        function_call {
          type = ChatCompletionRequestAssistantMessageFunctionCall
          description = ""
          optional = false
        }
        weight {
          type =  integer
          description = "Controls whether the assistant message is trained against (0 or 1)"
          enum = ["0", "1"]
          optional = false
        }
    }
  }
}

serviceTemplates {

  FineTuneChatCompletionRequestAssistantMessage {
    title = FineTuneChatCompletionRequestAssistantMessage
    description = FineTuneChatCompletionRequestAssistantMessage
    implements = openapi_server.resourceTypes.FineTuneChatCompletionRequestAssistantMessage

  }
}
