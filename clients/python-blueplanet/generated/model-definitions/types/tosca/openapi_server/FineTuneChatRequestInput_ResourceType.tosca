"$schema"   = "http://cyaninc.com/json-schemas/tosca-lite-v1/definition-module#"
title       = "openapi_server FineTuneChatRequestInput"
package     = openapi_server
version     = "1.0"
description = "Defines a FineTuneChatRequestInput"
authors     = ["F. Bar (foo@bar.baz)"]

imports {
  Root = tosca.resourceTypes.Root
  ChatCompletionFunctions = openapi_server.resourceTypes.ChatCompletionFunctions
  ChatCompletionTool = openapi_server.resourceTypes.ChatCompletionTool
  FineTuneChatRequestInputMessagesInner = openapi_server.resourceTypes.FineTuneChatRequestInputMessagesInner
}
resourceTypes {

  FineTuneChatRequestInput {
    title = FineTuneChatRequestInput
    description = FineTuneChatRequestInput
    derivedFrom = Root
    properties {
        messages {
          type = array
          items.type = FineTuneChatRequestInputMessagesInner
          description = ""
          optional = false
        }
        tools {
          type = array
          items.type = ChatCompletionTool
          description = "A list of tools the model may generate JSON inputs for."
          optional = false
        }
        parallel_tool_calls {
          type =  boolean
          description = "Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use."
          optional = false
        }
        functions {
          type = array
          items.type = ChatCompletionFunctions
          description = "A list of functions the model may generate JSON inputs for."
          optional = false
        }
    }
  }
}

serviceTemplates {

  FineTuneChatRequestInput {
    title = FineTuneChatRequestInput
    description = FineTuneChatRequestInput
    implements = openapi_server.resourceTypes.FineTuneChatRequestInput

  }
}
