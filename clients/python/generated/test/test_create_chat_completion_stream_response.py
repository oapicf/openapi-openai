# coding: utf-8

"""
    OpenAI API

    The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.

    The version of the OpenAPI document: 2.0.0
    Contact: blah+oapicf@cliffano.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from openapiopenai.models.create_chat_completion_stream_response import CreateChatCompletionStreamResponse

class TestCreateChatCompletionStreamResponse(unittest.TestCase):
    """CreateChatCompletionStreamResponse unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> CreateChatCompletionStreamResponse:
        """Test CreateChatCompletionStreamResponse
            include_optional is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `CreateChatCompletionStreamResponse`
        """
        model = CreateChatCompletionStreamResponse()
        if include_optional:
            return CreateChatCompletionStreamResponse(
                id = '',
                choices = [
                    openapiopenai.models.create_chat_completion_stream_response_choices_inner.CreateChatCompletionStreamResponse_choices_inner(
                        delta = openapiopenai.models.chat_completion_stream_response_delta.ChatCompletionStreamResponseDelta(
                            content = '', 
                            function_call = openapiopenai.models.chat_completion_stream_response_delta_function_call.ChatCompletionStreamResponseDelta_function_call(
                                arguments = '', 
                                name = '', ), 
                            tool_calls = [
                                openapiopenai.models.chat_completion_message_tool_call_chunk.ChatCompletionMessageToolCallChunk(
                                    index = 56, 
                                    id = '', 
                                    type = 'function', 
                                    function = openapiopenai.models.chat_completion_message_tool_call_chunk_function.ChatCompletionMessageToolCallChunk_function(
                                        name = '', 
                                        arguments = '', ), )
                                ], 
                            role = 'system', ), 
                        logprobs = openapiopenai.models.create_chat_completion_response_choices_inner_logprobs.CreateChatCompletionResponse_choices_inner_logprobs(
                            content = [
                                openapiopenai.models.chat_completion_token_logprob.ChatCompletionTokenLogprob(
                                    token = '', 
                                    logprob = 1.337, 
                                    bytes = [
                                        56
                                        ], 
                                    top_logprobs = [
                                        openapiopenai.models.chat_completion_token_logprob_top_logprobs_inner.ChatCompletionTokenLogprob_top_logprobs_inner(
                                            token = '', 
                                            logprob = 1.337, 
                                            bytes = [
                                                56
                                                ], )
                                        ], )
                                ], ), 
                        finish_reason = 'stop', 
                        index = 56, )
                    ],
                created = 56,
                model = '',
                system_fingerprint = '',
                object = 'chat.completion.chunk'
            )
        else:
            return CreateChatCompletionStreamResponse(
                id = '',
                choices = [
                    openapiopenai.models.create_chat_completion_stream_response_choices_inner.CreateChatCompletionStreamResponse_choices_inner(
                        delta = openapiopenai.models.chat_completion_stream_response_delta.ChatCompletionStreamResponseDelta(
                            content = '', 
                            function_call = openapiopenai.models.chat_completion_stream_response_delta_function_call.ChatCompletionStreamResponseDelta_function_call(
                                arguments = '', 
                                name = '', ), 
                            tool_calls = [
                                openapiopenai.models.chat_completion_message_tool_call_chunk.ChatCompletionMessageToolCallChunk(
                                    index = 56, 
                                    id = '', 
                                    type = 'function', 
                                    function = openapiopenai.models.chat_completion_message_tool_call_chunk_function.ChatCompletionMessageToolCallChunk_function(
                                        name = '', 
                                        arguments = '', ), )
                                ], 
                            role = 'system', ), 
                        logprobs = openapiopenai.models.create_chat_completion_response_choices_inner_logprobs.CreateChatCompletionResponse_choices_inner_logprobs(
                            content = [
                                openapiopenai.models.chat_completion_token_logprob.ChatCompletionTokenLogprob(
                                    token = '', 
                                    logprob = 1.337, 
                                    bytes = [
                                        56
                                        ], 
                                    top_logprobs = [
                                        openapiopenai.models.chat_completion_token_logprob_top_logprobs_inner.ChatCompletionTokenLogprob_top_logprobs_inner(
                                            token = '', 
                                            logprob = 1.337, 
                                            bytes = [
                                                56
                                                ], )
                                        ], )
                                ], ), 
                        finish_reason = 'stop', 
                        index = 56, )
                    ],
                created = 56,
                model = '',
                object = 'chat.completion.chunk',
        )
        """

    def testCreateChatCompletionStreamResponse(self):
        """Test CreateChatCompletionStreamResponse"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
