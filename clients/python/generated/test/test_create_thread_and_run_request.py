# coding: utf-8

"""
    OpenAI API

    The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.

    The version of the OpenAPI document: 2.3.0
    Contact: blah+oapicf@cliffano.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from openapiopenai.models.create_thread_and_run_request import CreateThreadAndRunRequest

class TestCreateThreadAndRunRequest(unittest.TestCase):
    """CreateThreadAndRunRequest unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> CreateThreadAndRunRequest:
        """Test CreateThreadAndRunRequest
            include_optional is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `CreateThreadAndRunRequest`
        """
        model = CreateThreadAndRunRequest()
        if include_optional:
            return CreateThreadAndRunRequest(
                assistant_id = '',
                thread = openapiopenai.models.create_thread_request.CreateThreadRequest(
                    messages = [
                        openapiopenai.models.create_message_request.CreateMessageRequest(
                            role = 'user', 
                            content = null, 
                            attachments = [
                                openapiopenai.models.create_message_request_attachments_inner.CreateMessageRequest_attachments_inner(
                                    file_id = '', 
                                    tools = [
                                        null
                                        ], )
                                ], 
                            metadata = openapiopenai.models.metadata.metadata(), )
                        ], 
                    tool_resources = openapiopenai.models.create_thread_request_tool_resources.CreateThreadRequest_tool_resources(
                        code_interpreter = openapiopenai.models.create_assistant_request_tool_resources_code_interpreter.CreateAssistantRequest_tool_resources_code_interpreter(
                            file_ids = [
                                ''
                                ], ), 
                        file_search = openapiopenai.models.create_thread_request_tool_resources_file_search.CreateThreadRequest_tool_resources_file_search(
                            vector_store_ids = [
                                ''
                                ], 
                            vector_stores = [
                                openapiopenai.models.create_thread_request_tool_resources_file_search_vector_stores_inner.CreateThreadRequest_tool_resources_file_search_vector_stores_inner(
                                    chunking_strategy = openapiopenai.models.create_assistant_request_tool_resources_file_search_vector_stores_inner_chunking_strategy.CreateAssistantRequest_tool_resources_file_search_vector_stores_inner_chunking_strategy(), 
                                    metadata = openapiopenai.models.metadata.metadata(), )
                                ], ), ), 
                    metadata = openapiopenai.models.metadata.metadata(), ),
                model = gpt-4o,
                instructions = '',
                tools = [
                    null
                    ],
                tool_resources = openapiopenai.models.create_thread_and_run_request_tool_resources.CreateThreadAndRunRequest_tool_resources(
                    code_interpreter = openapiopenai.models.create_assistant_request_tool_resources_code_interpreter.CreateAssistantRequest_tool_resources_code_interpreter(
                        file_ids = [
                            ''
                            ], ), 
                    file_search = openapiopenai.models.assistant_object_tool_resources_file_search.AssistantObject_tool_resources_file_search(
                        vector_store_ids = [
                            ''
                            ], ), ),
                metadata = None,
                temperature = 1,
                top_p = 1,
                stream = True,
                max_prompt_tokens = 256,
                max_completion_tokens = 256,
                truncation_strategy = openapiopenai.models.thread_truncation_controls.Thread Truncation Controls(
                    type = 'auto', 
                    last_messages = 1, ),
                tool_choice = None,
                parallel_tool_calls = True,
                response_format = None
            )
        else:
            return CreateThreadAndRunRequest(
                assistant_id = '',
        )
        """

    def testCreateThreadAndRunRequest(self):
        """Test CreateThreadAndRunRequest"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
