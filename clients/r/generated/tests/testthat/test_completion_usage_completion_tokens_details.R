# Automatically generated by openapi-generator (https://openapi-generator.tech)
# Please update as you see appropriate

context("Test CompletionUsageCompletionTokensDetails")

model_instance <- CompletionUsageCompletionTokensDetails$new()

test_that("accepted_prediction_tokens", {
  # tests for the property `accepted_prediction_tokens` (integer)
  # When using Predicted Outputs, the number of tokens in the prediction that appeared in the completion. 

  # uncomment below to test the property
  #expect_equal(model.instance$`accepted_prediction_tokens`, "EXPECTED_RESULT")
})

test_that("audio_tokens", {
  # tests for the property `audio_tokens` (integer)
  # Audio input tokens generated by the model.

  # uncomment below to test the property
  #expect_equal(model.instance$`audio_tokens`, "EXPECTED_RESULT")
})

test_that("reasoning_tokens", {
  # tests for the property `reasoning_tokens` (integer)
  # Tokens generated by the model for reasoning.

  # uncomment below to test the property
  #expect_equal(model.instance$`reasoning_tokens`, "EXPECTED_RESULT")
})

test_that("rejected_prediction_tokens", {
  # tests for the property `rejected_prediction_tokens` (integer)
  # When using Predicted Outputs, the number of tokens in the prediction that did not appear in the completion. However, like reasoning tokens, these tokens are still counted in the total completion tokens for purposes of billing, output, and context window limits. 

  # uncomment below to test the property
  #expect_equal(model.instance$`rejected_prediction_tokens`, "EXPECTED_RESULT")
})
