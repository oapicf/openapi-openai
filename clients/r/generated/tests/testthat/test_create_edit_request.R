# Automatically generated by openapi-generator (https://openapi-generator.tech)
# Please update as you see appropriate

context("Test CreateEditRequest")

model_instance <- CreateEditRequest$new()

test_that("model", {
  # tests for the property `model` (CreateEditRequestModel)

  # uncomment below to test the property
  #expect_equal(model.instance$`model`, "EXPECTED_RESULT")
})

test_that("input", {
  # tests for the property `input` (character)
  # The input text to use as a starting point for the edit.

  # uncomment below to test the property
  #expect_equal(model.instance$`input`, "EXPECTED_RESULT")
})

test_that("instruction", {
  # tests for the property `instruction` (character)
  # The instruction that tells the model how to edit the prompt.

  # uncomment below to test the property
  #expect_equal(model.instance$`instruction`, "EXPECTED_RESULT")
})

test_that("n", {
  # tests for the property `n` (integer)
  # How many edits to generate for the input and instruction.

  # uncomment below to test the property
  #expect_equal(model.instance$`n`, "EXPECTED_RESULT")
})

test_that("temperature", {
  # tests for the property `temperature` (numeric)
  # What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.  We generally recommend altering this or &#x60;top_p&#x60; but not both. 

  # uncomment below to test the property
  #expect_equal(model.instance$`temperature`, "EXPECTED_RESULT")
})

test_that("top_p", {
  # tests for the property `top_p` (numeric)
  # An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.  We generally recommend altering this or &#x60;temperature&#x60; but not both. 

  # uncomment below to test the property
  #expect_equal(model.instance$`top_p`, "EXPECTED_RESULT")
})
