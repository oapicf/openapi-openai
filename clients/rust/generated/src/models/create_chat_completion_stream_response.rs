/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// CreateChatCompletionStreamResponse : Represents a streamed chunk of a chat completion response returned by model, based on the provided input.
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct CreateChatCompletionStreamResponse {
    /// A unique identifier for the chat completion. Each chunk has the same ID.
    #[serde(rename = "id")]
    pub id: String,
    /// A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the last chunk if you set `stream_options: {\"include_usage\": true}`. 
    #[serde(rename = "choices")]
    pub choices: Vec<models::CreateChatCompletionStreamResponseChoicesInner>,
    /// The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
    #[serde(rename = "created")]
    pub created: i32,
    /// The model to generate the completion.
    #[serde(rename = "model")]
    pub model: String,
    /// The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.
    #[serde(rename = "service_tier", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub service_tier: Option<Option<ServiceTier>>,
    /// This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism. 
    #[serde(rename = "system_fingerprint", skip_serializing_if = "Option::is_none")]
    pub system_fingerprint: Option<String>,
    /// The object type, which is always `chat.completion.chunk`.
    #[serde(rename = "object")]
    pub object: Object,
    #[serde(rename = "usage", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub usage: Option<Option<Box<models::CreateChatCompletionStreamResponseUsage>>>,
}

impl CreateChatCompletionStreamResponse {
    /// Represents a streamed chunk of a chat completion response returned by model, based on the provided input.
    pub fn new(id: String, choices: Vec<models::CreateChatCompletionStreamResponseChoicesInner>, created: i32, model: String, object: Object) -> CreateChatCompletionStreamResponse {
        CreateChatCompletionStreamResponse {
            id,
            choices,
            created,
            model,
            service_tier: None,
            system_fingerprint: None,
            object,
            usage: None,
        }
    }
}
/// The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum ServiceTier {
    #[serde(rename = "scale")]
    Scale,
    #[serde(rename = "default")]
    Default,
}

impl Default for ServiceTier {
    fn default() -> ServiceTier {
        Self::Scale
    }
}
/// The object type, which is always `chat.completion.chunk`.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum Object {
    #[serde(rename = "chat.completion.chunk")]
    ChatCompletionChunk,
}

impl Default for Object {
    fn default() -> Object {
        Self::ChatCompletionChunk
    }
}

