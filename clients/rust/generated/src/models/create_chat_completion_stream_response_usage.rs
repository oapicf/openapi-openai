/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// CreateChatCompletionStreamResponseUsage : An optional field that will only be present when you set `stream_options: {\"include_usage\": true}` in your request. When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request. 
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct CreateChatCompletionStreamResponseUsage {
    /// Number of tokens in the generated completion.
    #[serde(rename = "completion_tokens")]
    pub completion_tokens: i32,
    /// Number of tokens in the prompt.
    #[serde(rename = "prompt_tokens")]
    pub prompt_tokens: i32,
    /// Total number of tokens used in the request (prompt + completion).
    #[serde(rename = "total_tokens")]
    pub total_tokens: i32,
}

impl CreateChatCompletionStreamResponseUsage {
    /// An optional field that will only be present when you set `stream_options: {\"include_usage\": true}` in your request. When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request. 
    pub fn new(completion_tokens: i32, prompt_tokens: i32, total_tokens: i32) -> CreateChatCompletionStreamResponseUsage {
        CreateChatCompletionStreamResponseUsage {
            completion_tokens,
            prompt_tokens,
            total_tokens,
        }
    }
}

