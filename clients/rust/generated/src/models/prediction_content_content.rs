/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// PredictionContentContent : The content that should be matched when generating a model response. If generated tokens would match this content, the entire model response can be returned much more quickly. 
/// The content that should be matched when generating a model response. If generated tokens would match this content, the entire model response can be returned much more quickly. 
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
#[serde(untagged)]
pub enum PredictionContentContent {
    /// The content used for a Predicted Output. This is often the text of a file you are regenerating with minor changes. 
    TextContent(String),
    /// An array of content parts with a defined type. Supported options differ based on the [model](/docs/models) being used to generate the response. Can contain text inputs.
    Array of content parts(Vec<models::ChatCompletionRequestMessageContentPartText>),
}

impl Default for PredictionContentContent {
    fn default() -> Self {
        Self::TextContent(Default::default())
    }
}

