/**
 * OpenAI API
 * APIs for sampling from and fine-tuning language models
 *
 * The version of the OpenAPI document: 2.0.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

package io.swagger.client.api

import akka.{Done, NotUsed}
import com.lightbend.lagom.scaladsl.api.transport.Method
import com.lightbend.lagom.scaladsl.api.{Service, ServiceCall}
import play.api.libs.json._
import com.lightbend.lagom.scaladsl.api.deser.PathParamSerializer

import io.swagger.client.model.CreateChatCompletionRequest
import io.swagger.client.model.CreateChatCompletionResponse
import io.swagger.client.model.CreateCompletionRequest
import io.swagger.client.model.CreateCompletionResponse
import io.swagger.client.model.CreateEditRequest
import io.swagger.client.model.CreateEditResponse
import io.swagger.client.model.CreateEmbeddingRequest
import io.swagger.client.model.CreateEmbeddingResponse
import io.swagger.client.model.CreateFineTuneRequest
import io.swagger.client.model.CreateImageRequest
import io.swagger.client.model.CreateModerationRequest
import io.swagger.client.model.CreateModerationResponse
import io.swagger.client.model.CreateTranscriptionRequestModel
import io.swagger.client.model.CreateTranscriptionResponse
import io.swagger.client.model.CreateTranslationResponse
import io.swagger.client.model.DeleteFileResponse
import io.swagger.client.model.DeleteModelResponse
import java.io.File
import io.swagger.client.model.FineTune
import io.swagger.client.model.ImagesResponse
import io.swagger.client.model.ListFilesResponse
import io.swagger.client.model.ListFineTuneEventsResponse
import io.swagger.client.model.ListFineTunesResponse
import io.swagger.client.model.ListModelsResponse
import io.swagger.client.model.Model
import io.swagger.client.model.Number
import io.swagger.client.model.OpenAIFile

trait OpenAIApi extends Service {


  final override def descriptor = {
    import Service._
    named("OpenAIApi").withCalls(
      restCall(Method.POST, "/fine-tunes/:fine_tune_id/cancel", cancelFineTune _), 
      restCall(Method.POST, "/chat/completions", createChatCompletion _), 
      restCall(Method.POST, "/completions", createCompletion _), 
      restCall(Method.POST, "/edits", createEdit _), 
      restCall(Method.POST, "/embeddings", createEmbedding _), 
      restCall(Method.POST, "/files", createFile _), 
      restCall(Method.POST, "/fine-tunes", createFineTune _), 
      restCall(Method.POST, "/images/generations", createImage _), 
      restCall(Method.POST, "/images/edits", createImageEdit _), 
      restCall(Method.POST, "/images/variations", createImageVariation _), 
      restCall(Method.POST, "/moderations", createModeration _), 
      restCall(Method.POST, "/audio/transcriptions", createTranscription _), 
      restCall(Method.POST, "/audio/translations", createTranslation _), 
      restCall(Method.DELETE, "/files/:file_id", deleteFile _), 
      restCall(Method.DELETE, "/models/:model", deleteModel _), 
      restCall(Method.GET, "/files/:file_id/content", downloadFile _), 
      restCall(Method.GET, "/files", listFiles _), 
      restCall(Method.GET, "/fine-tunes/:fine_tune_id/events?stream", listFineTuneEvents _), 
      restCall(Method.GET, "/fine-tunes", listFineTunes _), 
      restCall(Method.GET, "/models", listModels _), 
      restCall(Method.GET, "/files/:file_id", retrieveFile _), 
      restCall(Method.GET, "/fine-tunes/:fine_tune_id", retrieveFineTune _), 
      restCall(Method.GET, "/models/:model", retrieveModel _)
    ).withAutoAcl(true)
  }


  /**
    * Immediately cancel a fine-tune job. 
    * 
    *  
    * @param fineTuneId The ID of the fine-tune job to cancel  
    * @return FineTune
    */
  def cancelFineTune(fineTuneId: String): ServiceCall[NotUsed ,FineTune]
  
  /**
    * Creates a model response for the given chat conversation.
    * 
    *  
    * @return CreateChatCompletionResponse Body Parameter   
    */
  def createChatCompletion(): ServiceCall[CreateChatCompletionRequest ,CreateChatCompletionResponse]
  
  /**
    * Creates a completion for the provided prompt and parameters.
    * 
    *  
    * @return CreateCompletionResponse Body Parameter   
    */
  def createCompletion(): ServiceCall[CreateCompletionRequest ,CreateCompletionResponse]
  
  /**
    * Creates a new edit for the provided input, instruction, and parameters.
    * 
    *  
    * @return CreateEditResponse Body Parameter   
    */
  def createEdit(): ServiceCall[CreateEditRequest ,CreateEditResponse]
  
  /**
    * Creates an embedding vector representing the input text.
    * 
    *  
    * @return CreateEmbeddingResponse Body Parameter   
    */
  def createEmbedding(): ServiceCall[CreateEmbeddingRequest ,CreateEmbeddingResponse]
  
  // file:File  -- not yet supported x-www-form-urlencoded
  // purpose:String  -- not yet supported x-www-form-urlencoded
  /**
    * Upload a file that contains document(s) to be used across various endpoints/features. Currently, the size of all the files uploaded by one organization can be up to 1 GB. Please contact us if you need to increase the storage limit. 
    * 
    *  
    * @param file Name of the [JSON Lines](https://jsonlines.readthedocs.io/en/latest/) file to be uploaded.  If the &#x60;purpose&#x60; is set to \\\&quot;fine-tune\\\&quot;, each line is a JSON record with \\\&quot;prompt\\\&quot; and \\\&quot;completion\\\&quot; fields representing your [training examples](/docs/guides/fine-tuning/prepare-training-data).   
    * @param purpose The intended purpose of the uploaded documents.  Use \\\&quot;fine-tune\\\&quot; for [Fine-tuning](/docs/api-reference/fine-tunes). This allows us to validate the format of the uploaded file.  
    * @return OpenAIFile
    */
  def createFile(): ServiceCall[NotUsed ,OpenAIFile]
  
  /**
    * Creates a job that fine-tunes a specified model from a given dataset.  Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.  [Learn more about Fine-tuning](/docs/guides/fine-tuning) 
    * 
    *  
    * @return FineTune Body Parameter   
    */
  def createFineTune(): ServiceCall[CreateFineTuneRequest ,FineTune]
  
  /**
    * Creates an image given a prompt.
    * 
    *  
    * @return ImagesResponse Body Parameter   
    */
  def createImage(): ServiceCall[CreateImageRequest ,ImagesResponse]
  
  // image:File  -- not yet supported x-www-form-urlencoded
  // prompt:String  -- not yet supported x-www-form-urlencoded
  // mask:File  -- not yet supported x-www-form-urlencoded
  // n:Int  -- not yet supported x-www-form-urlencoded
  // size:String  -- not yet supported x-www-form-urlencoded
  // responseFormat:String  -- not yet supported x-www-form-urlencoded
  // user:String  -- not yet supported x-www-form-urlencoded
  /**
    * Creates an edited or extended image given an original image and a prompt.
    * 
    *  
    * @param image The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.  
    * @param prompt A text description of the desired image(s). The maximum length is 1000 characters.  
    * @param mask An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where &#x60;image&#x60; should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as &#x60;image&#x60;. (optional) 
    * @param n The number of images to generate. Must be between 1 and 10. (optional, default to 1) 
    * @param size The size of the generated images. Must be one of &#x60;256x256&#x60;, &#x60;512x512&#x60;, or &#x60;1024x1024&#x60;. (optional, default to 1024x1024) 
    * @param responseFormat The format in which the generated images are returned. Must be one of &#x60;url&#x60; or &#x60;b64_json&#x60;. (optional, default to url) 
    * @param user A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).  (optional)
    * @return ImagesResponse
    */
  def createImageEdit(): ServiceCall[NotUsed ,ImagesResponse]
  
  // image:File  -- not yet supported x-www-form-urlencoded
  // n:Int  -- not yet supported x-www-form-urlencoded
  // size:String  -- not yet supported x-www-form-urlencoded
  // responseFormat:String  -- not yet supported x-www-form-urlencoded
  // user:String  -- not yet supported x-www-form-urlencoded
  /**
    * Creates a variation of a given image.
    * 
    *  
    * @param image The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.  
    * @param n The number of images to generate. Must be between 1 and 10. (optional, default to 1) 
    * @param size The size of the generated images. Must be one of &#x60;256x256&#x60;, &#x60;512x512&#x60;, or &#x60;1024x1024&#x60;. (optional, default to 1024x1024) 
    * @param responseFormat The format in which the generated images are returned. Must be one of &#x60;url&#x60; or &#x60;b64_json&#x60;. (optional, default to url) 
    * @param user A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).  (optional)
    * @return ImagesResponse
    */
  def createImageVariation(): ServiceCall[NotUsed ,ImagesResponse]
  
  /**
    * Classifies if text violates OpenAI&#39;s Content Policy
    * 
    *  
    * @return CreateModerationResponse Body Parameter   
    */
  def createModeration(): ServiceCall[CreateModerationRequest ,CreateModerationResponse]
  
  // file:File  -- not yet supported x-www-form-urlencoded
  // model:CreateTranscriptionRequestModel  -- not yet supported x-www-form-urlencoded
  // prompt:String  -- not yet supported x-www-form-urlencoded
  // responseFormat:String  -- not yet supported x-www-form-urlencoded
  // temperature:Number  -- not yet supported x-www-form-urlencoded
  // language:String  -- not yet supported x-www-form-urlencoded
  /**
    * Transcribes audio into the input language.
    * 
    *  
    * @param file The audio file object (not file name) to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.   
    * @param model   
    * @param prompt An optional text to guide the model&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.  (optional) 
    * @param responseFormat The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.  (optional, default to json) 
    * @param temperature The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.  (optional, default to 0) 
    * @param language The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.  (optional)
    * @return CreateTranscriptionResponse
    */
  def createTranscription(): ServiceCall[NotUsed ,CreateTranscriptionResponse]
  
  // file:File  -- not yet supported x-www-form-urlencoded
  // model:CreateTranscriptionRequestModel  -- not yet supported x-www-form-urlencoded
  // prompt:String  -- not yet supported x-www-form-urlencoded
  // responseFormat:String  -- not yet supported x-www-form-urlencoded
  // temperature:Number  -- not yet supported x-www-form-urlencoded
  /**
    * Translates audio into English.
    * 
    *  
    * @param file The audio file object (not file name) translate, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.   
    * @param model   
    * @param prompt An optional text to guide the model&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English.  (optional) 
    * @param responseFormat The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.  (optional, default to json) 
    * @param temperature The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.  (optional, default to 0)
    * @return CreateTranslationResponse
    */
  def createTranslation(): ServiceCall[NotUsed ,CreateTranslationResponse]
  
  /**
    * Delete a file.
    * 
    *  
    * @param fileId The ID of the file to use for this request 
    * @return DeleteFileResponse
    */
  def deleteFile(fileId: String): ServiceCall[NotUsed ,DeleteFileResponse]
  
  /**
    * Delete a fine-tuned model. You must have the Owner role in your organization.
    * 
    *  
    * @param model The model to delete 
    * @return DeleteModelResponse
    */
  def deleteModel(model: String): ServiceCall[NotUsed ,DeleteModelResponse]
  
  /**
    * Returns the contents of the specified file
    * 
    *  
    * @param fileId The ID of the file to use for this request 
    * @return String
    */
  def downloadFile(fileId: String): ServiceCall[NotUsed ,String]
  
  /**
    * Returns a list of files that belong to the user&#39;s organization.
    * 
    * 
    * @return ListFilesResponse
    */
  def listFiles(): ServiceCall[NotUsed ,ListFilesResponse]
        
  /**
    * Get fine-grained status updates for a fine-tune job. 
    * 
    *  
    * @param fineTuneId The ID of the fine-tune job to get events for.   
    * @param stream Whether to stream events for the fine-tune job. If set to true, events will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available. The stream will terminate with a &#x60;data: [DONE]&#x60; message when the job is finished (succeeded, cancelled, or failed).  If set to false, only events generated so far will be returned.  (optional, default to false)
    * @return ListFineTuneEventsResponse
    */
  def listFineTuneEvents(stream:           Option[Boolean] /* = false*/fineTuneId: String): ServiceCall[NotUsed ,ListFineTuneEventsResponse]
  
  /**
    * List your organization&#39;s fine-tuning jobs 
    * 
    * 
    * @return ListFineTunesResponse
    */
  def listFineTunes(): ServiceCall[NotUsed ,ListFineTunesResponse]
  
  /**
    * Lists the currently available models, and provides basic information about each one such as the owner and availability.
    * 
    * 
    * @return ListModelsResponse
    */
  def listModels(): ServiceCall[NotUsed ,ListModelsResponse]
  
  /**
    * Returns information about a specific file.
    * 
    *  
    * @param fileId The ID of the file to use for this request 
    * @return OpenAIFile
    */
  def retrieveFile(fileId: String): ServiceCall[NotUsed ,OpenAIFile]
  
  /**
    * Gets info about the fine-tune job.  [Learn more about Fine-tuning](/docs/guides/fine-tuning) 
    * 
    *  
    * @param fineTuneId The ID of the fine-tune job  
    * @return FineTune
    */
  def retrieveFineTune(fineTuneId: String): ServiceCall[NotUsed ,FineTune]
  
  /**
    * Retrieves a model instance, providing basic information about the model such as the owner and permissioning.
    * 
    *  
    * @param model The ID of the model to use for this request 
    * @return Model
    */
  def retrieveModel(model: String): ServiceCall[NotUsed ,Model]
  

        object OpenAIApiSizeEnum extends Enumeration {
        val   256x256, 512x512, 1024x1024 = Value     
        type OpenAIApiSizeEnum = Value
        implicit val format: Format[Value] = Format(Reads.enumNameReads(this), Writes.enumNameWrites[OpenAIApiSizeEnum.type])
        implicit val pathParamSerializer: PathParamSerializer[OpenAIApiSizeEnum] = PathParamSerializer.required("OpenAIApiSizeEnum")(withName)(_.toString)
        }
        object OpenAIApiResponseFormatEnum extends Enumeration {
        val   url, b64_json = Value     
        type OpenAIApiResponseFormatEnum = Value
        implicit val format: Format[Value] = Format(Reads.enumNameReads(this), Writes.enumNameWrites[OpenAIApiResponseFormatEnum.type])
        implicit val pathParamSerializer: PathParamSerializer[OpenAIApiResponseFormatEnum] = PathParamSerializer.required("OpenAIApiResponseFormatEnum")(withName)(_.toString)
        }
        object OpenAIApiSizeEnum extends Enumeration {
        val   256x256, 512x512, 1024x1024 = Value     
        type OpenAIApiSizeEnum = Value
        implicit val format: Format[Value] = Format(Reads.enumNameReads(this), Writes.enumNameWrites[OpenAIApiSizeEnum.type])
        implicit val pathParamSerializer: PathParamSerializer[OpenAIApiSizeEnum] = PathParamSerializer.required("OpenAIApiSizeEnum")(withName)(_.toString)
        }
        object OpenAIApiResponseFormatEnum extends Enumeration {
        val   url, b64_json = Value     
        type OpenAIApiResponseFormatEnum = Value
        implicit val format: Format[Value] = Format(Reads.enumNameReads(this), Writes.enumNameWrites[OpenAIApiResponseFormatEnum.type])
        implicit val pathParamSerializer: PathParamSerializer[OpenAIApiResponseFormatEnum] = PathParamSerializer.required("OpenAIApiResponseFormatEnum")(withName)(_.toString)
        }
  }
