/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
package org.openapitools.client.model


  /**
   * Returned in `server_vad` mode when the server detects the end of speech in  the audio buffer. The server will also send an `conversation.item.created`  event with the user message item that is created from the audio buffer. 
   */
case class RealtimeServerEventInputAudioBufferSpeechStopped(
  /* The unique ID of the server event. */
  eventId: String,
  /* The event type, must be `input_audio_buffer.speech_stopped`. */
  `type`: RealtimeServerEventInputAudioBufferSpeechStoppedEnums.`Type`,
  /* Milliseconds since the session started when speech stopped. This will  correspond to the end of audio sent to the model, and thus includes the  `min_silence_duration_ms` configured in the Session.  */
  audioEndMs: Int,
  /* The ID of the user message item that will be created. */
  itemId: String
)

object RealtimeServerEventInputAudioBufferSpeechStoppedEnums {

  type `Type` = `Type`.Value
  object `Type` extends Enumeration {
    val InputAudioBufferSpeechStopped = Value("input_audio_buffer.speech_stopped")
  }

}
