/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 */

package org.openapitools.server.model

case class UsageCompletionsResult(
  `object`: String,

  /* The aggregated number of text input tokens used, including cached tokens. For customers subscribe to scale tier, this includes scale tier tokens. */
  inputTokens: Int,

  /* The aggregated number of text input tokens that has been cached from previous requests. For customers subscribe to scale tier, this includes scale tier tokens. */
  inputCachedTokens: Option[Int],

  /* The aggregated number of text output tokens used. For customers subscribe to scale tier, this includes scale tier tokens. */
  outputTokens: Int,

  /* The aggregated number of audio input tokens used, including cached tokens. */
  inputAudioTokens: Option[Int],

  /* The aggregated number of audio output tokens used. */
  outputAudioTokens: Option[Int],

  /* The count of requests made to the model. */
  numModelRequests: Int,

  /* When `group_by=project_id`, this field provides the project ID of the grouped usage result. */
  projectId: Option[String],

  /* When `group_by=user_id`, this field provides the user ID of the grouped usage result. */
  userId: Option[String],

  /* When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result. */
  apiKeyId: Option[String],

  /* When `group_by=model`, this field provides the model name of the grouped usage result. */
  model: Option[String],

  /* When `group_by=batch`, this field tells whether the grouped usage result is batch or not. */
  batch: Option[Boolean]

 )
