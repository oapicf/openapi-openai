//
// TruncationObject.swift
//
// Generated by openapi-generator
// https://openapi-generator.tech
//

import Foundation
#if canImport(AnyCodable)
import AnyCodable
#endif

public struct TruncationObject: Codable, JSONEncodable, Hashable {

    public enum ModelType: String, Codable, CaseIterable {
        case auto = "auto"
        case lastMessages = "last_messages"
    }
    public static let lastMessagesRule = NumericRule<Int>(minimum: 1, exclusiveMinimum: false, maximum: nil, exclusiveMaximum: false, multipleOf: nil)
    /** The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`. */
    public var type: ModelType?
    /** The number of most recent messages from the thread when constructing the context for the run. */
    public var lastMessages: Int?

    public init(type: ModelType? = nil, lastMessages: Int? = nil) {
        self.type = type
        self.lastMessages = lastMessages
    }

    public enum CodingKeys: String, CodingKey, CaseIterable {
        case type
        case lastMessages = "last_messages"
    }

    // Encodable protocol methods

    public func encode(to encoder: Encoder) throws {
        var container = encoder.container(keyedBy: CodingKeys.self)
        try container.encodeIfPresent(type, forKey: .type)
        try container.encodeIfPresent(lastMessages, forKey: .lastMessages)
    }
}

