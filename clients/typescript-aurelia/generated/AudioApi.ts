/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.0.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { autoinject } from 'aurelia-framework';
import { HttpClient } from 'aurelia-http-client';
import { Api } from './Api';
import { AuthStorage } from './AuthStorage';
import {
  CreateTranslation200Response,
  CreateSpeechRequest,
  CreateTranscriptionRequestModel,
  CreateTranscription200Response,
} from './models';

/**
 * createSpeech - parameters interface
 */
export interface ICreateSpeechParams {
  createSpeechRequest: CreateSpeechRequest;
}

/**
 * createTranscription - parameters interface
 */
export interface ICreateTranscriptionParams {
  file: File;
  model: CreateTranscriptionRequestModel;
  language?: string;
  prompt?: string;
  responseFormat?: string;
  temperature?: number;
  timestampGranularities?: Array<string>;
}

/**
 * createTranslation - parameters interface
 */
export interface ICreateTranslationParams {
  file: File;
  model: CreateTranscriptionRequestModel;
  prompt?: string;
  responseFormat?: string;
  temperature?: number;
}

/**
 * AudioApi - API class
 */
@autoinject()
export class AudioApi extends Api {

  /**
   * Creates a new AudioApi class.
   *
   * @param httpClient The Aurelia HTTP client to be injected.
   * @param authStorage A storage for authentication data.
   */
  constructor(httpClient: HttpClient, authStorage: AuthStorage) {
    super(httpClient, authStorage);
  }

  /**
   * Generates audio from the input text.
   * @param params.createSpeechRequest 
   */
  async createSpeech(params: ICreateSpeechParams): Promise<File> {
    // Verify required parameters are set
    this.ensureParamIsSet('createSpeech', params, 'createSpeechRequest');

    // Create URL to call
    const url = `${this.basePath}/audio/speech`;

    const response = await this.httpClient.createRequest(url)
      // Set HTTP method
      .asPost()
      // Encode body parameter
      .withHeader('content-type', 'application/json')
      .withContent(JSON.stringify(params['createSpeechRequest'] || {}))

      // Authentication 'ApiKeyAuth' required
      // Send the request
      .send();

    if (response.statusCode < 200 || response.statusCode >= 300) {
      throw new Error(response.content);
    }

    // Extract the content
    return response.content;
  }

  /**
   * Transcribes audio into the input language.
   * @param params.file The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm. 
   * @param params.model 
   * @param params.language The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency. 
   * @param params.prompt An optional text to guide the model\\\&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language. 
   * @param params.responseFormat The format of the transcript output, in one of these options: &#x60;json&#x60;, &#x60;text&#x60;, &#x60;srt&#x60;, &#x60;verbose_json&#x60;, or &#x60;vtt&#x60;. 
   * @param params.temperature The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit. 
   * @param params.timestampGranularities The timestamp granularities to populate for this transcription. &#x60;response_format&#x60; must be set &#x60;verbose_json&#x60; to use timestamp granularities. Either or both of these options are supported: &#x60;word&#x60;, or &#x60;segment&#x60;. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency. 
   */
  async createTranscription(params: ICreateTranscriptionParams): Promise<CreateTranscription200Response> {
    // Verify required parameters are set
    this.ensureParamIsSet('createTranscription', params, 'file');
    this.ensureParamIsSet('createTranscription', params, 'model');

    // Create URL to call
    const url = `${this.basePath}/audio/transcriptions`;

    const response = await this.httpClient.createRequest(url)
      // Set HTTP method
      .asPost()
      // Encode form parameters
      .withHeader('content-type', 'application/x-www-form-urlencoded')
      .withContent(this.queryString({ 
        'file': params['file'],
        'model': params['model'],
        'language': params['language'],
        'prompt': params['prompt'],
        'response_format': params['responseFormat'],
        'temperature': params['temperature'],
        'timestamp_granularities[]': params['timestampGranularities'],
      }))

      // Authentication 'ApiKeyAuth' required
      // Send the request
      .send();

    if (response.statusCode < 200 || response.statusCode >= 300) {
      throw new Error(response.content);
    }

    // Extract the content
    return response.content;
  }

  /**
   * Translates audio into English.
   * @param params.file The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm. 
   * @param params.model 
   * @param params.prompt An optional text to guide the model\\\&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English. 
   * @param params.responseFormat The format of the transcript output, in one of these options: &#x60;json&#x60;, &#x60;text&#x60;, &#x60;srt&#x60;, &#x60;verbose_json&#x60;, or &#x60;vtt&#x60;. 
   * @param params.temperature The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit. 
   */
  async createTranslation(params: ICreateTranslationParams): Promise<CreateTranslation200Response> {
    // Verify required parameters are set
    this.ensureParamIsSet('createTranslation', params, 'file');
    this.ensureParamIsSet('createTranslation', params, 'model');

    // Create URL to call
    const url = `${this.basePath}/audio/translations`;

    const response = await this.httpClient.createRequest(url)
      // Set HTTP method
      .asPost()
      // Encode form parameters
      .withHeader('content-type', 'application/x-www-form-urlencoded')
      .withContent(this.queryString({ 
        'file': params['file'],
        'model': params['model'],
        'prompt': params['prompt'],
        'response_format': params['responseFormat'],
        'temperature': params['temperature'],
      }))

      // Authentication 'ApiKeyAuth' required
      // Send the request
      .send();

    if (response.statusCode < 200 || response.statusCode >= 300) {
      throw new Error(response.content);
    }

    // Extract the content
    return response.content;
  }

}

