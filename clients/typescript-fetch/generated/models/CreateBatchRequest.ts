/* tslint:disable */
/* eslint-disable */
/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { mapValues } from '../runtime';
/**
 * 
 * @export
 * @interface CreateBatchRequest
 */
export interface CreateBatchRequest {
    /**
     * The ID of an uploaded file that contains requests for the new batch.
     * 
     * See [upload file](/docs/api-reference/files/create) for how to upload a file.
     * 
     * Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.
     * 
     * @type {string}
     * @memberof CreateBatchRequest
     */
    inputFileId: string;
    /**
     * The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.
     * @type {string}
     * @memberof CreateBatchRequest
     */
    endpoint: CreateBatchRequestEndpointEnum;
    /**
     * The time frame within which the batch should be processed. Currently only `24h` is supported.
     * @type {string}
     * @memberof CreateBatchRequest
     */
    completionWindow: CreateBatchRequestCompletionWindowEnum;
    /**
     * Optional custom metadata for the batch.
     * @type {{ [key: string]: string; }}
     * @memberof CreateBatchRequest
     */
    metadata?: { [key: string]: string; } | null;
}


/**
 * @export
 */
export const CreateBatchRequestEndpointEnum = {
    V1ChatCompletions: '/v1/chat/completions',
    V1Embeddings: '/v1/embeddings',
    V1Completions: '/v1/completions'
} as const;
export type CreateBatchRequestEndpointEnum = typeof CreateBatchRequestEndpointEnum[keyof typeof CreateBatchRequestEndpointEnum];

/**
 * @export
 */
export const CreateBatchRequestCompletionWindowEnum = {
    _24h: '24h'
} as const;
export type CreateBatchRequestCompletionWindowEnum = typeof CreateBatchRequestCompletionWindowEnum[keyof typeof CreateBatchRequestCompletionWindowEnum];


/**
 * Check if a given object implements the CreateBatchRequest interface.
 */
export function instanceOfCreateBatchRequest(value: object): value is CreateBatchRequest {
    if (!('inputFileId' in value) || value['inputFileId'] === undefined) return false;
    if (!('endpoint' in value) || value['endpoint'] === undefined) return false;
    if (!('completionWindow' in value) || value['completionWindow'] === undefined) return false;
    return true;
}

export function CreateBatchRequestFromJSON(json: any): CreateBatchRequest {
    return CreateBatchRequestFromJSONTyped(json, false);
}

export function CreateBatchRequestFromJSONTyped(json: any, ignoreDiscriminator: boolean): CreateBatchRequest {
    if (json == null) {
        return json;
    }
    return {
        
        'inputFileId': json['input_file_id'],
        'endpoint': json['endpoint'],
        'completionWindow': json['completion_window'],
        'metadata': json['metadata'] == null ? undefined : json['metadata'],
    };
}

export function CreateBatchRequestToJSON(json: any): CreateBatchRequest {
    return CreateBatchRequestToJSONTyped(json, false);
}

export function CreateBatchRequestToJSONTyped(value?: CreateBatchRequest | null, ignoreDiscriminator: boolean = false): any {
    if (value == null) {
        return value;
    }

    return {
        
        'input_file_id': value['inputFileId'],
        'endpoint': value['endpoint'],
        'completion_window': value['completionWindow'],
        'metadata': value['metadata'],
    };
}

