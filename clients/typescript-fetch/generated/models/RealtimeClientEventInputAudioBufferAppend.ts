/* tslint:disable */
/* eslint-disable */
/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { mapValues } from '../runtime';
/**
 * Send this event to append audio bytes to the input audio buffer. The audio 
 * buffer is temporary storage you can write to and later commit. In Server VAD 
 * mode, the audio buffer is used to detect speech and the server will decide 
 * when to commit. When Server VAD is disabled, you must commit the audio buffer
 * manually.
 * 
 * The client may choose how much audio to place in each event up to a maximum 
 * of 15 MiB, for example streaming smaller chunks from the client may allow the 
 * VAD to be more responsive. Unlike made other client events, the server will 
 * not send a confirmation response to this event.
 * 
 * @export
 * @interface RealtimeClientEventInputAudioBufferAppend
 */
export interface RealtimeClientEventInputAudioBufferAppend {
    /**
     * Optional client-generated ID used to identify this event.
     * @type {string}
     * @memberof RealtimeClientEventInputAudioBufferAppend
     */
    eventId?: string;
    /**
     * The event type, must be `input_audio_buffer.append`.
     * @type {string}
     * @memberof RealtimeClientEventInputAudioBufferAppend
     */
    type: RealtimeClientEventInputAudioBufferAppendTypeEnum;
    /**
     * Base64-encoded audio bytes. This must be in the format specified by the 
     * `input_audio_format` field in the session configuration.
     * 
     * @type {string}
     * @memberof RealtimeClientEventInputAudioBufferAppend
     */
    audio: string;
}


/**
 * @export
 */
export const RealtimeClientEventInputAudioBufferAppendTypeEnum = {
    InputAudioBufferAppend: 'input_audio_buffer.append'
} as const;
export type RealtimeClientEventInputAudioBufferAppendTypeEnum = typeof RealtimeClientEventInputAudioBufferAppendTypeEnum[keyof typeof RealtimeClientEventInputAudioBufferAppendTypeEnum];


/**
 * Check if a given object implements the RealtimeClientEventInputAudioBufferAppend interface.
 */
export function instanceOfRealtimeClientEventInputAudioBufferAppend(value: object): value is RealtimeClientEventInputAudioBufferAppend {
    if (!('type' in value) || value['type'] === undefined) return false;
    if (!('audio' in value) || value['audio'] === undefined) return false;
    return true;
}

export function RealtimeClientEventInputAudioBufferAppendFromJSON(json: any): RealtimeClientEventInputAudioBufferAppend {
    return RealtimeClientEventInputAudioBufferAppendFromJSONTyped(json, false);
}

export function RealtimeClientEventInputAudioBufferAppendFromJSONTyped(json: any, ignoreDiscriminator: boolean): RealtimeClientEventInputAudioBufferAppend {
    if (json == null) {
        return json;
    }
    return {
        
        'eventId': json['event_id'] == null ? undefined : json['event_id'],
        'type': json['type'],
        'audio': json['audio'],
    };
}

export function RealtimeClientEventInputAudioBufferAppendToJSON(json: any): RealtimeClientEventInputAudioBufferAppend {
    return RealtimeClientEventInputAudioBufferAppendToJSONTyped(json, false);
}

export function RealtimeClientEventInputAudioBufferAppendToJSONTyped(value?: RealtimeClientEventInputAudioBufferAppend | null, ignoreDiscriminator: boolean = false): any {
    if (value == null) {
        return value;
    }

    return {
        
        'event_id': value['eventId'],
        'type': value['type'],
        'audio': value['audio'],
    };
}

