/* tslint:disable */
/* eslint-disable */
/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { mapValues } from '../runtime';
/**
 * This event is the output of audio transcription for user audio written to the 
 * user audio buffer. Transcription begins when the input audio buffer is 
 * committed by the client or server (in `server_vad` mode). Transcription runs 
 * asynchronously with Response creation, so this event may come before or after 
 * the Response events.
 * 
 * Realtime API models accept audio natively, and thus input transcription is a 
 * separate process run on a separate ASR (Automatic Speech Recognition) model, 
 * currently always `whisper-1`. Thus the transcript may diverge somewhat from 
 * the model's interpretation, and should be treated as a rough guide.
 * 
 * @export
 * @interface RealtimeServerEventConversationItemInputAudioTranscriptionCompleted
 */
export interface RealtimeServerEventConversationItemInputAudioTranscriptionCompleted {
    /**
     * The unique ID of the server event.
     * @type {string}
     * @memberof RealtimeServerEventConversationItemInputAudioTranscriptionCompleted
     */
    eventId: string;
    /**
     * The event type, must be
     * `conversation.item.input_audio_transcription.completed`.
     * 
     * @type {string}
     * @memberof RealtimeServerEventConversationItemInputAudioTranscriptionCompleted
     */
    type: RealtimeServerEventConversationItemInputAudioTranscriptionCompletedTypeEnum;
    /**
     * The ID of the user message item containing the audio.
     * @type {string}
     * @memberof RealtimeServerEventConversationItemInputAudioTranscriptionCompleted
     */
    itemId: string;
    /**
     * The index of the content part containing the audio.
     * @type {number}
     * @memberof RealtimeServerEventConversationItemInputAudioTranscriptionCompleted
     */
    contentIndex: number;
    /**
     * The transcribed text.
     * @type {string}
     * @memberof RealtimeServerEventConversationItemInputAudioTranscriptionCompleted
     */
    transcript: string;
}


/**
 * @export
 */
export const RealtimeServerEventConversationItemInputAudioTranscriptionCompletedTypeEnum = {
    ConversationItemInputAudioTranscriptionCompleted: 'conversation.item.input_audio_transcription.completed'
} as const;
export type RealtimeServerEventConversationItemInputAudioTranscriptionCompletedTypeEnum = typeof RealtimeServerEventConversationItemInputAudioTranscriptionCompletedTypeEnum[keyof typeof RealtimeServerEventConversationItemInputAudioTranscriptionCompletedTypeEnum];


/**
 * Check if a given object implements the RealtimeServerEventConversationItemInputAudioTranscriptionCompleted interface.
 */
export function instanceOfRealtimeServerEventConversationItemInputAudioTranscriptionCompleted(value: object): value is RealtimeServerEventConversationItemInputAudioTranscriptionCompleted {
    if (!('eventId' in value) || value['eventId'] === undefined) return false;
    if (!('type' in value) || value['type'] === undefined) return false;
    if (!('itemId' in value) || value['itemId'] === undefined) return false;
    if (!('contentIndex' in value) || value['contentIndex'] === undefined) return false;
    if (!('transcript' in value) || value['transcript'] === undefined) return false;
    return true;
}

export function RealtimeServerEventConversationItemInputAudioTranscriptionCompletedFromJSON(json: any): RealtimeServerEventConversationItemInputAudioTranscriptionCompleted {
    return RealtimeServerEventConversationItemInputAudioTranscriptionCompletedFromJSONTyped(json, false);
}

export function RealtimeServerEventConversationItemInputAudioTranscriptionCompletedFromJSONTyped(json: any, ignoreDiscriminator: boolean): RealtimeServerEventConversationItemInputAudioTranscriptionCompleted {
    if (json == null) {
        return json;
    }
    return {
        
        'eventId': json['event_id'],
        'type': json['type'],
        'itemId': json['item_id'],
        'contentIndex': json['content_index'],
        'transcript': json['transcript'],
    };
}

export function RealtimeServerEventConversationItemInputAudioTranscriptionCompletedToJSON(json: any): RealtimeServerEventConversationItemInputAudioTranscriptionCompleted {
    return RealtimeServerEventConversationItemInputAudioTranscriptionCompletedToJSONTyped(json, false);
}

export function RealtimeServerEventConversationItemInputAudioTranscriptionCompletedToJSONTyped(value?: RealtimeServerEventConversationItemInputAudioTranscriptionCompleted | null, ignoreDiscriminator: boolean = false): any {
    if (value == null) {
        return value;
    }

    return {
        
        'event_id': value['eventId'],
        'type': value['type'],
        'item_id': value['itemId'],
        'content_index': value['contentIndex'],
        'transcript': value['transcript'],
    };
}

