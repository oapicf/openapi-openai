/**
 * OpenAI API
 * APIs for sampling from and fine-tuning language models
 *
 * The version of the OpenAPI document: 2.0.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
/* tslint:disable:no-unused-variable member-ordering */

import { Observable } from 'rxjs/Observable';

import { map } from 'rxjs/operators';
import IHttpClient from '../IHttpClient';
import { inject, injectable } from 'inversify';
import { IAPIConfiguration } from '../IAPIConfiguration';
import { Headers } from '../Headers';
import HttpResponse from '../HttpResponse';

import { CreateChatCompletionRequest } from '../model/createChatCompletionRequest';
import { CreateChatCompletionResponse } from '../model/createChatCompletionResponse';
import { CreateCompletionRequest } from '../model/createCompletionRequest';
import { CreateCompletionResponse } from '../model/createCompletionResponse';
import { CreateEditRequest } from '../model/createEditRequest';
import { CreateEditResponse } from '../model/createEditResponse';
import { CreateEmbeddingRequest } from '../model/createEmbeddingRequest';
import { CreateEmbeddingResponse } from '../model/createEmbeddingResponse';
import { CreateFineTuneRequest } from '../model/createFineTuneRequest';
import { CreateImageRequest } from '../model/createImageRequest';
import { CreateModerationRequest } from '../model/createModerationRequest';
import { CreateModerationResponse } from '../model/createModerationResponse';
import { CreateTranscriptionRequestModel } from '../model/createTranscriptionRequestModel';
import { CreateTranscriptionResponse } from '../model/createTranscriptionResponse';
import { CreateTranslationResponse } from '../model/createTranslationResponse';
import { DeleteFileResponse } from '../model/deleteFileResponse';
import { DeleteModelResponse } from '../model/deleteModelResponse';
import { FineTune } from '../model/fineTune';
import { ImagesResponse } from '../model/imagesResponse';
import { ListFilesResponse } from '../model/listFilesResponse';
import { ListFineTuneEventsResponse } from '../model/listFineTuneEventsResponse';
import { ListFineTunesResponse } from '../model/listFineTunesResponse';
import { ListModelsResponse } from '../model/listModelsResponse';
import { Model } from '../model/model';
import { OpenAIFile } from '../model/openAIFile';

import { COLLECTION_FORMATS }  from '../variables';



@injectable()
export class OpenAIService {
    private basePath: string = 'https://api.openai.com/v1';

    constructor(@inject('IApiHttpClient') private httpClient: IHttpClient,
        @inject('IAPIConfiguration') private APIConfiguration: IAPIConfiguration ) {
        if(this.APIConfiguration.basePath)
            this.basePath = this.APIConfiguration.basePath;
    }

    /**
     * Immediately cancel a fine-tune job. 
     * 
     * @param fineTuneId The ID of the fine-tune job to cancel 
     
     */
    public cancelFineTune(fineTuneId: string, observe?: 'body', headers?: Headers): Observable<FineTune>;
    public cancelFineTune(fineTuneId: string, observe?: 'response', headers?: Headers): Observable<HttpResponse<FineTune>>;
    public cancelFineTune(fineTuneId: string, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (fineTuneId === null || fineTuneId === undefined){
            throw new Error('Required parameter fineTuneId was null or undefined when calling cancelFineTune.');
        }

        headers['Accept'] = 'application/json';

        const response: Observable<HttpResponse<FineTune>> = this.httpClient.post(`${this.basePath}/fine-tunes/${encodeURIComponent(String(fineTuneId))}/cancel`, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <FineTune>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Creates a model response for the given chat conversation.
     * 
     * @param createChatCompletionRequest 
     
     */
    public createChatCompletion(createChatCompletionRequest: CreateChatCompletionRequest, observe?: 'body', headers?: Headers): Observable<CreateChatCompletionResponse>;
    public createChatCompletion(createChatCompletionRequest: CreateChatCompletionRequest, observe?: 'response', headers?: Headers): Observable<HttpResponse<CreateChatCompletionResponse>>;
    public createChatCompletion(createChatCompletionRequest: CreateChatCompletionRequest, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (createChatCompletionRequest === null || createChatCompletionRequest === undefined){
            throw new Error('Required parameter createChatCompletionRequest was null or undefined when calling createChatCompletion.');
        }

        headers['Accept'] = 'application/json';
        headers['Content-Type'] = 'application/json';

        const response: Observable<HttpResponse<CreateChatCompletionResponse>> = this.httpClient.post(`${this.basePath}/chat/completions`, createChatCompletionRequest , headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <CreateChatCompletionResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Creates a completion for the provided prompt and parameters.
     * 
     * @param createCompletionRequest 
     
     */
    public createCompletion(createCompletionRequest: CreateCompletionRequest, observe?: 'body', headers?: Headers): Observable<CreateCompletionResponse>;
    public createCompletion(createCompletionRequest: CreateCompletionRequest, observe?: 'response', headers?: Headers): Observable<HttpResponse<CreateCompletionResponse>>;
    public createCompletion(createCompletionRequest: CreateCompletionRequest, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (createCompletionRequest === null || createCompletionRequest === undefined){
            throw new Error('Required parameter createCompletionRequest was null or undefined when calling createCompletion.');
        }

        headers['Accept'] = 'application/json';
        headers['Content-Type'] = 'application/json';

        const response: Observable<HttpResponse<CreateCompletionResponse>> = this.httpClient.post(`${this.basePath}/completions`, createCompletionRequest , headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <CreateCompletionResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Creates a new edit for the provided input, instruction, and parameters.
     * 
     * @param createEditRequest 
     
     */
    public createEdit(createEditRequest: CreateEditRequest, observe?: 'body', headers?: Headers): Observable<CreateEditResponse>;
    public createEdit(createEditRequest: CreateEditRequest, observe?: 'response', headers?: Headers): Observable<HttpResponse<CreateEditResponse>>;
    public createEdit(createEditRequest: CreateEditRequest, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (createEditRequest === null || createEditRequest === undefined){
            throw new Error('Required parameter createEditRequest was null or undefined when calling createEdit.');
        }

        headers['Accept'] = 'application/json';
        headers['Content-Type'] = 'application/json';

        const response: Observable<HttpResponse<CreateEditResponse>> = this.httpClient.post(`${this.basePath}/edits`, createEditRequest , headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <CreateEditResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Creates an embedding vector representing the input text.
     * 
     * @param createEmbeddingRequest 
     
     */
    public createEmbedding(createEmbeddingRequest: CreateEmbeddingRequest, observe?: 'body', headers?: Headers): Observable<CreateEmbeddingResponse>;
    public createEmbedding(createEmbeddingRequest: CreateEmbeddingRequest, observe?: 'response', headers?: Headers): Observable<HttpResponse<CreateEmbeddingResponse>>;
    public createEmbedding(createEmbeddingRequest: CreateEmbeddingRequest, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (createEmbeddingRequest === null || createEmbeddingRequest === undefined){
            throw new Error('Required parameter createEmbeddingRequest was null or undefined when calling createEmbedding.');
        }

        headers['Accept'] = 'application/json';
        headers['Content-Type'] = 'application/json';

        const response: Observable<HttpResponse<CreateEmbeddingResponse>> = this.httpClient.post(`${this.basePath}/embeddings`, createEmbeddingRequest , headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <CreateEmbeddingResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Upload a file that contains document(s) to be used across various endpoints/features. Currently, the size of all the files uploaded by one organization can be up to 1 GB. Please contact us if you need to increase the storage limit. 
     * 
     * @param file Name of the [JSON Lines](https://jsonlines.readthedocs.io/en/latest/) file to be uploaded.  If the &#x60;purpose&#x60; is set to \\\&quot;fine-tune\\\&quot;, each line is a JSON record with \\\&quot;prompt\\\&quot; and \\\&quot;completion\\\&quot; fields representing your [training examples](/docs/guides/fine-tuning/prepare-training-data). 
     * @param purpose The intended purpose of the uploaded documents.  Use \\\&quot;fine-tune\\\&quot; for [Fine-tuning](/docs/api-reference/fine-tunes). This allows us to validate the format of the uploaded file. 
     
     */
    public createFile(file: Blob, purpose: string, observe?: 'body', headers?: Headers): Observable<OpenAIFile>;
    public createFile(file: Blob, purpose: string, observe?: 'response', headers?: Headers): Observable<HttpResponse<OpenAIFile>>;
    public createFile(file: Blob, purpose: string, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (file === null || file === undefined){
            throw new Error('Required parameter file was null or undefined when calling createFile.');
        }

        if (purpose === null || purpose === undefined){
            throw new Error('Required parameter purpose was null or undefined when calling createFile.');
        }

        headers['Accept'] = 'application/json';

        let formData: FormData = new FormData();
        headers['Content-Type'] = 'multipart/form-data';
        if (file !== undefined) {
            formData.append('file', <any>file);
        }
        if (purpose !== undefined) {
            formData.append('purpose', <any>purpose);
        }

        const response: Observable<HttpResponse<OpenAIFile>> = this.httpClient.post(`${this.basePath}/files`, formData, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <OpenAIFile>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Creates a job that fine-tunes a specified model from a given dataset.  Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.  [Learn more about Fine-tuning](/docs/guides/fine-tuning) 
     * 
     * @param createFineTuneRequest 
     
     */
    public createFineTune(createFineTuneRequest: CreateFineTuneRequest, observe?: 'body', headers?: Headers): Observable<FineTune>;
    public createFineTune(createFineTuneRequest: CreateFineTuneRequest, observe?: 'response', headers?: Headers): Observable<HttpResponse<FineTune>>;
    public createFineTune(createFineTuneRequest: CreateFineTuneRequest, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (createFineTuneRequest === null || createFineTuneRequest === undefined){
            throw new Error('Required parameter createFineTuneRequest was null or undefined when calling createFineTune.');
        }

        headers['Accept'] = 'application/json';
        headers['Content-Type'] = 'application/json';

        const response: Observable<HttpResponse<FineTune>> = this.httpClient.post(`${this.basePath}/fine-tunes`, createFineTuneRequest , headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <FineTune>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Creates an image given a prompt.
     * 
     * @param createImageRequest 
     
     */
    public createImage(createImageRequest: CreateImageRequest, observe?: 'body', headers?: Headers): Observable<ImagesResponse>;
    public createImage(createImageRequest: CreateImageRequest, observe?: 'response', headers?: Headers): Observable<HttpResponse<ImagesResponse>>;
    public createImage(createImageRequest: CreateImageRequest, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (createImageRequest === null || createImageRequest === undefined){
            throw new Error('Required parameter createImageRequest was null or undefined when calling createImage.');
        }

        headers['Accept'] = 'application/json';
        headers['Content-Type'] = 'application/json';

        const response: Observable<HttpResponse<ImagesResponse>> = this.httpClient.post(`${this.basePath}/images/generations`, createImageRequest , headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <ImagesResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Creates an edited or extended image given an original image and a prompt.
     * 
     * @param image The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.
     * @param prompt A text description of the desired image(s). The maximum length is 1000 characters.
     * @param mask An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where &#x60;image&#x60; should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as &#x60;image&#x60;.
     * @param n The number of images to generate. Must be between 1 and 10.
     * @param size The size of the generated images. Must be one of &#x60;256x256&#x60;, &#x60;512x512&#x60;, or &#x60;1024x1024&#x60;.
     * @param responseFormat The format in which the generated images are returned. Must be one of &#x60;url&#x60; or &#x60;b64_json&#x60;.
     * @param user A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids). 
     
     */
    public createImageEdit(image: Blob, prompt: string, mask?: Blob, n?: number, size?: string, responseFormat?: string, user?: string, observe?: 'body', headers?: Headers): Observable<ImagesResponse>;
    public createImageEdit(image: Blob, prompt: string, mask?: Blob, n?: number, size?: string, responseFormat?: string, user?: string, observe?: 'response', headers?: Headers): Observable<HttpResponse<ImagesResponse>>;
    public createImageEdit(image: Blob, prompt: string, mask?: Blob, n?: number, size?: string, responseFormat?: string, user?: string, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (image === null || image === undefined){
            throw new Error('Required parameter image was null or undefined when calling createImageEdit.');
        }

        if (prompt === null || prompt === undefined){
            throw new Error('Required parameter prompt was null or undefined when calling createImageEdit.');
        }

        headers['Accept'] = 'application/json';

        let formData: FormData = new FormData();
        headers['Content-Type'] = 'multipart/form-data';
        if (image !== undefined) {
            formData.append('image', <any>image);
        }
        if (mask !== undefined) {
            formData.append('mask', <any>mask);
        }
        if (prompt !== undefined) {
            formData.append('prompt', <any>prompt);
        }
        if (n !== undefined) {
            formData.append('n', <any>n);
        }
        if (size !== undefined) {
            formData.append('size', <any>size);
        }
        if (responseFormat !== undefined) {
            formData.append('response_format', <any>responseFormat);
        }
        if (user !== undefined) {
            formData.append('user', <any>user);
        }

        const response: Observable<HttpResponse<ImagesResponse>> = this.httpClient.post(`${this.basePath}/images/edits`, formData, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <ImagesResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Creates a variation of a given image.
     * 
     * @param image The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.
     * @param n The number of images to generate. Must be between 1 and 10.
     * @param size The size of the generated images. Must be one of &#x60;256x256&#x60;, &#x60;512x512&#x60;, or &#x60;1024x1024&#x60;.
     * @param responseFormat The format in which the generated images are returned. Must be one of &#x60;url&#x60; or &#x60;b64_json&#x60;.
     * @param user A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids). 
     
     */
    public createImageVariation(image: Blob, n?: number, size?: string, responseFormat?: string, user?: string, observe?: 'body', headers?: Headers): Observable<ImagesResponse>;
    public createImageVariation(image: Blob, n?: number, size?: string, responseFormat?: string, user?: string, observe?: 'response', headers?: Headers): Observable<HttpResponse<ImagesResponse>>;
    public createImageVariation(image: Blob, n?: number, size?: string, responseFormat?: string, user?: string, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (image === null || image === undefined){
            throw new Error('Required parameter image was null or undefined when calling createImageVariation.');
        }

        headers['Accept'] = 'application/json';

        let formData: FormData = new FormData();
        headers['Content-Type'] = 'multipart/form-data';
        if (image !== undefined) {
            formData.append('image', <any>image);
        }
        if (n !== undefined) {
            formData.append('n', <any>n);
        }
        if (size !== undefined) {
            formData.append('size', <any>size);
        }
        if (responseFormat !== undefined) {
            formData.append('response_format', <any>responseFormat);
        }
        if (user !== undefined) {
            formData.append('user', <any>user);
        }

        const response: Observable<HttpResponse<ImagesResponse>> = this.httpClient.post(`${this.basePath}/images/variations`, formData, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <ImagesResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Classifies if text violates OpenAI\&#39;s Content Policy
     * 
     * @param createModerationRequest 
     
     */
    public createModeration(createModerationRequest: CreateModerationRequest, observe?: 'body', headers?: Headers): Observable<CreateModerationResponse>;
    public createModeration(createModerationRequest: CreateModerationRequest, observe?: 'response', headers?: Headers): Observable<HttpResponse<CreateModerationResponse>>;
    public createModeration(createModerationRequest: CreateModerationRequest, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (createModerationRequest === null || createModerationRequest === undefined){
            throw new Error('Required parameter createModerationRequest was null or undefined when calling createModeration.');
        }

        headers['Accept'] = 'application/json';
        headers['Content-Type'] = 'application/json';

        const response: Observable<HttpResponse<CreateModerationResponse>> = this.httpClient.post(`${this.basePath}/moderations`, createModerationRequest , headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <CreateModerationResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Transcribes audio into the input language.
     * 
     * @param file The audio file object (not file name) to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm. 
     * @param model 
     * @param prompt An optional text to guide the model\\\&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language. 
     * @param responseFormat The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt. 
     * @param temperature The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit. 
     * @param language The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency. 
     
     */
    public createTranscription(file: Blob, model: CreateTranscriptionRequestModel, prompt?: string, responseFormat?: string, temperature?: number, language?: string, observe?: 'body', headers?: Headers): Observable<CreateTranscriptionResponse>;
    public createTranscription(file: Blob, model: CreateTranscriptionRequestModel, prompt?: string, responseFormat?: string, temperature?: number, language?: string, observe?: 'response', headers?: Headers): Observable<HttpResponse<CreateTranscriptionResponse>>;
    public createTranscription(file: Blob, model: CreateTranscriptionRequestModel, prompt?: string, responseFormat?: string, temperature?: number, language?: string, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (file === null || file === undefined){
            throw new Error('Required parameter file was null or undefined when calling createTranscription.');
        }

        if (model === null || model === undefined){
            throw new Error('Required parameter model was null or undefined when calling createTranscription.');
        }

        headers['Accept'] = 'application/json';

        let formData: FormData = new FormData();
        headers['Content-Type'] = 'multipart/form-data';
        if (file !== undefined) {
            formData.append('file', <any>file);
        }
        if (model !== undefined) {
            formData.append('model', <any>model);
        }
        if (prompt !== undefined) {
            formData.append('prompt', <any>prompt);
        }
        if (responseFormat !== undefined) {
            formData.append('response_format', <any>responseFormat);
        }
        if (temperature !== undefined) {
            formData.append('temperature', <any>temperature);
        }
        if (language !== undefined) {
            formData.append('language', <any>language);
        }

        const response: Observable<HttpResponse<CreateTranscriptionResponse>> = this.httpClient.post(`${this.basePath}/audio/transcriptions`, formData, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <CreateTranscriptionResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Translates audio into English.
     * 
     * @param file The audio file object (not file name) translate, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm. 
     * @param model 
     * @param prompt An optional text to guide the model\\\&#39;s style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English. 
     * @param responseFormat The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt. 
     * @param temperature The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit. 
     
     */
    public createTranslation(file: Blob, model: CreateTranscriptionRequestModel, prompt?: string, responseFormat?: string, temperature?: number, observe?: 'body', headers?: Headers): Observable<CreateTranslationResponse>;
    public createTranslation(file: Blob, model: CreateTranscriptionRequestModel, prompt?: string, responseFormat?: string, temperature?: number, observe?: 'response', headers?: Headers): Observable<HttpResponse<CreateTranslationResponse>>;
    public createTranslation(file: Blob, model: CreateTranscriptionRequestModel, prompt?: string, responseFormat?: string, temperature?: number, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (file === null || file === undefined){
            throw new Error('Required parameter file was null or undefined when calling createTranslation.');
        }

        if (model === null || model === undefined){
            throw new Error('Required parameter model was null or undefined when calling createTranslation.');
        }

        headers['Accept'] = 'application/json';

        let formData: FormData = new FormData();
        headers['Content-Type'] = 'multipart/form-data';
        if (file !== undefined) {
            formData.append('file', <any>file);
        }
        if (model !== undefined) {
            formData.append('model', <any>model);
        }
        if (prompt !== undefined) {
            formData.append('prompt', <any>prompt);
        }
        if (responseFormat !== undefined) {
            formData.append('response_format', <any>responseFormat);
        }
        if (temperature !== undefined) {
            formData.append('temperature', <any>temperature);
        }

        const response: Observable<HttpResponse<CreateTranslationResponse>> = this.httpClient.post(`${this.basePath}/audio/translations`, formData, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <CreateTranslationResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Delete a file.
     * 
     * @param fileId The ID of the file to use for this request
     
     */
    public deleteFile(fileId: string, observe?: 'body', headers?: Headers): Observable<DeleteFileResponse>;
    public deleteFile(fileId: string, observe?: 'response', headers?: Headers): Observable<HttpResponse<DeleteFileResponse>>;
    public deleteFile(fileId: string, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (fileId === null || fileId === undefined){
            throw new Error('Required parameter fileId was null or undefined when calling deleteFile.');
        }

        headers['Accept'] = 'application/json';

        const response: Observable<HttpResponse<DeleteFileResponse>> = this.httpClient.delete(`${this.basePath}/files/${encodeURIComponent(String(fileId))}`, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <DeleteFileResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Delete a fine-tuned model. You must have the Owner role in your organization.
     * 
     * @param model The model to delete
     
     */
    public deleteModel(model: string, observe?: 'body', headers?: Headers): Observable<DeleteModelResponse>;
    public deleteModel(model: string, observe?: 'response', headers?: Headers): Observable<HttpResponse<DeleteModelResponse>>;
    public deleteModel(model: string, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (model === null || model === undefined){
            throw new Error('Required parameter model was null or undefined when calling deleteModel.');
        }

        headers['Accept'] = 'application/json';

        const response: Observable<HttpResponse<DeleteModelResponse>> = this.httpClient.delete(`${this.basePath}/models/${encodeURIComponent(String(model))}`, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <DeleteModelResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Returns the contents of the specified file
     * 
     * @param fileId The ID of the file to use for this request
     
     */
    public downloadFile(fileId: string, observe?: 'body', headers?: Headers): Observable<string>;
    public downloadFile(fileId: string, observe?: 'response', headers?: Headers): Observable<HttpResponse<string>>;
    public downloadFile(fileId: string, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (fileId === null || fileId === undefined){
            throw new Error('Required parameter fileId was null or undefined when calling downloadFile.');
        }

        headers['Accept'] = 'application/json';

        const response: Observable<HttpResponse<string>> = this.httpClient.get(`${this.basePath}/files/${encodeURIComponent(String(fileId))}/content`, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <string>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Returns a list of files that belong to the user\&#39;s organization.
     * 
     
     */
    public listFiles(observe?: 'body', headers?: Headers): Observable<ListFilesResponse>;
    public listFiles(observe?: 'response', headers?: Headers): Observable<HttpResponse<ListFilesResponse>>;
    public listFiles(observe: any = 'body', headers: Headers = {}): Observable<any> {
        headers['Accept'] = 'application/json';

        const response: Observable<HttpResponse<ListFilesResponse>> = this.httpClient.get(`${this.basePath}/files`, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <ListFilesResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Get fine-grained status updates for a fine-tune job. 
     * 
     * @param fineTuneId The ID of the fine-tune job to get events for. 
     * @param stream Whether to stream events for the fine-tune job. If set to true, events will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available. The stream will terminate with a &#x60;data: [DONE]&#x60; message when the job is finished (succeeded, cancelled, or failed).  If set to false, only events generated so far will be returned. 
     
     */
    public listFineTuneEvents(fineTuneId: string, stream?: boolean, observe?: 'body', headers?: Headers): Observable<ListFineTuneEventsResponse>;
    public listFineTuneEvents(fineTuneId: string, stream?: boolean, observe?: 'response', headers?: Headers): Observable<HttpResponse<ListFineTuneEventsResponse>>;
    public listFineTuneEvents(fineTuneId: string, stream?: boolean, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (fineTuneId === null || fineTuneId === undefined){
            throw new Error('Required parameter fineTuneId was null or undefined when calling listFineTuneEvents.');
        }

        let queryParameters: string[] = [];
        if (stream !== undefined) {
            queryParameters.push('stream='+encodeURIComponent(String(stream)));
        }

        headers['Accept'] = 'application/json';

        const response: Observable<HttpResponse<ListFineTuneEventsResponse>> = this.httpClient.get(`${this.basePath}/fine-tunes/${encodeURIComponent(String(fineTuneId))}/events?${queryParameters.join('&')}`, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <ListFineTuneEventsResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * List your organization\&#39;s fine-tuning jobs 
     * 
     
     */
    public listFineTunes(observe?: 'body', headers?: Headers): Observable<ListFineTunesResponse>;
    public listFineTunes(observe?: 'response', headers?: Headers): Observable<HttpResponse<ListFineTunesResponse>>;
    public listFineTunes(observe: any = 'body', headers: Headers = {}): Observable<any> {
        headers['Accept'] = 'application/json';

        const response: Observable<HttpResponse<ListFineTunesResponse>> = this.httpClient.get(`${this.basePath}/fine-tunes`, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <ListFineTunesResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Lists the currently available models, and provides basic information about each one such as the owner and availability.
     * 
     
     */
    public listModels(observe?: 'body', headers?: Headers): Observable<ListModelsResponse>;
    public listModels(observe?: 'response', headers?: Headers): Observable<HttpResponse<ListModelsResponse>>;
    public listModels(observe: any = 'body', headers: Headers = {}): Observable<any> {
        headers['Accept'] = 'application/json';

        const response: Observable<HttpResponse<ListModelsResponse>> = this.httpClient.get(`${this.basePath}/models`, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <ListModelsResponse>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Returns information about a specific file.
     * 
     * @param fileId The ID of the file to use for this request
     
     */
    public retrieveFile(fileId: string, observe?: 'body', headers?: Headers): Observable<OpenAIFile>;
    public retrieveFile(fileId: string, observe?: 'response', headers?: Headers): Observable<HttpResponse<OpenAIFile>>;
    public retrieveFile(fileId: string, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (fileId === null || fileId === undefined){
            throw new Error('Required parameter fileId was null or undefined when calling retrieveFile.');
        }

        headers['Accept'] = 'application/json';

        const response: Observable<HttpResponse<OpenAIFile>> = this.httpClient.get(`${this.basePath}/files/${encodeURIComponent(String(fileId))}`, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <OpenAIFile>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Gets info about the fine-tune job.  [Learn more about Fine-tuning](/docs/guides/fine-tuning) 
     * 
     * @param fineTuneId The ID of the fine-tune job 
     
     */
    public retrieveFineTune(fineTuneId: string, observe?: 'body', headers?: Headers): Observable<FineTune>;
    public retrieveFineTune(fineTuneId: string, observe?: 'response', headers?: Headers): Observable<HttpResponse<FineTune>>;
    public retrieveFineTune(fineTuneId: string, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (fineTuneId === null || fineTuneId === undefined){
            throw new Error('Required parameter fineTuneId was null or undefined when calling retrieveFineTune.');
        }

        headers['Accept'] = 'application/json';

        const response: Observable<HttpResponse<FineTune>> = this.httpClient.get(`${this.basePath}/fine-tunes/${encodeURIComponent(String(fineTuneId))}`, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <FineTune>(httpResponse.response))
               );
        }
        return response;
    }


    /**
     * Retrieves a model instance, providing basic information about the model such as the owner and permissioning.
     * 
     * @param model The ID of the model to use for this request
     
     */
    public retrieveModel(model: string, observe?: 'body', headers?: Headers): Observable<Model>;
    public retrieveModel(model: string, observe?: 'response', headers?: Headers): Observable<HttpResponse<Model>>;
    public retrieveModel(model: string, observe: any = 'body', headers: Headers = {}): Observable<any> {
        if (model === null || model === undefined){
            throw new Error('Required parameter model was null or undefined when calling retrieveModel.');
        }

        headers['Accept'] = 'application/json';

        const response: Observable<HttpResponse<Model>> = this.httpClient.get(`${this.basePath}/models/${encodeURIComponent(String(model))}`, headers);
        if (observe === 'body') {
               return response.pipe(
                   map((httpResponse: HttpResponse) => <Model>(httpResponse.response))
               );
        }
        return response;
    }

}
