/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import * as models from './models';

/**
 * Represents an `assistant` that can call the model and use tools.
 */
export interface AssistantObject {
    /**
     * The identifier, which can be referenced in API endpoints.
     */
    id: string;

    /**
     * The object type, which is always `assistant`.
     */
    object: AssistantObject.ObjectEnum;

    /**
     * The Unix timestamp (in seconds) for when the assistant was created.
     */
    created_at: number;

    /**
     * The name of the assistant. The maximum length is 256 characters. 
     */
    name: string;

    /**
     * The description of the assistant. The maximum length is 512 characters. 
     */
    description: string;

    /**
     * ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them. 
     */
    model: string;

    /**
     * The system instructions that the assistant uses. The maximum length is 256,000 characters. 
     */
    instructions: string;

    /**
     * A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`. 
     */
    tools: Array<models.AssistantObjectToolsInner>;

    tool_resources?: models.AssistantObjectToolResources;

    /**
     * Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long. 
     */
    metadata: object;

    /**
     * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. 
     */
    temperature?: number;

    /**
     * An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.  We generally recommend altering this or temperature but not both. 
     */
    top_p?: number;

    response_format?: models.AssistantsApiResponseFormatOption;

}
export namespace AssistantObject {
    export enum ObjectEnum {
        Assistant = <any> 'assistant'
    }
}
