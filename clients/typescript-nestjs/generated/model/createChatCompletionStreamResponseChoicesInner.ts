/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.0.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
import { CreateChatCompletionResponseChoicesInnerLogprobs } from './createChatCompletionResponseChoicesInnerLogprobs';
import { ChatCompletionStreamResponseDelta } from './chatCompletionStreamResponseDelta';


export interface CreateChatCompletionStreamResponseChoicesInner { 
    delta: ChatCompletionStreamResponseDelta;
    logprobs?: CreateChatCompletionResponseChoicesInnerLogprobs | null;
    /**
     * The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function. 
     */
    finish_reason: CreateChatCompletionStreamResponseChoicesInner.FinishReasonEnum | null;
    /**
     * The index of the choice in the list of choices.
     */
    index: number;
}
export namespace CreateChatCompletionStreamResponseChoicesInner {
    export type FinishReasonEnum = 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call';
    export const FinishReasonEnum = {
        Stop: 'stop' as FinishReasonEnum,
        Length: 'length' as FinishReasonEnum,
        ToolCalls: 'tool_calls' as FinishReasonEnum,
        ContentFilter: 'content_filter' as FinishReasonEnum,
        FunctionCall: 'function_call' as FinishReasonEnum
    };
}


