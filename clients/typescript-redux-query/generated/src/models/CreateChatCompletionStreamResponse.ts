// tslint:disable
/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { exists, mapValues } from '../runtime';
import {
    CreateChatCompletionStreamResponseChoicesInner,
    CreateChatCompletionStreamResponseChoicesInnerFromJSON,
    CreateChatCompletionStreamResponseChoicesInnerToJSON,
    CreateChatCompletionStreamResponseUsage,
    CreateChatCompletionStreamResponseUsageFromJSON,
    CreateChatCompletionStreamResponseUsageToJSON,
} from './';

/**
 * Represents a streamed chunk of a chat completion response returned by model, based on the provided input.
 * @export
 * @interface CreateChatCompletionStreamResponse
 */
export interface CreateChatCompletionStreamResponse  {
    /**
     * A unique identifier for the chat completion. Each chunk has the same ID.
     * @type {string}
     * @memberof CreateChatCompletionStreamResponse
     */
    id: string;
    /**
     * A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the last chunk if you set `stream_options: {\"include_usage\": true}`. 
     * @type {Array<CreateChatCompletionStreamResponseChoicesInner>}
     * @memberof CreateChatCompletionStreamResponse
     */
    choices: Array<CreateChatCompletionStreamResponseChoicesInner>;
    /**
     * The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
     * @type {number}
     * @memberof CreateChatCompletionStreamResponse
     */
    created: number;
    /**
     * The model to generate the completion.
     * @type {string}
     * @memberof CreateChatCompletionStreamResponse
     */
    model: string;
    /**
     * The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.
     * @type {string}
     * @memberof CreateChatCompletionStreamResponse
     */
    serviceTier?: CreateChatCompletionStreamResponseServiceTierEnum;
    /**
     * This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism. 
     * @type {string}
     * @memberof CreateChatCompletionStreamResponse
     */
    systemFingerprint?: string;
    /**
     * The object type, which is always `chat.completion.chunk`.
     * @type {string}
     * @memberof CreateChatCompletionStreamResponse
     */
    object: CreateChatCompletionStreamResponseObjectEnum;
    /**
     * 
     * @type {CreateChatCompletionStreamResponseUsage}
     * @memberof CreateChatCompletionStreamResponse
     */
    usage?: CreateChatCompletionStreamResponseUsage;
}

export function CreateChatCompletionStreamResponseFromJSON(json: any): CreateChatCompletionStreamResponse {
    return {
        'id': json['id'],
        'choices': (json['choices'] as Array<any>).map(CreateChatCompletionStreamResponseChoicesInnerFromJSON),
        'created': json['created'],
        'model': json['model'],
        'serviceTier': !exists(json, 'service_tier') ? undefined : json['service_tier'],
        'systemFingerprint': !exists(json, 'system_fingerprint') ? undefined : json['system_fingerprint'],
        'object': json['object'],
        'usage': !exists(json, 'usage') ? undefined : CreateChatCompletionStreamResponseUsageFromJSON(json['usage']),
    };
}

export function CreateChatCompletionStreamResponseToJSON(value?: CreateChatCompletionStreamResponse): any {
    if (value === undefined) {
        return undefined;
    }
    return {
        'id': value.id,
        'choices': (value.choices as Array<any>).map(CreateChatCompletionStreamResponseChoicesInnerToJSON),
        'created': value.created,
        'model': value.model,
        'service_tier': value.serviceTier,
        'system_fingerprint': value.systemFingerprint,
        'object': value.object,
        'usage': CreateChatCompletionStreamResponseUsageToJSON(value.usage),
    };
}

/**
* @export
* @enum {string}
*/
export enum CreateChatCompletionStreamResponseServiceTierEnum {
    Scale = 'scale',
    Default = 'default'
}
/**
* @export
* @enum {string}
*/
export enum CreateChatCompletionStreamResponseObjectEnum {
    ChatCompletionChunk = 'chat.completion.chunk'
}


