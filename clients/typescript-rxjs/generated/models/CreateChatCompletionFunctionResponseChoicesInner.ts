// tslint:disable
/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import type {
    ChatCompletionResponseMessage,
} from './';

/**
 * @export
 * @interface CreateChatCompletionFunctionResponseChoicesInner
 */
export interface CreateChatCompletionFunctionResponseChoicesInner {
    /**
     * The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, or `function_call` if the model called a function. 
     * @type {string}
     * @memberof CreateChatCompletionFunctionResponseChoicesInner
     */
    finish_reason: CreateChatCompletionFunctionResponseChoicesInnerFinishReasonEnum;
    /**
     * The index of the choice in the list of choices.
     * @type {number}
     * @memberof CreateChatCompletionFunctionResponseChoicesInner
     */
    index: number;
    /**
     * @type {ChatCompletionResponseMessage}
     * @memberof CreateChatCompletionFunctionResponseChoicesInner
     */
    message: ChatCompletionResponseMessage;
}

/**
 * @export
 * @enum {string}
 */
export enum CreateChatCompletionFunctionResponseChoicesInnerFinishReasonEnum {
    Stop = 'stop',
    Length = 'length',
    FunctionCall = 'function_call',
    ContentFilter = 'content_filter'
}

