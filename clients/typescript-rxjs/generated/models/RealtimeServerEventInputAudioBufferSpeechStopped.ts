// tslint:disable
/**
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * Contact: blah+oapicf@cliffano.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

/**
 * Returned in `server_vad` mode when the server detects the end of speech in  the audio buffer. The server will also send an `conversation.item.created`  event with the user message item that is created from the audio buffer. 
 * @export
 * @interface RealtimeServerEventInputAudioBufferSpeechStopped
 */
export interface RealtimeServerEventInputAudioBufferSpeechStopped {
    /**
     * The unique ID of the server event.
     * @type {string}
     * @memberof RealtimeServerEventInputAudioBufferSpeechStopped
     */
    event_id: string;
    /**
     * The event type, must be `input_audio_buffer.speech_stopped`.
     * @type {string}
     * @memberof RealtimeServerEventInputAudioBufferSpeechStopped
     */
    type: RealtimeServerEventInputAudioBufferSpeechStoppedTypeEnum;
    /**
     * Milliseconds since the session started when speech stopped. This will  correspond to the end of audio sent to the model, and thus includes the  `min_silence_duration_ms` configured in the Session. 
     * @type {number}
     * @memberof RealtimeServerEventInputAudioBufferSpeechStopped
     */
    audio_end_ms: number;
    /**
     * The ID of the user message item that will be created.
     * @type {string}
     * @memberof RealtimeServerEventInputAudioBufferSpeechStopped
     */
    item_id: string;
}

/**
 * @export
 * @enum {string}
 */
export enum RealtimeServerEventInputAudioBufferSpeechStoppedTypeEnum {
    InputAudioBufferSpeechStopped = 'input_audio_buffer.speech_stopped'
}

